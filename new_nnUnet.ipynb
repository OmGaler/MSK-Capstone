{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmGaler/MSK-Capstone/blob/master/new_nnUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTx6t4ID87Kq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj-URPve6g8Y",
        "outputId": "50a240fd-b8d8-4156-db91-62530a276bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Background checkpoint download started.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-10 (download_checkpoint):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-1-1f2118c8a558>\", line 8, in download_checkpoint\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/nnunetresults/'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import threading\n",
        "from google.colab import files\n",
        "\n",
        "def download_checkpoint():\n",
        "    while True:\n",
        "        files_list = os.listdir(\"/nnunetresults/\")\n",
        "        for file in files_list:\n",
        "            if file.endswith(\".pth\"):\n",
        "                print(\"Checkpoint found. Downloading...\")\n",
        "                local_path = os.path.join(\"/nnunetresults/\", file)\n",
        "                files.download(local_path)\n",
        "                return\n",
        "        time.sleep(10)  # Check every 10 seconds\n",
        "\n",
        "def main():\n",
        "    # Start the download_checkpoint function in a separate thread\n",
        "    thread = threading.Thread(target=download_checkpoint)\n",
        "    thread.daemon = True  # Daemonize the thread so it terminates when the main thread terminates\n",
        "    thread.start()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"Background checkpoint download started.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkZG-toIysqa",
        "outputId": "2f70acd4-9ccf-4150-b300-0cc95cc71b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (819.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.1+cu118\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ncoCMi2Yhl"
      },
      "outputs": [],
      "source": [
        "! mkdir \"nnUNet_raw\"\n",
        "! mkdir \"nnUNet_preprocessed\"\n",
        "! mkdir \"nnUNet_results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jRNXWxi3OC7"
      },
      "source": [
        "Hmm this should be giving an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyDmNgOjhdDk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set environment variable\n",
        "os.environ['nnUNet_raw'] = '/content/nnUNet_raw'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "os.environ['nnUNet_results'] = '/content/nnUNet_results'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3kgnbk8hl59",
        "outputId": "e9754e69-2d2d-45a7-fe57-e511849cc982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nnUNet_raw\n"
          ]
        }
      ],
      "source": [
        "!echo ${nnUNet_raw}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD_xh89m7zyQ",
        "outputId": "10917c63-d0db-4614-b02a-6e63ca92352e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchio\n",
            "  Downloading torchio-0.19.6-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m163.8/173.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from torchio)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.2.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.2)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (67.7.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]->torchio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]->torchio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n",
            "Installing collected packages: SimpleITK, shellingham, Deprecated, colorama, torchio\n",
            "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 colorama-0.4.6 shellingham-1.5.4 torchio-0.19.6\n"
          ]
        }
      ],
      "source": [
        "!pip install torchio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WW2REhSWAi6"
      },
      "outputs": [],
      "source": [
        "# ! mkdir 'nnUNet_raw/Task07_Kidney'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/imagesTs'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/imagesTr'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/labelsTr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FizGjtm6tey"
      },
      "outputs": [],
      "source": [
        "! mkdir 'nnUNet_raw/Dataset007_Kidney'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/imagesTs'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/imagesTr'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/labelsTr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwtDwyqwDCMP",
        "outputId": "74ada110-35d0-45bf-9d5d-06d070e74bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'batchgenerators'...\n",
            "remote: Enumerating objects: 3204, done.\u001b[K\n",
            "remote: Counting objects: 100% (575/575), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 3204 (delta 480), reused 461 (delta 461), pack-reused 2629\u001b[K\n",
            "Receiving objects: 100% (3204/3204), 7.53 MiB | 15.94 MiB/s, done.\n",
            "Resolving deltas: 100% (2424/2424), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MIC-DKFZ/batchgenerators.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "tL3ko5HEDC_S",
        "outputId": "d253da64-5d0b-4812-846d-a8923aba1e86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/batchgenerators\n",
            "Processing /content/batchgenerators\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (0.18.3)\n",
            "Collecting unittest2 (from batchgenerators==0.25)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->batchgenerators==0.25) (1.3.2)\n",
            "Collecting argparse (from unittest2->batchgenerators==0.25)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.10/dist-packages (from unittest2->batchgenerators==0.25) (1.16.0)\n",
            "Collecting traceback2 (from unittest2->batchgenerators==0.25)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators==0.25)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: batchgenerators\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=92664 sha256=4e00987b057ecbb55acaa8bd714aa565d49a236a6d92bfbb17849686fc19f85f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m827iv_7/wheels/36/51/5d/3aa020578c0d1835119dcfda74d4432a5adf9470682aa6c1e1\n",
            "Successfully built batchgenerators\n",
            "Installing collected packages: linecache2, argparse, traceback2, unittest2, batchgenerators\n",
            "Successfully installed argparse-1.4.0 batchgenerators-0.25 linecache2-1.0.0 traceback2-1.4.0 unittest2-1.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "91200f203bd34da7b2c91a6b5c8b0d0b",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd batchgenerators\n",
        "!pip install .\n",
        "\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VH8KeZk05e1",
        "outputId": "57f996c7-06c6-4b98-a37e-ff8d4f724c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'nnUNet'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (201/201), done.\u001b[K\n",
            "remote: Total 216 (delta 13), reused 216 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (216/216), 1.94 MiB | 30.03 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "# !pip install nnunetv2\n",
        "!git clone https://github.com/bennyjacob326/nnUNet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "erVTFQUAUOdL",
        "outputId": "5c2d45a3-1dea-43b3-cab6-383750427647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/nnUNet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.2.1+cu118)\n",
            "Collecting acvl-utils>=0.2 (from nnunetv2==2.2.1)\n",
            "  Downloading acvl_utils-0.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures>=0.2 (from nnunetv2==2.2.1)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (4.66.2)\n",
            "Collecting dicom2nifti (from nnunetv2==2.2.1)\n",
            "  Downloading dicom2nifti-2.4.10-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.11.4)\n",
            "Requirement already satisfied: batchgenerators>=0.25 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.19.3)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.5.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.20.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2024.2.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.31.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (4.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.13.1)\n",
            "Collecting imagecodecs (from nnunetv2==2.2.1)\n",
            "  Downloading imagecodecs-2024.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs (from nnunetv2==2.2.1)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting connected-components-3d (from acvl-utils>=0.2->nnunetv2==2.2.1)\n",
            "  Downloading connected_components_3d-3.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (9.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (0.18.3)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (2.31.6)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (2.2.0)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2==2.2.1)\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-gdcm (from dicom2nifti->nnunetv2==2.2.1)\n",
            "  Downloading python_gdcm-3.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2==2.2.1) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2==2.2.1) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2==2.2.1) (1.3.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2==2.2.1) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.2.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->nnunetv2==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->nnunetv2==2.2.1) (1.3.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.10/dist-packages (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1) (1.4.0)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.10/dist-packages (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.2.1) (1.0.0)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, dynamic-network-architectures\n",
            "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.2.1-0.editable-py3-none-any.whl size=16232 sha256=7b3ef97deaa03a741a78a3da1c00ca693d6150170ebf308d039700d488de0332\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-roq6oa7e/wheels/66/a8/0c/d8553e2873068c742a2c91eadf0e7dbc86388a52232ce6319b\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22439 sha256=fe1c9389d4a0a3faacdc01724784701fe32b25f240c3f7e6268ebb8b4d34c886\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30049 sha256=ab6125b350813e27ba6523dedc859c7be878d668639e381c97f8fe944b936899\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n",
            "Successfully built nnunetv2 acvl-utils dynamic-network-architectures\n",
            "Installing collected packages: argparse, yacs, python-gdcm, pydicom, imagecodecs, connected-components-3d, dicom2nifti, dynamic-network-architectures, acvl-utils, nnunetv2\n",
            "Successfully installed acvl-utils-0.2 argparse-1.4.0 connected-components-3d-3.12.4 dicom2nifti-2.4.10 dynamic-network-architectures-0.3.1 imagecodecs-2024.1.1 nnunetv2-2.2.1 pydicom-2.4.4 python-gdcm-3.0.23 yacs-0.1.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e934c7954072419aa4101277faf72182",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install -e /content/nnUNet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdcJeH2VG4um"
      },
      "outputs": [],
      "source": [
        "from nnUNet.nnunetv2.paths import nnUNet_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l8hxDajxYXz",
        "outputId": "67ab3d8c-8c12-4bb0-a928-a0443e9cf7f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.3\n",
            "    Uninstalling gdown-4.7.3:\n",
            "      Successfully uninstalled gdown-4.7.3\n",
            "Successfully installed gdown-5.1.0\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-YzI7y-ZbZlcGgzRP6Ont_A32ayMUVbj\n",
            "From (redirected): https://drive.google.com/uc?id=1-YzI7y-ZbZlcGgzRP6Ont_A32ayMUVbj&confirm=t&uuid=08e86a74-5688-4605-b5d2-c2a447bb44f3\n",
            "To: /content/300_cases.zip\n",
            "100% 12.1G/12.1G [02:11<00:00, 92.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "# https://drive.google.com/file/d/1-YzI7y-ZbZlcGgzRP6Ont_A32ayMUVbj/view?usp=share_link\n",
        "!gdown --id \"1-YzI7y-ZbZlcGgzRP6Ont_A32ayMUVbj\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg3eat1tybHd",
        "outputId": "087a04ae-38dc-4a19-9ff4-0082e5a3c596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/300_cases.zip\n",
            " extracting: /content/kits_data/case_00211/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00211/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00046/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00046/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00434/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00434/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00292/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00292/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00102/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00102/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00121/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00121/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00559/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00559/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00572/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00572/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00417/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00417/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00145/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00145/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00066/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00066/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00547/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00547/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00280/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00280/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00418/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00418/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00442/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00442/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00074/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00074/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00058/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00058/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00166/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00166/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00516/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00516/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00247/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00247/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00182/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00182/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00588/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00588/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00269/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00269/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00021/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00021/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00207/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00207/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00232/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00232/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00462/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00462/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00485/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00485/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00178/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00178/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00406/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00406/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00552/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00552/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00455/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00455/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00160/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00160/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00493/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00493/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00576/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00576/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00000/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00000/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00540/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00540/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00293/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00293/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00139/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00139/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00124/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00124/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00436/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00436/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00475/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00475/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00268/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00268/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00414/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00414/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00466/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00466/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00194/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00194/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00033/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00033/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00524/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00524/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00007/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00007/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00235/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00235/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00068/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00068/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00109/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00109/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00096/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00096/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00556/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00556/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00118/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00118/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00188/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00188/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00218/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00218/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00063/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00063/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00037/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00037/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00506/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00506/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00560/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00560/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00176/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00176/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00221/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00221/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00585/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00585/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00431/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00431/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00206/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00206/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00577/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00577/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00057/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00057/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00195/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00195/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00003/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00003/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00586/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00586/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00451/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00451/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00177/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00177/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00020/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00020/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00413/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00413/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00238/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00238/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00042/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00042/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00541/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00541/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00090/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00090/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00170/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00170/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00053/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00053/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00078/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00078/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00008/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00008/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00108/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00108/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00472/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00472/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00479/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00479/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00065/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00065/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00441/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00441/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00272/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00272/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00454/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00454/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00199/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00199/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00159/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00159/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00482/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00482/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00115/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00115/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00404/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00404/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00503/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00503/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00219/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00219/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00471/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00471/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00461/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00461/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00043/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00043/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00181/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00181/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00439/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00439/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00250/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00250/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00073/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00073/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00574/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00574/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00010/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00010/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00152/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00152/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00164/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00164/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00513/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00513/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00129/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00129/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00264/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00264/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00550/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00550/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00567/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00567/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00290/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00290/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00113/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00113/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00274/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00274/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00209/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00209/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00112/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00112/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00002/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00002/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00465/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00465/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00514/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00514/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00233/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00233/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00535/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00535/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00281/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00281/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00532/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00532/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00095/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00095/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00146/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00146/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00035/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00035/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00120/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00120/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00570/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00570/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00285/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00285/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00409/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00409/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00171/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00171/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00093/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00093/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00024/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00024/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00009/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00009/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00091/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00091/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00477/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00477/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00554/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00554/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00271/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00271/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00143/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00143/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00110/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00110/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00529/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00529/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00273/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00273/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00027/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00027/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00507/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00507/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00212/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00212/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00031/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00031/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00425/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00425/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00291/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00291/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00163/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00163/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00258/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00258/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00573/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00573/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00525/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00525/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00239/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00239/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00501/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00501/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00534/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00534/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00059/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00059/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00015/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00015/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00069/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00069/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00183/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00183/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00071/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00071/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00162/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00162/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00569/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00569/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00231/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00231/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00428/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00428/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00419/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00419/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00400/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00400/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00563/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00563/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00056/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00056/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00401/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00401/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00119/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00119/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00089/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00089/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00165/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00165/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00530/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00530/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00528/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00528/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00517/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00517/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00421/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00421/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00039/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00039/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00440/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00440/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00094/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00094/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00012/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00012/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00476/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00476/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00549/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00549/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00052/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00052/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00469/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00469/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00114/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00114/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00282/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00282/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00252/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00252/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00580/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00580/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00473/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00473/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00001/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00001/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00584/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00584/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00132/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00132/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00150/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00150/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00060/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00060/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00014/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00014/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00453/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00453/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00276/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00276/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00179/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00179/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00076/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00076/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00407/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00407/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00197/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00197/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00025/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00025/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00227/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00227/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00229/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00229/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00426/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00426/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00085/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00085/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00443/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00443/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00064/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00064/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00251/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00251/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00450/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00450/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00127/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00127/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00125/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00125/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00518/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00518/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00213/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00213/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00040/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00040/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00568/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00568/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00136/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00136/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00470/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00470/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00267/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00267/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00288/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00288/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00067/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00067/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00240/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00240/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00104/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00104/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00526/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00526/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00079/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00079/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00511/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00511/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00167/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00167/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00581/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00581/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00097/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00097/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00226/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00226/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00117/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00117/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00180/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00180/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00222/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00222/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00184/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00184/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00223/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00223/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00019/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00019/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00018/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00018/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00017/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00017/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00210/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00210/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00100/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00100/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00087/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00087/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00141/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00141/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00508/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00508/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00262/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00262/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00175/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00175/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00491/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00491/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00260/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00260/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00566/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00566/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00255/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00255/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00415/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00415/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00032/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00032/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00243/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00243/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00433/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00433/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00402/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00402/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00448/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00448/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00432/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00432/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00026/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00026/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00036/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00036/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00512/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00512/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00082/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00082/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00157/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00157/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00041/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00041/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00086/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00086/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00253/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00253/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00565/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00565/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00583/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00583/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00173/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00173/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00287/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00287/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00205/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00205/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00296/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00296/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00106/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00106/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00144/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00144/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00411/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00411/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00061/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00061/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00423/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00423/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00420/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00420/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00538/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00538/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00542/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00542/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00131/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00131/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00427/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00427/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00153/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00153/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00030/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00030/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00174/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00174/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00265/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00265/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00084/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00084/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00548/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00548/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00553/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00553/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00403/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00403/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00478/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00478/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00192/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00192/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00447/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00447/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00187/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00187/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00286/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00286/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00151/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00151/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00533/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00533/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00147/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00147/segmentation.nii.gz  \n",
            " extracting: /content/kits_data/case_00081/imaging.nii.gz  \n",
            " extracting: /content/kits_data/case_00081/segmentation.nii.gz  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/300_cases.zip -d /content/kits_data\n",
        "# !rm -rf /content/kits_data\n",
        "# !unzip 100\\ cases.zip -d /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp-ft4CugTdi"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# import os\n",
        "# import shutil\n",
        "# import numpy as np\n",
        "# import nibabel as nib\n",
        "\n",
        "# def round_labels(input_dir, output_dir):\n",
        "#     # Iterate over files in the input directory\n",
        "#     os.mkdir(output_dir)\n",
        "#     for folder in os.listdir(input_dir):\n",
        "#         if folder[:4]== 'case':\n",
        "#             # if filename.endswith(\".nii.gz\"):\n",
        "#             folderpath = os.path.join(input_dir,   folder)\n",
        "#             os.makedirs(os.path.join(output_dir,folder))\n",
        "#             for filename in os.listdir(folderpath):\n",
        "#                 input_file = os.path.join(input_dir,   folder, filename)\n",
        "#                 output_file = os.path.join(output_dir, folder, filename)\n",
        "#                 if filename == \"segmentation.nii.gz\":\n",
        "#                     # Load the segmentation image\n",
        "#                     img = nib.load(input_file)\n",
        "#                     data = img.get_fdata()\n",
        "#                     # Round the labels\n",
        "#                     rounded_data = np.rint(data).astype(np.uint8)\n",
        "\n",
        "#                     # Save the rounded labels to a new NIfTI file\n",
        "#                     rounded_img = nib.Nifti1Image(rounded_data, img.affine, img.header)\n",
        "#                     nib.save(rounded_img, output_file)\n",
        "#                 else:\n",
        "#                     shutil.copyfile(input_file, output_file)\n",
        "#         else:\n",
        "#             print(\"Didn't enter folder\",folder)\n",
        "\n",
        "\n",
        "# round_labels(\"/content/kits_data_original\", \"/content/kits_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b_62YLDgVr1"
      },
      "outputs": [],
      "source": [
        "# import nibabel as nib\n",
        "# import os\n",
        "\n",
        "\n",
        "# def modify_segmentation_file(seg_file_path):\n",
        "#     # load the image\n",
        "#     img = nib.load(seg_file_path)\n",
        "#     # get the image data\n",
        "#     data = img.get_fdata()\n",
        "#     # change segmentation levels\n",
        "#     # data[data != 2] = 0\n",
        "#     data[data == 2] = 1\n",
        "#     # create the new image\n",
        "#     modified_img = nib.Nifti1Image(data, img.affine, img.header)\n",
        "#     # delete the old file\n",
        "#     os.remove(seg_file_path)\n",
        "#     print(\"Removed \" + seg_file_path)\n",
        "#     # save the image\n",
        "#     nib.save(modified_img, seg_file_path)\n",
        "#     print(\"saved new \" + seg_file_path)\n",
        "\n",
        "\n",
        "# cases_dir = '/content/kits_data'\n",
        "# # Iterate over all folders in cases_dir\n",
        "# for root, dirs, files in os.walk(cases_dir):\n",
        "#     for file in files:\n",
        "#         if file == \"segmentation.nii.gz\":\n",
        "#             seg_file_path = os.path.join(root, file)\n",
        "#             modify_segmentation_file(seg_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKFYyb_fypv9",
        "outputId": "7533d2be-1249-4959-ceb8-aac0987ce78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imaging file for case_00032 moved successfully.\n",
            "Segmentation file for case_00032 moved successfully.\n",
            "Imaging file for case_00223 moved successfully.\n",
            "Segmentation file for case_00223 moved successfully.\n",
            "Imaging file for case_00540 moved successfully.\n",
            "Segmentation file for case_00540 moved successfully.\n",
            "Imaging file for case_00425 moved successfully.\n",
            "Segmentation file for case_00425 moved successfully.\n",
            "Imaging file for case_00581 moved successfully.\n",
            "Segmentation file for case_00581 moved successfully.\n",
            "Imaging file for case_00411 moved successfully.\n",
            "Segmentation file for case_00411 moved successfully.\n",
            "Imaging file for case_00037 moved successfully.\n",
            "Segmentation file for case_00037 moved successfully.\n",
            "Imaging file for case_00231 moved successfully.\n",
            "Segmentation file for case_00231 moved successfully.\n",
            "Imaging file for case_00506 moved successfully.\n",
            "Segmentation file for case_00506 moved successfully.\n",
            "Imaging file for case_00427 moved successfully.\n",
            "Segmentation file for case_00427 moved successfully.\n",
            "Imaging file for case_00517 moved successfully.\n",
            "Segmentation file for case_00517 moved successfully.\n",
            "Imaging file for case_00418 moved successfully.\n",
            "Segmentation file for case_00418 moved successfully.\n",
            "Imaging file for case_00572 moved successfully.\n",
            "Segmentation file for case_00572 moved successfully.\n",
            "Imaging file for case_00036 moved successfully.\n",
            "Segmentation file for case_00036 moved successfully.\n",
            "Imaging file for case_00183 moved successfully.\n",
            "Segmentation file for case_00183 moved successfully.\n",
            "Imaging file for case_00188 moved successfully.\n",
            "Segmentation file for case_00188 moved successfully.\n",
            "Imaging file for case_00053 moved successfully.\n",
            "Segmentation file for case_00053 moved successfully.\n",
            "Imaging file for case_00265 moved successfully.\n",
            "Segmentation file for case_00265 moved successfully.\n",
            "Imaging file for case_00285 moved successfully.\n",
            "Segmentation file for case_00285 moved successfully.\n",
            "Imaging file for case_00584 moved successfully.\n",
            "Segmentation file for case_00584 moved successfully.\n",
            "Imaging file for case_00222 moved successfully.\n",
            "Segmentation file for case_00222 moved successfully.\n",
            "Imaging file for case_00073 moved successfully.\n",
            "Segmentation file for case_00073 moved successfully.\n",
            "Imaging file for case_00280 moved successfully.\n",
            "Segmentation file for case_00280 moved successfully.\n",
            "Imaging file for case_00093 moved successfully.\n",
            "Segmentation file for case_00093 moved successfully.\n",
            "Imaging file for case_00197 moved successfully.\n",
            "Segmentation file for case_00197 moved successfully.\n",
            "Imaging file for case_00003 moved successfully.\n",
            "Segmentation file for case_00003 moved successfully.\n",
            "Imaging file for case_00250 moved successfully.\n",
            "Segmentation file for case_00250 moved successfully.\n",
            "Imaging file for case_00287 moved successfully.\n",
            "Segmentation file for case_00287 moved successfully.\n",
            "Imaging file for case_00403 moved successfully.\n",
            "Segmentation file for case_00403 moved successfully.\n",
            "Imaging file for case_00560 moved successfully.\n",
            "Segmentation file for case_00560 moved successfully.\n",
            "Imaging file for case_00269 moved successfully.\n",
            "Segmentation file for case_00269 moved successfully.\n",
            "Imaging file for case_00262 moved successfully.\n",
            "Segmentation file for case_00262 moved successfully.\n",
            "Imaging file for case_00081 moved successfully.\n",
            "Segmentation file for case_00081 moved successfully.\n",
            "Imaging file for case_00144 moved successfully.\n",
            "Segmentation file for case_00144 moved successfully.\n",
            "Imaging file for case_00550 moved successfully.\n",
            "Segmentation file for case_00550 moved successfully.\n",
            "Imaging file for case_00199 moved successfully.\n",
            "Segmentation file for case_00199 moved successfully.\n",
            "Imaging file for case_00181 moved successfully.\n",
            "Segmentation file for case_00181 moved successfully.\n",
            "Imaging file for case_00529 moved successfully.\n",
            "Segmentation file for case_00529 moved successfully.\n",
            "Imaging file for case_00095 moved successfully.\n",
            "Segmentation file for case_00095 moved successfully.\n",
            "Imaging file for case_00127 moved successfully.\n",
            "Segmentation file for case_00127 moved successfully.\n",
            "Imaging file for case_00100 moved successfully.\n",
            "Segmentation file for case_00100 moved successfully.\n",
            "Imaging file for case_00113 moved successfully.\n",
            "Segmentation file for case_00113 moved successfully.\n",
            "Imaging file for case_00218 moved successfully.\n",
            "Segmentation file for case_00218 moved successfully.\n",
            "Imaging file for case_00209 moved successfully.\n",
            "Segmentation file for case_00209 moved successfully.\n",
            "Imaging file for case_00553 moved successfully.\n",
            "Segmentation file for case_00553 moved successfully.\n",
            "Imaging file for case_00178 moved successfully.\n",
            "Segmentation file for case_00178 moved successfully.\n",
            "Imaging file for case_00585 moved successfully.\n",
            "Segmentation file for case_00585 moved successfully.\n",
            "Imaging file for case_00472 moved successfully.\n",
            "Segmentation file for case_00472 moved successfully.\n",
            "Imaging file for case_00110 moved successfully.\n",
            "Segmentation file for case_00110 moved successfully.\n",
            "Imaging file for case_00239 moved successfully.\n",
            "Segmentation file for case_00239 moved successfully.\n",
            "Imaging file for case_00141 moved successfully.\n",
            "Segmentation file for case_00141 moved successfully.\n",
            "Imaging file for case_00547 moved successfully.\n",
            "Segmentation file for case_00547 moved successfully.\n",
            "Imaging file for case_00171 moved successfully.\n",
            "Segmentation file for case_00171 moved successfully.\n",
            "Imaging file for case_00439 moved successfully.\n",
            "Segmentation file for case_00439 moved successfully.\n",
            "Imaging file for case_00164 moved successfully.\n",
            "Segmentation file for case_00164 moved successfully.\n",
            "Imaging file for case_00417 moved successfully.\n",
            "Segmentation file for case_00417 moved successfully.\n",
            "Imaging file for case_00476 moved successfully.\n",
            "Segmentation file for case_00476 moved successfully.\n",
            "Imaging file for case_00407 moved successfully.\n",
            "Segmentation file for case_00407 moved successfully.\n",
            "Imaging file for case_00542 moved successfully.\n",
            "Segmentation file for case_00542 moved successfully.\n",
            "Imaging file for case_00260 moved successfully.\n",
            "Segmentation file for case_00260 moved successfully.\n",
            "Imaging file for case_00121 moved successfully.\n",
            "Segmentation file for case_00121 moved successfully.\n",
            "Imaging file for case_00192 moved successfully.\n",
            "Segmentation file for case_00192 moved successfully.\n",
            "Imaging file for case_00473 moved successfully.\n",
            "Segmentation file for case_00473 moved successfully.\n",
            "Imaging file for case_00404 moved successfully.\n",
            "Segmentation file for case_00404 moved successfully.\n",
            "Imaging file for case_00255 moved successfully.\n",
            "Segmentation file for case_00255 moved successfully.\n",
            "Imaging file for case_00097 moved successfully.\n",
            "Segmentation file for case_00097 moved successfully.\n",
            "Imaging file for case_00021 moved successfully.\n",
            "Segmentation file for case_00021 moved successfully.\n",
            "Imaging file for case_00030 moved successfully.\n",
            "Segmentation file for case_00030 moved successfully.\n",
            "Imaging file for case_00501 moved successfully.\n",
            "Segmentation file for case_00501 moved successfully.\n",
            "Imaging file for case_00414 moved successfully.\n",
            "Segmentation file for case_00414 moved successfully.\n",
            "Imaging file for case_00040 moved successfully.\n",
            "Segmentation file for case_00040 moved successfully.\n",
            "Imaging file for case_00176 moved successfully.\n",
            "Segmentation file for case_00176 moved successfully.\n",
            "Imaging file for case_00415 moved successfully.\n",
            "Segmentation file for case_00415 moved successfully.\n",
            "Imaging file for case_00131 moved successfully.\n",
            "Segmentation file for case_00131 moved successfully.\n",
            "Imaging file for case_00406 moved successfully.\n",
            "Segmentation file for case_00406 moved successfully.\n",
            "Imaging file for case_00136 moved successfully.\n",
            "Segmentation file for case_00136 moved successfully.\n",
            "Imaging file for case_00001 moved successfully.\n",
            "Segmentation file for case_00001 moved successfully.\n",
            "Imaging file for case_00271 moved successfully.\n",
            "Segmentation file for case_00271 moved successfully.\n",
            "Imaging file for case_00431 moved successfully.\n",
            "Segmentation file for case_00431 moved successfully.\n",
            "Imaging file for case_00019 moved successfully.\n",
            "Segmentation file for case_00019 moved successfully.\n",
            "Imaging file for case_00532 moved successfully.\n",
            "Segmentation file for case_00532 moved successfully.\n",
            "Imaging file for case_00165 moved successfully.\n",
            "Segmentation file for case_00165 moved successfully.\n",
            "Imaging file for case_00448 moved successfully.\n",
            "Segmentation file for case_00448 moved successfully.\n",
            "Imaging file for case_00117 moved successfully.\n",
            "Segmentation file for case_00117 moved successfully.\n",
            "Imaging file for case_00491 moved successfully.\n",
            "Segmentation file for case_00491 moved successfully.\n",
            "Imaging file for case_00052 moved successfully.\n",
            "Segmentation file for case_00052 moved successfully.\n",
            "Imaging file for case_00251 moved successfully.\n",
            "Segmentation file for case_00251 moved successfully.\n",
            "Imaging file for case_00120 moved successfully.\n",
            "Segmentation file for case_00120 moved successfully.\n",
            "Imaging file for case_00074 moved successfully.\n",
            "Segmentation file for case_00074 moved successfully.\n",
            "Imaging file for case_00114 moved successfully.\n",
            "Segmentation file for case_00114 moved successfully.\n",
            "Imaging file for case_00556 moved successfully.\n",
            "Segmentation file for case_00556 moved successfully.\n",
            "Imaging file for case_00025 moved successfully.\n",
            "Segmentation file for case_00025 moved successfully.\n",
            "Imaging file for case_00150 moved successfully.\n",
            "Segmentation file for case_00150 moved successfully.\n",
            "Imaging file for case_00541 moved successfully.\n",
            "Segmentation file for case_00541 moved successfully.\n",
            "Imaging file for case_00554 moved successfully.\n",
            "Segmentation file for case_00554 moved successfully.\n",
            "Imaging file for case_00455 moved successfully.\n",
            "Segmentation file for case_00455 moved successfully.\n",
            "Imaging file for case_00170 moved successfully.\n",
            "Segmentation file for case_00170 moved successfully.\n",
            "Imaging file for case_00413 moved successfully.\n",
            "Segmentation file for case_00413 moved successfully.\n",
            "Imaging file for case_00096 moved successfully.\n",
            "Segmentation file for case_00096 moved successfully.\n",
            "Imaging file for case_00563 moved successfully.\n",
            "Segmentation file for case_00563 moved successfully.\n",
            "Imaging file for case_00173 moved successfully.\n",
            "Segmentation file for case_00173 moved successfully.\n",
            "Imaging file for case_00466 moved successfully.\n",
            "Segmentation file for case_00466 moved successfully.\n",
            "Imaging file for case_00485 moved successfully.\n",
            "Segmentation file for case_00485 moved successfully.\n",
            "Imaging file for case_00292 moved successfully.\n",
            "Segmentation file for case_00292 moved successfully.\n",
            "Imaging file for case_00286 moved successfully.\n",
            "Segmentation file for case_00286 moved successfully.\n",
            "Imaging file for case_00071 moved successfully.\n",
            "Segmentation file for case_00071 moved successfully.\n",
            "Imaging file for case_00276 moved successfully.\n",
            "Segmentation file for case_00276 moved successfully.\n",
            "Imaging file for case_00421 moved successfully.\n",
            "Segmentation file for case_00421 moved successfully.\n",
            "Imaging file for case_00559 moved successfully.\n",
            "Segmentation file for case_00559 moved successfully.\n",
            "Imaging file for case_00065 moved successfully.\n",
            "Segmentation file for case_00065 moved successfully.\n",
            "Imaging file for case_00549 moved successfully.\n",
            "Segmentation file for case_00549 moved successfully.\n",
            "Imaging file for case_00524 moved successfully.\n",
            "Segmentation file for case_00524 moved successfully.\n",
            "Imaging file for case_00513 moved successfully.\n",
            "Segmentation file for case_00513 moved successfully.\n",
            "Imaging file for case_00059 moved successfully.\n",
            "Segmentation file for case_00059 moved successfully.\n",
            "Imaging file for case_00205 moved successfully.\n",
            "Segmentation file for case_00205 moved successfully.\n",
            "Imaging file for case_00010 moved successfully.\n",
            "Segmentation file for case_00010 moved successfully.\n",
            "Imaging file for case_00056 moved successfully.\n",
            "Segmentation file for case_00056 moved successfully.\n",
            "Imaging file for case_00548 moved successfully.\n",
            "Segmentation file for case_00548 moved successfully.\n",
            "Imaging file for case_00238 moved successfully.\n",
            "Segmentation file for case_00238 moved successfully.\n",
            "Imaging file for case_00229 moved successfully.\n",
            "Segmentation file for case_00229 moved successfully.\n",
            "Imaging file for case_00082 moved successfully.\n",
            "Segmentation file for case_00082 moved successfully.\n",
            "Imaging file for case_00160 moved successfully.\n",
            "Segmentation file for case_00160 moved successfully.\n",
            "Imaging file for case_00000 moved successfully.\n",
            "Segmentation file for case_00000 moved successfully.\n",
            "Imaging file for case_00112 moved successfully.\n",
            "Segmentation file for case_00112 moved successfully.\n",
            "Imaging file for case_00477 moved successfully.\n",
            "Segmentation file for case_00477 moved successfully.\n",
            "Imaging file for case_00552 moved successfully.\n",
            "Segmentation file for case_00552 moved successfully.\n",
            "Imaging file for case_00219 moved successfully.\n",
            "Segmentation file for case_00219 moved successfully.\n",
            "Imaging file for case_00433 moved successfully.\n",
            "Segmentation file for case_00433 moved successfully.\n",
            "Imaging file for case_00290 moved successfully.\n",
            "Segmentation file for case_00290 moved successfully.\n",
            "Imaging file for case_00106 moved successfully.\n",
            "Segmentation file for case_00106 moved successfully.\n",
            "Imaging file for case_00401 moved successfully.\n",
            "Segmentation file for case_00401 moved successfully.\n",
            "Imaging file for case_00567 moved successfully.\n",
            "Segmentation file for case_00567 moved successfully.\n",
            "Imaging file for case_00132 moved successfully.\n",
            "Segmentation file for case_00132 moved successfully.\n",
            "Imaging file for case_00570 moved successfully.\n",
            "Segmentation file for case_00570 moved successfully.\n",
            "Imaging file for case_00043 moved successfully.\n",
            "Segmentation file for case_00043 moved successfully.\n",
            "Imaging file for case_00012 moved successfully.\n",
            "Segmentation file for case_00012 moved successfully.\n",
            "Imaging file for case_00296 moved successfully.\n",
            "Segmentation file for case_00296 moved successfully.\n",
            "Imaging file for case_00063 moved successfully.\n",
            "Segmentation file for case_00063 moved successfully.\n",
            "Imaging file for case_00442 moved successfully.\n",
            "Segmentation file for case_00442 moved successfully.\n",
            "Imaging file for case_00226 moved successfully.\n",
            "Segmentation file for case_00226 moved successfully.\n",
            "Imaging file for case_00258 moved successfully.\n",
            "Segmentation file for case_00258 moved successfully.\n",
            "Imaging file for case_00227 moved successfully.\n",
            "Segmentation file for case_00227 moved successfully.\n",
            "Imaging file for case_00243 moved successfully.\n",
            "Segmentation file for case_00243 moved successfully.\n",
            "Imaging file for case_00469 moved successfully.\n",
            "Segmentation file for case_00469 moved successfully.\n",
            "Imaging file for case_00588 moved successfully.\n",
            "Segmentation file for case_00588 moved successfully.\n",
            "Imaging file for case_00057 moved successfully.\n",
            "Segmentation file for case_00057 moved successfully.\n",
            "Imaging file for case_00084 moved successfully.\n",
            "Segmentation file for case_00084 moved successfully.\n",
            "Imaging file for case_00207 moved successfully.\n",
            "Segmentation file for case_00207 moved successfully.\n",
            "Imaging file for case_00079 moved successfully.\n",
            "Segmentation file for case_00079 moved successfully.\n",
            "Imaging file for case_00195 moved successfully.\n",
            "Segmentation file for case_00195 moved successfully.\n",
            "Imaging file for case_00042 moved successfully.\n",
            "Segmentation file for case_00042 moved successfully.\n",
            "Imaging file for case_00267 moved successfully.\n",
            "Segmentation file for case_00267 moved successfully.\n",
            "Imaging file for case_00031 moved successfully.\n",
            "Segmentation file for case_00031 moved successfully.\n",
            "Imaging file for case_00102 moved successfully.\n",
            "Segmentation file for case_00102 moved successfully.\n",
            "Imaging file for case_00014 moved successfully.\n",
            "Segmentation file for case_00014 moved successfully.\n",
            "Imaging file for case_00067 moved successfully.\n",
            "Segmentation file for case_00067 moved successfully.\n",
            "Imaging file for case_00586 moved successfully.\n",
            "Segmentation file for case_00586 moved successfully.\n",
            "Imaging file for case_00068 moved successfully.\n",
            "Segmentation file for case_00068 moved successfully.\n",
            "Imaging file for case_00420 moved successfully.\n",
            "Segmentation file for case_00420 moved successfully.\n",
            "Imaging file for case_00184 moved successfully.\n",
            "Segmentation file for case_00184 moved successfully.\n",
            "Imaging file for case_00428 moved successfully.\n",
            "Segmentation file for case_00428 moved successfully.\n",
            "Imaging file for case_00210 moved successfully.\n",
            "Segmentation file for case_00210 moved successfully.\n",
            "Imaging file for case_00434 moved successfully.\n",
            "Segmentation file for case_00434 moved successfully.\n",
            "Imaging file for case_00574 moved successfully.\n",
            "Segmentation file for case_00574 moved successfully.\n",
            "Imaging file for case_00177 moved successfully.\n",
            "Segmentation file for case_00177 moved successfully.\n",
            "Imaging file for case_00247 moved successfully.\n",
            "Segmentation file for case_00247 moved successfully.\n",
            "Imaging file for case_00440 moved successfully.\n",
            "Segmentation file for case_00440 moved successfully.\n",
            "Imaging file for case_00069 moved successfully.\n",
            "Segmentation file for case_00069 moved successfully.\n",
            "Imaging file for case_00078 moved successfully.\n",
            "Segmentation file for case_00078 moved successfully.\n",
            "Imaging file for case_00089 moved successfully.\n",
            "Segmentation file for case_00089 moved successfully.\n",
            "Imaging file for case_00041 moved successfully.\n",
            "Segmentation file for case_00041 moved successfully.\n",
            "Imaging file for case_00419 moved successfully.\n",
            "Segmentation file for case_00419 moved successfully.\n",
            "Imaging file for case_00530 moved successfully.\n",
            "Segmentation file for case_00530 moved successfully.\n",
            "Imaging file for case_00454 moved successfully.\n",
            "Segmentation file for case_00454 moved successfully.\n",
            "Imaging file for case_00024 moved successfully.\n",
            "Segmentation file for case_00024 moved successfully.\n",
            "Imaging file for case_00443 moved successfully.\n",
            "Segmentation file for case_00443 moved successfully.\n",
            "Imaging file for case_00145 moved successfully.\n",
            "Segmentation file for case_00145 moved successfully.\n",
            "Imaging file for case_00129 moved successfully.\n",
            "Segmentation file for case_00129 moved successfully.\n",
            "Imaging file for case_00027 moved successfully.\n",
            "Segmentation file for case_00027 moved successfully.\n",
            "Imaging file for case_00194 moved successfully.\n",
            "Segmentation file for case_00194 moved successfully.\n",
            "Imaging file for case_00125 moved successfully.\n",
            "Segmentation file for case_00125 moved successfully.\n",
            "Imaging file for case_00182 moved successfully.\n",
            "Segmentation file for case_00182 moved successfully.\n",
            "Imaging file for case_00461 moved successfully.\n",
            "Segmentation file for case_00461 moved successfully.\n",
            "Imaging file for case_00076 moved successfully.\n",
            "Segmentation file for case_00076 moved successfully.\n",
            "Imaging file for case_00240 moved successfully.\n",
            "Segmentation file for case_00240 moved successfully.\n",
            "Imaging file for case_00018 moved successfully.\n",
            "Segmentation file for case_00018 moved successfully.\n",
            "Imaging file for case_00091 moved successfully.\n",
            "Segmentation file for case_00091 moved successfully.\n",
            "Imaging file for case_00568 moved successfully.\n",
            "Segmentation file for case_00568 moved successfully.\n",
            "Imaging file for case_00008 moved successfully.\n",
            "Segmentation file for case_00008 moved successfully.\n",
            "Imaging file for case_00020 moved successfully.\n",
            "Segmentation file for case_00020 moved successfully.\n",
            "Imaging file for case_00147 moved successfully.\n",
            "Segmentation file for case_00147 moved successfully.\n",
            "Imaging file for case_00143 moved successfully.\n",
            "Segmentation file for case_00143 moved successfully.\n",
            "Imaging file for case_00017 moved successfully.\n",
            "Segmentation file for case_00017 moved successfully.\n",
            "Imaging file for case_00087 moved successfully.\n",
            "Segmentation file for case_00087 moved successfully.\n",
            "Imaging file for case_00426 moved successfully.\n",
            "Segmentation file for case_00426 moved successfully.\n",
            "Imaging file for case_00232 moved successfully.\n",
            "Segmentation file for case_00232 moved successfully.\n",
            "Imaging file for case_00451 moved successfully.\n",
            "Segmentation file for case_00451 moved successfully.\n",
            "Imaging file for case_00009 moved successfully.\n",
            "Segmentation file for case_00009 moved successfully.\n",
            "Imaging file for case_00465 moved successfully.\n",
            "Segmentation file for case_00465 moved successfully.\n",
            "Imaging file for case_00007 moved successfully.\n",
            "Segmentation file for case_00007 moved successfully.\n",
            "Imaging file for case_00159 moved successfully.\n",
            "Segmentation file for case_00159 moved successfully.\n",
            "Imaging file for case_00268 moved successfully.\n",
            "Segmentation file for case_00268 moved successfully.\n",
            "Imaging file for case_00152 moved successfully.\n",
            "Segmentation file for case_00152 moved successfully.\n",
            "Imaging file for case_00264 moved successfully.\n",
            "Segmentation file for case_00264 moved successfully.\n",
            "Imaging file for case_00235 moved successfully.\n",
            "Segmentation file for case_00235 moved successfully.\n",
            "Imaging file for case_00174 moved successfully.\n",
            "Segmentation file for case_00174 moved successfully.\n",
            "Imaging file for case_00002 moved successfully.\n",
            "Segmentation file for case_00002 moved successfully.\n",
            "Imaging file for case_00253 moved successfully.\n",
            "Segmentation file for case_00253 moved successfully.\n",
            "Imaging file for case_00157 moved successfully.\n",
            "Segmentation file for case_00157 moved successfully.\n",
            "Imaging file for case_00151 moved successfully.\n",
            "Segmentation file for case_00151 moved successfully.\n",
            "Imaging file for case_00441 moved successfully.\n",
            "Segmentation file for case_00441 moved successfully.\n",
            "Imaging file for case_00447 moved successfully.\n",
            "Segmentation file for case_00447 moved successfully.\n",
            "Imaging file for case_00516 moved successfully.\n",
            "Segmentation file for case_00516 moved successfully.\n",
            "Imaging file for case_00061 moved successfully.\n",
            "Segmentation file for case_00061 moved successfully.\n",
            "Imaging file for case_00503 moved successfully.\n",
            "Segmentation file for case_00503 moved successfully.\n",
            "Imaging file for case_00423 moved successfully.\n",
            "Segmentation file for case_00423 moved successfully.\n",
            "Imaging file for case_00064 moved successfully.\n",
            "Segmentation file for case_00064 moved successfully.\n",
            "Imaging file for case_00402 moved successfully.\n",
            "Segmentation file for case_00402 moved successfully.\n",
            "Imaging file for case_00281 moved successfully.\n",
            "Segmentation file for case_00281 moved successfully.\n",
            "Imaging file for case_00525 moved successfully.\n",
            "Segmentation file for case_00525 moved successfully.\n",
            "Imaging file for case_00104 moved successfully.\n",
            "Segmentation file for case_00104 moved successfully.\n",
            "Imaging file for case_00282 moved successfully.\n",
            "Segmentation file for case_00282 moved successfully.\n",
            "Imaging file for case_00288 moved successfully.\n",
            "Segmentation file for case_00288 moved successfully.\n",
            "Imaging file for case_00139 moved successfully.\n",
            "Segmentation file for case_00139 moved successfully.\n",
            "Imaging file for case_00566 moved successfully.\n",
            "Segmentation file for case_00566 moved successfully.\n",
            "Imaging file for case_00118 moved successfully.\n",
            "Segmentation file for case_00118 moved successfully.\n",
            "Imaging file for case_00475 moved successfully.\n",
            "Segmentation file for case_00475 moved successfully.\n",
            "Imaging file for case_00512 moved successfully.\n",
            "Segmentation file for case_00512 moved successfully.\n",
            "Imaging file for case_00187 moved successfully.\n",
            "Segmentation file for case_00187 moved successfully.\n",
            "Imaging file for case_00162 moved successfully.\n",
            "Segmentation file for case_00162 moved successfully.\n",
            "Imaging file for case_00573 moved successfully.\n",
            "Segmentation file for case_00573 moved successfully.\n",
            "Imaging file for case_00163 moved successfully.\n",
            "Segmentation file for case_00163 moved successfully.\n",
            "Imaging file for case_00086 moved successfully.\n",
            "Segmentation file for case_00086 moved successfully.\n",
            "Imaging file for case_00528 moved successfully.\n",
            "Segmentation file for case_00528 moved successfully.\n",
            "Imaging file for case_00058 moved successfully.\n",
            "Segmentation file for case_00058 moved successfully.\n",
            "Imaging file for case_00577 moved successfully.\n",
            "Segmentation file for case_00577 moved successfully.\n",
            "Imaging file for case_00206 moved successfully.\n",
            "Segmentation file for case_00206 moved successfully.\n",
            "Imaging file for case_00108 moved successfully.\n",
            "Segmentation file for case_00108 moved successfully.\n",
            "Imaging file for case_00180 moved successfully.\n",
            "Segmentation file for case_00180 moved successfully.\n",
            "Imaging file for case_00094 moved successfully.\n",
            "Segmentation file for case_00094 moved successfully.\n",
            "Imaging file for case_00212 moved successfully.\n",
            "Segmentation file for case_00212 moved successfully.\n",
            "Imaging file for case_00146 moved successfully.\n",
            "Segmentation file for case_00146 moved successfully.\n",
            "Imaging file for case_00450 moved successfully.\n",
            "Segmentation file for case_00450 moved successfully.\n",
            "Imaging file for case_00039 moved successfully.\n",
            "Segmentation file for case_00039 moved successfully.\n",
            "Imaging file for case_00514 moved successfully.\n",
            "Segmentation file for case_00514 moved successfully.\n",
            "Imaging file for case_00580 moved successfully.\n",
            "Segmentation file for case_00580 moved successfully.\n",
            "Imaging file for case_00153 moved successfully.\n",
            "Segmentation file for case_00153 moved successfully.\n",
            "Imaging file for case_00478 moved successfully.\n",
            "Segmentation file for case_00478 moved successfully.\n",
            "Imaging file for case_00179 moved successfully.\n",
            "Segmentation file for case_00179 moved successfully.\n",
            "Imaging file for case_00538 moved successfully.\n",
            "Segmentation file for case_00538 moved successfully.\n",
            "Imaging file for case_00479 moved successfully.\n",
            "Segmentation file for case_00479 moved successfully.\n",
            "Imaging file for case_00471 moved successfully.\n",
            "Segmentation file for case_00471 moved successfully.\n",
            "Imaging file for case_00470 moved successfully.\n",
            "Segmentation file for case_00470 moved successfully.\n",
            "Imaging file for case_00233 moved successfully.\n",
            "Segmentation file for case_00233 moved successfully.\n",
            "Imaging file for case_00409 moved successfully.\n",
            "Segmentation file for case_00409 moved successfully.\n",
            "Imaging file for case_00066 moved successfully.\n",
            "Segmentation file for case_00066 moved successfully.\n",
            "Imaging file for case_00507 moved successfully.\n",
            "Segmentation file for case_00507 moved successfully.\n",
            "Imaging file for case_00119 moved successfully.\n",
            "Segmentation file for case_00119 moved successfully.\n",
            "Imaging file for case_00124 moved successfully.\n",
            "Segmentation file for case_00124 moved successfully.\n",
            "Imaging file for case_00252 moved successfully.\n",
            "Segmentation file for case_00252 moved successfully.\n",
            "Imaging file for case_00526 moved successfully.\n",
            "Segmentation file for case_00526 moved successfully.\n",
            "Imaging file for case_00175 moved successfully.\n",
            "Segmentation file for case_00175 moved successfully.\n",
            "Imaging file for case_00274 moved successfully.\n",
            "Segmentation file for case_00274 moved successfully.\n",
            "Imaging file for case_00293 moved successfully.\n",
            "Segmentation file for case_00293 moved successfully.\n",
            "Imaging file for case_00213 moved successfully.\n",
            "Segmentation file for case_00213 moved successfully.\n",
            "Imaging file for case_00576 moved successfully.\n",
            "Segmentation file for case_00576 moved successfully.\n",
            "Imaging file for case_00015 moved successfully.\n",
            "Segmentation file for case_00015 moved successfully.\n",
            "Imaging file for case_00565 moved successfully.\n",
            "Segmentation file for case_00565 moved successfully.\n",
            "Imaging file for case_00046 moved successfully.\n",
            "Segmentation file for case_00046 moved successfully.\n",
            "Imaging file for case_00166 moved successfully.\n",
            "Segmentation file for case_00166 moved successfully.\n",
            "Imaging file for case_00033 moved successfully.\n",
            "Segmentation file for case_00033 moved successfully.\n",
            "Imaging file for case_00583 moved successfully.\n",
            "Segmentation file for case_00583 moved successfully.\n",
            "Imaging file for case_00569 moved successfully.\n",
            "Segmentation file for case_00569 moved successfully.\n",
            "Imaging file for case_00090 moved successfully.\n",
            "Segmentation file for case_00090 moved successfully.\n",
            "Imaging file for case_00115 moved successfully.\n",
            "Segmentation file for case_00115 moved successfully.\n",
            "Imaging file for case_00453 moved successfully.\n",
            "Segmentation file for case_00453 moved successfully.\n",
            "Imaging file for case_00482 moved successfully.\n",
            "Segmentation file for case_00482 moved successfully.\n",
            "Imaging file for case_00060 moved successfully.\n",
            "Segmentation file for case_00060 moved successfully.\n",
            "Imaging file for case_00436 moved successfully.\n",
            "Segmentation file for case_00436 moved successfully.\n",
            "Imaging file for case_00533 moved successfully.\n",
            "Segmentation file for case_00533 moved successfully.\n",
            "Imaging file for case_00511 moved successfully.\n",
            "Segmentation file for case_00511 moved successfully.\n",
            "Imaging file for case_00400 moved successfully.\n",
            "Segmentation file for case_00400 moved successfully.\n",
            "Imaging file for case_00518 moved successfully.\n",
            "Segmentation file for case_00518 moved successfully.\n",
            "Imaging file for case_00211 moved successfully.\n",
            "Segmentation file for case_00211 moved successfully.\n",
            "Imaging file for case_00272 moved successfully.\n",
            "Segmentation file for case_00272 moved successfully.\n",
            "Imaging file for case_00462 moved successfully.\n",
            "Segmentation file for case_00462 moved successfully.\n",
            "Imaging file for case_00534 moved successfully.\n",
            "Segmentation file for case_00534 moved successfully.\n",
            "Imaging file for case_00535 moved successfully.\n",
            "Segmentation file for case_00535 moved successfully.\n",
            "Imaging file for case_00026 moved successfully.\n",
            "Segmentation file for case_00026 moved successfully.\n",
            "Imaging file for case_00273 moved successfully.\n",
            "Segmentation file for case_00273 moved successfully.\n",
            "Imaging file for case_00221 moved successfully.\n",
            "Segmentation file for case_00221 moved successfully.\n",
            "Imaging file for case_00035 moved successfully.\n",
            "Segmentation file for case_00035 moved successfully.\n",
            "Imaging file for case_00085 moved successfully.\n",
            "Segmentation file for case_00085 moved successfully.\n",
            "Imaging file for case_00291 moved successfully.\n",
            "Segmentation file for case_00291 moved successfully.\n",
            "Imaging file for case_00109 moved successfully.\n",
            "Segmentation file for case_00109 moved successfully.\n",
            "Imaging file for case_00167 moved successfully.\n",
            "Segmentation file for case_00167 moved successfully.\n",
            "Imaging file for case_00432 moved successfully.\n",
            "Segmentation file for case_00432 moved successfully.\n",
            "Imaging file for case_00493 moved successfully.\n",
            "Segmentation file for case_00493 moved successfully.\n",
            "Imaging file for case_00508 moved successfully.\n",
            "Segmentation file for case_00508 moved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths to the source and destination folders\n",
        "# source_folder = \"/content/50 cases\"\n",
        "source_folder = \"/content/kits_data\"\n",
        "destination_train_folder = \"/content/nnUNet_raw/Dataset007_Kidney/imagesTr\"\n",
        "destination_test_folder = \"/content/nnUNet_raw/Dataset007_Kidney/labelsTr\"\n",
        "\n",
        "# Create destination folders if they don't exist\n",
        "os.makedirs(destination_train_folder, exist_ok=True)\n",
        "os.makedirs(destination_test_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through each folder in the source directory\n",
        "for case_folder in os.listdir(source_folder):\n",
        "    case_folder_path = os.path.join(source_folder, case_folder)\n",
        "\n",
        "    # Check if the item in the source folder is a directory\n",
        "    if os.path.isdir(case_folder_path):\n",
        "        # Find the imaging.nii.gz and segmentation.nii.gz files\n",
        "        imaging_file = os.path.join(case_folder_path, \"imaging.nii.gz\")\n",
        "        segmentation_file = os.path.join(case_folder_path, \"segmentation.nii.gz\")\n",
        "\n",
        "        # Check if both files exist\n",
        "        if os.path.exists(imaging_file) and os.path.exists(segmentation_file):\n",
        "            # Rename and move the imaging file to the training folder\n",
        "            new_imaging_file = os.path.join(destination_train_folder, f\"{case_folder}_0000.nii.gz\")\n",
        "            try:\n",
        "                shutil.move(imaging_file, new_imaging_file)\n",
        "                print(f\"Imaging file for {case_folder} moved successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Imaging file not found for {case_folder}. Skipping...\")\n",
        "\n",
        "            # Rename and move the segmentation file to the testing folder\n",
        "            new_segmentation_file = os.path.join(destination_test_folder, f\"{case_folder}.nii.gz\")\n",
        "            try:\n",
        "                shutil.move(segmentation_file, new_segmentation_file)\n",
        "                print(f\"Segmentation file for {case_folder} moved successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Segmentation file not found for {case_folder}. Skipping...\")\n",
        "        else:\n",
        "            print(f\"Files not found in {case_folder}. Skipping...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-WAYHlW4zry"
      },
      "source": [
        "Needed to redunce the number of workers for colab free. (`-np 4`. The default is 4 or 8 depending on the subtask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C-SsTqE7mQW",
        "outputId": "7a1d9902-8f82-44b0-ebbc-5e4791e45b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON file saved to: /content/nnUNet_raw/Dataset007_Kidney/dataset.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Define the dataset information\n",
        "dataset_info = {\n",
        "    \"channel_names\": {\n",
        "        \"0\": \"CT\"\n",
        "    },\n",
        "    \"labels\": {\n",
        "        \"background\": 0,\n",
        "        \"kidney\": [1, 2, 3],\n",
        "        # \"masses\": [2, 3],\n",
        "        \"tumor\": 1\n",
        "    },\n",
        "    \"numTraining\": 299,\n",
        "    \"file_ending\": \".nii.gz\",\n",
        "    \"overwrite_image_reader_writer\": \"NibabelIOWithReorient\",\n",
        "    # \"regions_class_order\": [1, 3, 2]\n",
        "    \"regions_class_order\": [1, 2]\n",
        "}\n",
        "\n",
        "# Define the file path for saving the JSON file\n",
        "output_file = '/content/nnUNet_raw/Dataset007_Kidney/dataset.json'\n",
        "\n",
        "# Write the dataset information to the JSON file\n",
        "with open(output_file, 'w') as json_file:\n",
        "    json.dump(dataset_info, json_file, indent=4)\n",
        "\n",
        "print(f\"JSON file saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-dZFYRlwja-",
        "outputId": "d2dc0cfd-23fa-4940-b93f-6889a119b219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset007_Kidney\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "100% 299/299 [01:26<00:00,  3.45it/s]\n",
            "Experiment planning...\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': array([256, 256]), 'median_image_size_in_voxels': array([256., 256.]), 'spacing': array([1.6156863 , 1.56556368]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': array([ 80, 160, 160]), 'median_image_size_in_voxels': array([114., 256., 256.]), 'spacing': array([3.53769231, 1.6156863 , 1.56556368]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [4, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/nnUNet_preprocessed/Dataset007_Kidney/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset007_Kidney\n",
            "Configuration: 2d...\n",
            "100% 299/299 [17:18<00:00,  3.47s/it]\n",
            "Configuration: 3d_fullres...\n",
            "100% 299/299 [11:52<00:00,  2.38s/it]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset007_Kidney. Skipping.\n"
          ]
        }
      ],
      "source": [
        "! nnUNetv2_plan_and_preprocess -d 07 --verify_dataset_integrity -np 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soQh2a5TiB51",
        "outputId": "714c244b-314d-4dfe-b2fc-60964ed5a6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[64, 64]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/nnUNet_preprocessed/Dataset007_Kidney/nnUNetPlans.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(data[\"configurations\"][\"2d\"]['patch_size'])\n",
        "data[\"configurations\"][\"2d\"]['patch_size'] = [64,64]\n",
        "data[\"configurations\"][\"2d\"]['batch_size'] = 100\n",
        "\n",
        "with open(\"/content/nnUNet_preprocessed/Dataset007_Kidney/nnUNetPlans.json\", \"w\") as f:\n",
        "    json.dump(data, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmirhd2if1h"
      },
      "source": [
        "Train dataset 6, using 2d images, start with fold 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dr9Y-9rL-qO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGyfVokAD2ob",
        "outputId": "1752943b-e3ab-40b9-eed8-0ac073cb50be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 100, 'patch_size': [64, 64], 'median_image_size_in_voxels': [128.0, 128.0], 'spacing': [3.1023621559143066, 3.1434547901153564], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset007_Kidney', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.4928081035614014, 3.1023621559143066, 3.1434547901153564], 'original_median_shape_after_transp': [111, 128, 128], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1222.729248046875, 'mean': 80.02265930175781, 'median': 72.80106353759766, 'min': -108.11952209472656, 'percentile_00_5': -30.959068298339844, 'percentile_99_5': 276.8561706542969, 'std': 57.263057708740234}}} \n",
            "\n",
            "2024-03-12 17:13:36.223258: unpacking dataset...\n",
            "2024-03-12 17:13:44.481088: unpacking done...\n",
            "2024-03-12 17:13:44.482877: do_dummy_2d_data_aug: False\n",
            "2024-03-12 17:13:44.483919: Creating new 5-fold cross-validation split...\n",
            "2024-03-12 17:13:44.485600: Desired fold for training: 2\n",
            "2024-03-12 17:13:44.485679: This split has 80 training and 20 validation cases.\n",
            "2024-03-12 17:13:44.491160: Unable to plot network architecture:\n",
            "2024-03-12 17:13:44.491237: No module named 'hiddenlayer'\n",
            "2024-03-12 17:13:44.516531: \n",
            "2024-03-12 17:13:44.516635: Epoch 0\n",
            "2024-03-12 17:13:44.516743: Current learning rate: 0.01\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-03-12 17:14:11.738730: train_loss -0.065\n",
            "2024-03-12 17:14:11.740192: val_loss -0.3128\n",
            "2024-03-12 17:14:11.740585: Pseudo dice [0.4866]\n",
            "2024-03-12 17:14:11.741574: Epoch time: 27.22 s\n",
            "2024-03-12 17:14:11.741826: Yayy! New best EMA pseudo Dice: 0.4866\n",
            "2024-03-12 17:14:13.358386: \n",
            "2024-03-12 17:14:13.358567: Epoch 1\n",
            "2024-03-12 17:14:13.358694: Current learning rate: 0.00991\n",
            "2024-03-12 17:14:34.229472: train_loss -0.4931\n",
            "2024-03-12 17:14:34.229797: val_loss -0.512\n",
            "2024-03-12 17:14:34.229950: Pseudo dice [0.6231]\n",
            "2024-03-12 17:14:34.230096: Epoch time: 20.87 s\n",
            "2024-03-12 17:14:34.230230: Yayy! New best EMA pseudo Dice: 0.5002\n",
            "2024-03-12 17:14:36.137946: \n",
            "2024-03-12 17:14:36.138270: Epoch 2\n",
            "2024-03-12 17:14:36.138427: Current learning rate: 0.00982\n",
            "2024-03-12 17:14:56.823956: train_loss -0.5925\n",
            "2024-03-12 17:14:56.824385: val_loss -0.5528\n",
            "2024-03-12 17:14:56.824563: Pseudo dice [0.6521]\n",
            "2024-03-12 17:14:56.824890: Epoch time: 20.69 s\n",
            "2024-03-12 17:14:56.825067: Yayy! New best EMA pseudo Dice: 0.5154\n",
            "2024-03-12 17:14:58.801277: \n",
            "2024-03-12 17:14:58.801491: Epoch 3\n",
            "2024-03-12 17:14:58.801647: Current learning rate: 0.00973\n",
            "2024-03-12 17:15:19.554772: train_loss -0.6352\n",
            "2024-03-12 17:15:19.555129: val_loss -0.6078\n",
            "2024-03-12 17:15:19.555310: Pseudo dice [0.694]\n",
            "2024-03-12 17:15:19.555525: Epoch time: 20.75 s\n",
            "2024-03-12 17:15:19.555692: Yayy! New best EMA pseudo Dice: 0.5333\n",
            "2024-03-12 17:15:21.696388: \n",
            "2024-03-12 17:15:21.696596: Epoch 4\n",
            "2024-03-12 17:15:21.696775: Current learning rate: 0.00964\n",
            "2024-03-12 17:15:42.156290: train_loss -0.6606\n",
            "2024-03-12 17:15:42.156762: val_loss -0.609\n",
            "2024-03-12 17:15:42.156981: Pseudo dice [0.7028]\n",
            "2024-03-12 17:15:42.157203: Epoch time: 20.46 s\n",
            "2024-03-12 17:15:42.157407: Yayy! New best EMA pseudo Dice: 0.5502\n",
            "2024-03-12 17:15:44.179066: \n",
            "2024-03-12 17:15:44.179246: Epoch 5\n",
            "2024-03-12 17:15:44.179386: Current learning rate: 0.00955\n",
            "2024-03-12 17:16:04.744160: train_loss -0.6739\n",
            "2024-03-12 17:16:04.744608: val_loss -0.6642\n",
            "2024-03-12 17:16:04.744953: Pseudo dice [0.7571]\n",
            "2024-03-12 17:16:04.745176: Epoch time: 20.57 s\n",
            "2024-03-12 17:16:04.745267: Yayy! New best EMA pseudo Dice: 0.5709\n",
            "2024-03-12 17:16:06.640851: \n",
            "2024-03-12 17:16:06.641130: Epoch 6\n",
            "2024-03-12 17:16:06.641282: Current learning rate: 0.00946\n",
            "2024-03-12 17:16:27.195374: train_loss -0.7085\n",
            "2024-03-12 17:16:27.195624: val_loss -0.6465\n",
            "2024-03-12 17:16:27.195748: Pseudo dice [0.741]\n",
            "2024-03-12 17:16:27.195863: Epoch time: 20.56 s\n",
            "2024-03-12 17:16:27.195964: Yayy! New best EMA pseudo Dice: 0.5879\n",
            "2024-03-12 17:16:29.212855: \n",
            "2024-03-12 17:16:29.213066: Epoch 7\n",
            "2024-03-12 17:16:29.213194: Current learning rate: 0.00937\n",
            "2024-03-12 17:16:49.870727: train_loss -0.7203\n",
            "2024-03-12 17:16:49.871050: val_loss -0.6819\n",
            "2024-03-12 17:16:49.871212: Pseudo dice [0.7645]\n",
            "2024-03-12 17:16:49.871378: Epoch time: 20.66 s\n",
            "2024-03-12 17:16:49.871518: Yayy! New best EMA pseudo Dice: 0.6056\n",
            "2024-03-12 17:16:51.995430: \n",
            "2024-03-12 17:16:51.995680: Epoch 8\n",
            "2024-03-12 17:16:51.995821: Current learning rate: 0.00928\n",
            "2024-03-12 17:17:12.609062: train_loss -0.7405\n",
            "2024-03-12 17:17:12.609376: val_loss -0.7197\n",
            "2024-03-12 17:17:12.609517: Pseudo dice [0.7918]\n",
            "2024-03-12 17:17:12.609636: Epoch time: 20.61 s\n",
            "2024-03-12 17:17:12.609738: Yayy! New best EMA pseudo Dice: 0.6242\n",
            "2024-03-12 17:17:14.549633: \n",
            "2024-03-12 17:17:14.549889: Epoch 9\n",
            "2024-03-12 17:17:14.550034: Current learning rate: 0.00919\n",
            "2024-03-12 17:17:35.446266: train_loss -0.7446\n",
            "2024-03-12 17:17:35.446728: val_loss -0.7059\n",
            "2024-03-12 17:17:35.446863: Pseudo dice [0.7825]\n",
            "2024-03-12 17:17:35.447016: Epoch time: 20.9 s\n",
            "2024-03-12 17:17:35.447295: Yayy! New best EMA pseudo Dice: 0.64\n",
            "2024-03-12 17:17:37.546089: \n",
            "2024-03-12 17:17:37.546367: Epoch 10\n",
            "2024-03-12 17:17:37.546534: Current learning rate: 0.0091\n",
            "2024-03-12 17:17:58.275611: train_loss -0.7586\n",
            "2024-03-12 17:17:58.276004: val_loss -0.6644\n",
            "2024-03-12 17:17:58.276270: Pseudo dice [0.7486]\n",
            "2024-03-12 17:17:58.276524: Epoch time: 20.73 s\n",
            "2024-03-12 17:17:58.276678: Yayy! New best EMA pseudo Dice: 0.6509\n",
            "2024-03-12 17:18:00.316877: \n",
            "2024-03-12 17:18:00.317267: Epoch 11\n",
            "2024-03-12 17:18:00.317463: Current learning rate: 0.009\n",
            "2024-03-12 17:18:20.904810: train_loss -0.7614\n",
            "2024-03-12 17:18:20.905346: val_loss -0.6064\n",
            "2024-03-12 17:18:20.905692: Pseudo dice [0.6979]\n",
            "2024-03-12 17:18:20.906106: Epoch time: 20.59 s\n",
            "2024-03-12 17:18:20.906426: Yayy! New best EMA pseudo Dice: 0.6556\n",
            "2024-03-12 17:18:22.842375: \n",
            "2024-03-12 17:18:22.842640: Epoch 12\n",
            "2024-03-12 17:18:22.842784: Current learning rate: 0.00891\n",
            "2024-03-12 17:18:43.178163: train_loss -0.779\n",
            "2024-03-12 17:18:43.178528: val_loss -0.6624\n",
            "2024-03-12 17:18:43.178700: Pseudo dice [0.7464]\n",
            "2024-03-12 17:18:43.178834: Epoch time: 20.34 s\n",
            "2024-03-12 17:18:43.178947: Yayy! New best EMA pseudo Dice: 0.6647\n",
            "2024-03-12 17:18:45.200222: \n",
            "2024-03-12 17:18:45.200454: Epoch 13\n",
            "2024-03-12 17:18:45.200597: Current learning rate: 0.00882\n",
            "2024-03-12 17:19:05.917207: train_loss -0.7879\n",
            "2024-03-12 17:19:05.917663: val_loss -0.7535\n",
            "2024-03-12 17:19:05.917921: Pseudo dice [0.8171]\n",
            "2024-03-12 17:19:05.918165: Epoch time: 20.72 s\n",
            "2024-03-12 17:19:05.918719: Yayy! New best EMA pseudo Dice: 0.6799\n",
            "2024-03-12 17:19:07.876384: \n",
            "2024-03-12 17:19:07.876566: Epoch 14\n",
            "2024-03-12 17:19:07.876693: Current learning rate: 0.00873\n",
            "2024-03-12 17:19:28.579005: train_loss -0.7963\n",
            "2024-03-12 17:19:28.579370: val_loss -0.7287\n",
            "2024-03-12 17:19:28.579617: Pseudo dice [0.798]\n",
            "2024-03-12 17:19:28.579848: Epoch time: 20.7 s\n",
            "2024-03-12 17:19:28.580036: Yayy! New best EMA pseudo Dice: 0.6917\n",
            "2024-03-12 17:19:30.578058: \n",
            "2024-03-12 17:19:30.578231: Epoch 15\n",
            "2024-03-12 17:19:30.578380: Current learning rate: 0.00864\n",
            "2024-03-12 17:19:51.179134: train_loss -0.7958\n",
            "2024-03-12 17:19:51.179457: val_loss -0.7085\n",
            "2024-03-12 17:19:51.179619: Pseudo dice [0.7831]\n",
            "2024-03-12 17:19:51.179759: Epoch time: 20.6 s\n",
            "2024-03-12 17:19:51.179876: Yayy! New best EMA pseudo Dice: 0.7009\n",
            "2024-03-12 17:19:53.336152: \n",
            "2024-03-12 17:19:53.336342: Epoch 16\n",
            "2024-03-12 17:19:53.336468: Current learning rate: 0.00855\n",
            "2024-03-12 17:20:13.612718: train_loss -0.8082\n",
            "2024-03-12 17:20:13.613000: val_loss -0.7443\n",
            "2024-03-12 17:20:13.613546: Pseudo dice [0.811]\n",
            "2024-03-12 17:20:13.613984: Epoch time: 20.28 s\n",
            "2024-03-12 17:20:13.614902: Yayy! New best EMA pseudo Dice: 0.7119\n",
            "2024-03-12 17:20:15.726704: \n",
            "2024-03-12 17:20:15.726879: Epoch 17\n",
            "2024-03-12 17:20:15.727037: Current learning rate: 0.00846\n",
            "2024-03-12 17:20:36.126408: train_loss -0.8053\n",
            "2024-03-12 17:20:36.126719: val_loss -0.6695\n",
            "2024-03-12 17:20:36.126888: Pseudo dice [0.7482]\n",
            "2024-03-12 17:20:36.127039: Epoch time: 20.4 s\n",
            "2024-03-12 17:20:36.127159: Yayy! New best EMA pseudo Dice: 0.7155\n",
            "2024-03-12 17:20:38.174226: \n",
            "2024-03-12 17:20:38.174414: Epoch 18\n",
            "2024-03-12 17:20:38.174550: Current learning rate: 0.00836\n",
            "2024-03-12 17:20:58.741272: train_loss -0.8058\n",
            "2024-03-12 17:20:58.741583: val_loss -0.705\n",
            "2024-03-12 17:20:58.741742: Pseudo dice [0.7794]\n",
            "2024-03-12 17:20:58.741893: Epoch time: 20.57 s\n",
            "2024-03-12 17:20:58.742017: Yayy! New best EMA pseudo Dice: 0.7219\n",
            "2024-03-12 17:21:00.789596: \n",
            "2024-03-12 17:21:00.789891: Epoch 19\n",
            "2024-03-12 17:21:00.790054: Current learning rate: 0.00827\n",
            "2024-03-12 17:21:21.608255: train_loss -0.8139\n",
            "2024-03-12 17:21:21.608608: val_loss -0.7121\n",
            "2024-03-12 17:21:21.608773: Pseudo dice [0.7905]\n",
            "2024-03-12 17:21:21.609115: Epoch time: 20.82 s\n",
            "2024-03-12 17:21:21.609472: Yayy! New best EMA pseudo Dice: 0.7288\n",
            "2024-03-12 17:21:23.572936: \n",
            "2024-03-12 17:21:23.573138: Epoch 20\n",
            "2024-03-12 17:21:23.573286: Current learning rate: 0.00818\n",
            "2024-03-12 17:21:44.430677: train_loss -0.821\n",
            "2024-03-12 17:21:44.431059: val_loss -0.7406\n",
            "2024-03-12 17:21:44.431311: Pseudo dice [0.8067]\n",
            "2024-03-12 17:21:44.431531: Epoch time: 20.86 s\n",
            "2024-03-12 17:21:44.431718: Yayy! New best EMA pseudo Dice: 0.7366\n",
            "2024-03-12 17:21:46.418658: \n",
            "2024-03-12 17:21:46.418893: Epoch 21\n",
            "2024-03-12 17:21:46.419066: Current learning rate: 0.00809\n",
            "2024-03-12 17:22:07.096628: train_loss -0.8235\n",
            "2024-03-12 17:22:07.097550: val_loss -0.731\n",
            "2024-03-12 17:22:07.098128: Pseudo dice [0.8002]\n",
            "2024-03-12 17:22:07.098872: Epoch time: 20.68 s\n",
            "2024-03-12 17:22:07.099259: Yayy! New best EMA pseudo Dice: 0.7429\n",
            "2024-03-12 17:22:09.191061: \n",
            "2024-03-12 17:22:09.191240: Epoch 22\n",
            "2024-03-12 17:22:09.191382: Current learning rate: 0.008\n",
            "2024-03-12 17:22:29.435737: train_loss -0.8261\n",
            "2024-03-12 17:22:29.436050: val_loss -0.7467\n",
            "2024-03-12 17:22:29.436219: Pseudo dice [0.8124]\n",
            "2024-03-12 17:22:29.436388: Epoch time: 20.25 s\n",
            "2024-03-12 17:22:29.436538: Yayy! New best EMA pseudo Dice: 0.7499\n",
            "2024-03-12 17:22:31.483374: \n",
            "2024-03-12 17:22:31.483602: Epoch 23\n",
            "2024-03-12 17:22:31.483729: Current learning rate: 0.0079\n",
            "2024-03-12 17:22:51.847572: train_loss -0.8295\n",
            "2024-03-12 17:22:51.847795: val_loss -0.7343\n",
            "2024-03-12 17:22:51.847881: Pseudo dice [0.8025]\n",
            "2024-03-12 17:22:51.847961: Epoch time: 20.37 s\n",
            "2024-03-12 17:22:51.848025: Yayy! New best EMA pseudo Dice: 0.7551\n",
            "2024-03-12 17:22:53.773853: \n",
            "2024-03-12 17:22:53.774181: Epoch 24\n",
            "2024-03-12 17:22:53.774338: Current learning rate: 0.00781\n",
            "2024-03-12 17:23:14.154344: train_loss -0.8299\n",
            "2024-03-12 17:23:14.154743: val_loss -0.7433\n",
            "2024-03-12 17:23:14.154959: Pseudo dice [0.8127]\n",
            "2024-03-12 17:23:14.155174: Epoch time: 20.38 s\n",
            "2024-03-12 17:23:14.155349: Yayy! New best EMA pseudo Dice: 0.7609\n",
            "2024-03-12 17:23:16.069927: \n",
            "2024-03-12 17:23:16.070279: Epoch 25\n",
            "2024-03-12 17:23:16.070445: Current learning rate: 0.00772\n",
            "2024-03-12 17:23:37.134639: train_loss -0.8279\n",
            "2024-03-12 17:23:37.135063: val_loss -0.7281\n",
            "2024-03-12 17:23:37.135309: Pseudo dice [0.8028]\n",
            "2024-03-12 17:23:37.138063: Epoch time: 21.07 s\n",
            "2024-03-12 17:23:37.138345: Yayy! New best EMA pseudo Dice: 0.7651\n",
            "2024-03-12 17:23:39.107826: \n",
            "2024-03-12 17:23:39.108203: Epoch 26\n",
            "2024-03-12 17:23:39.108352: Current learning rate: 0.00763\n",
            "2024-03-12 17:23:59.953208: train_loss -0.834\n",
            "2024-03-12 17:23:59.953609: val_loss -0.6715\n",
            "2024-03-12 17:23:59.953855: Pseudo dice [0.7529]\n",
            "2024-03-12 17:23:59.954099: Epoch time: 20.85 s\n",
            "2024-03-12 17:24:01.508539: \n",
            "2024-03-12 17:24:01.508789: Epoch 27\n",
            "2024-03-12 17:24:01.508919: Current learning rate: 0.00753\n",
            "2024-03-12 17:24:22.505968: train_loss -0.8369\n",
            "2024-03-12 17:24:22.506401: val_loss -0.7223\n",
            "2024-03-12 17:24:22.506658: Pseudo dice [0.7946]\n",
            "2024-03-12 17:24:22.506916: Epoch time: 21.0 s\n",
            "2024-03-12 17:24:22.507163: Yayy! New best EMA pseudo Dice: 0.7669\n",
            "2024-03-12 17:24:24.630396: \n",
            "2024-03-12 17:24:24.630579: Epoch 28\n",
            "2024-03-12 17:24:24.630711: Current learning rate: 0.00744\n",
            "2024-03-12 17:24:45.559684: train_loss -0.84\n",
            "2024-03-12 17:24:45.559968: val_loss -0.7487\n",
            "2024-03-12 17:24:45.560093: Pseudo dice [0.8117]\n",
            "2024-03-12 17:24:45.560209: Epoch time: 20.93 s\n",
            "2024-03-12 17:24:45.560309: Yayy! New best EMA pseudo Dice: 0.7714\n",
            "2024-03-12 17:24:47.484199: \n",
            "2024-03-12 17:24:47.484398: Epoch 29\n",
            "2024-03-12 17:24:47.484528: Current learning rate: 0.00735\n",
            "2024-03-12 17:25:08.466607: train_loss -0.8401\n",
            "2024-03-12 17:25:08.466917: val_loss -0.7249\n",
            "2024-03-12 17:25:08.467084: Pseudo dice [0.7983]\n",
            "2024-03-12 17:25:08.467259: Epoch time: 20.98 s\n",
            "2024-03-12 17:25:08.467425: Yayy! New best EMA pseudo Dice: 0.7741\n",
            "2024-03-12 17:25:10.665786: \n",
            "2024-03-12 17:25:10.666081: Epoch 30\n",
            "2024-03-12 17:25:10.666211: Current learning rate: 0.00725\n",
            "2024-03-12 17:25:31.240498: train_loss -0.8472\n",
            "2024-03-12 17:25:31.240824: val_loss -0.6977\n",
            "2024-03-12 17:25:31.240985: Pseudo dice [0.7669]\n",
            "2024-03-12 17:25:31.241158: Epoch time: 20.58 s\n",
            "2024-03-12 17:25:32.922864: \n",
            "2024-03-12 17:25:32.923077: Epoch 31\n",
            "2024-03-12 17:25:32.923250: Current learning rate: 0.00716\n",
            "2024-03-12 17:25:53.761250: train_loss -0.8478\n",
            "2024-03-12 17:25:53.761607: val_loss -0.6996\n",
            "2024-03-12 17:25:53.761789: Pseudo dice [0.7778]\n",
            "2024-03-12 17:25:53.761959: Epoch time: 20.84 s\n",
            "2024-03-12 17:25:55.341855: \n",
            "2024-03-12 17:25:55.342068: Epoch 32\n",
            "2024-03-12 17:25:55.342209: Current learning rate: 0.00707\n",
            "2024-03-12 17:26:16.371850: train_loss -0.8435\n",
            "2024-03-12 17:26:16.372149: val_loss -0.7229\n",
            "2024-03-12 17:26:16.372308: Pseudo dice [0.796]\n",
            "2024-03-12 17:26:16.372493: Epoch time: 21.03 s\n",
            "2024-03-12 17:26:16.372635: Yayy! New best EMA pseudo Dice: 0.776\n",
            "2024-03-12 17:26:18.345083: \n",
            "2024-03-12 17:26:18.345335: Epoch 33\n",
            "2024-03-12 17:26:18.345478: Current learning rate: 0.00697\n",
            "2024-03-12 17:26:39.412548: train_loss -0.8484\n",
            "2024-03-12 17:26:39.412937: val_loss -0.7392\n",
            "2024-03-12 17:26:39.413166: Pseudo dice [0.8044]\n",
            "2024-03-12 17:26:39.413375: Epoch time: 21.07 s\n",
            "2024-03-12 17:26:39.413560: Yayy! New best EMA pseudo Dice: 0.7789\n",
            "2024-03-12 17:26:41.545879: \n",
            "2024-03-12 17:26:41.546075: Epoch 34\n",
            "2024-03-12 17:26:41.546201: Current learning rate: 0.00688\n",
            "2024-03-12 17:27:02.414710: train_loss -0.8589\n",
            "2024-03-12 17:27:02.415070: val_loss -0.7144\n",
            "2024-03-12 17:27:02.415247: Pseudo dice [0.7796]\n",
            "2024-03-12 17:27:02.415416: Epoch time: 20.87 s\n",
            "2024-03-12 17:27:02.415569: Yayy! New best EMA pseudo Dice: 0.779\n",
            "2024-03-12 17:27:04.489069: \n",
            "2024-03-12 17:27:04.489424: Epoch 35\n",
            "2024-03-12 17:27:04.489576: Current learning rate: 0.00679\n",
            "2024-03-12 17:27:25.128268: train_loss -0.8555\n",
            "2024-03-12 17:27:25.128698: val_loss -0.7314\n",
            "2024-03-12 17:27:25.128932: Pseudo dice [0.8]\n",
            "2024-03-12 17:27:25.129157: Epoch time: 20.64 s\n",
            "2024-03-12 17:27:25.129396: Yayy! New best EMA pseudo Dice: 0.7811\n",
            "2024-03-12 17:27:27.249390: \n",
            "2024-03-12 17:27:27.249581: Epoch 36\n",
            "2024-03-12 17:27:27.249703: Current learning rate: 0.00669\n",
            "2024-03-12 17:27:47.902061: train_loss -0.8526\n",
            "2024-03-12 17:27:47.902403: val_loss -0.6929\n",
            "2024-03-12 17:27:47.902664: Pseudo dice [0.7724]\n",
            "2024-03-12 17:27:47.902859: Epoch time: 20.65 s\n",
            "2024-03-12 17:27:49.504148: \n",
            "2024-03-12 17:27:49.504328: Epoch 37\n",
            "2024-03-12 17:27:49.504480: Current learning rate: 0.0066\n",
            "2024-03-12 17:28:10.432716: train_loss -0.8603\n",
            "2024-03-12 17:28:10.433477: val_loss -0.7462\n",
            "2024-03-12 17:28:10.435289: Pseudo dice [0.8081]\n",
            "2024-03-12 17:28:10.436605: Epoch time: 20.93 s\n",
            "2024-03-12 17:28:10.436869: Yayy! New best EMA pseudo Dice: 0.783\n",
            "2024-03-12 17:28:12.471197: \n",
            "2024-03-12 17:28:12.471392: Epoch 38\n",
            "2024-03-12 17:28:12.471518: Current learning rate: 0.0065\n",
            "2024-03-12 17:28:33.518225: train_loss -0.8621\n",
            "2024-03-12 17:28:33.519704: val_loss -0.6999\n",
            "2024-03-12 17:28:33.520789: Pseudo dice [0.776]\n",
            "2024-03-12 17:28:33.521214: Epoch time: 21.05 s\n",
            "2024-03-12 17:28:35.177306: \n",
            "2024-03-12 17:28:35.177596: Epoch 39\n",
            "2024-03-12 17:28:35.177740: Current learning rate: 0.00641\n",
            "2024-03-12 17:28:56.052970: train_loss -0.8587\n",
            "2024-03-12 17:28:56.053389: val_loss -0.7347\n",
            "2024-03-12 17:28:56.053663: Pseudo dice [0.803]\n",
            "2024-03-12 17:28:56.055674: Epoch time: 20.88 s\n",
            "2024-03-12 17:28:56.056352: Yayy! New best EMA pseudo Dice: 0.7844\n",
            "2024-03-12 17:28:58.347923: \n",
            "2024-03-12 17:28:58.348109: Epoch 40\n",
            "2024-03-12 17:28:58.348239: Current learning rate: 0.00631\n",
            "2024-03-12 17:29:19.445637: train_loss -0.8676\n",
            "2024-03-12 17:29:19.445975: val_loss -0.7483\n",
            "2024-03-12 17:29:19.446133: Pseudo dice [0.8124]\n",
            "2024-03-12 17:29:19.446241: Epoch time: 21.1 s\n",
            "2024-03-12 17:29:19.446376: Yayy! New best EMA pseudo Dice: 0.7872\n",
            "2024-03-12 17:29:21.885315: \n",
            "2024-03-12 17:29:21.885766: Epoch 41\n",
            "2024-03-12 17:29:21.885920: Current learning rate: 0.00622\n",
            "2024-03-12 17:29:42.871184: train_loss -0.8582\n",
            "2024-03-12 17:29:42.871516: val_loss -0.7131\n",
            "2024-03-12 17:29:42.871707: Pseudo dice [0.7869]\n",
            "2024-03-12 17:29:42.871896: Epoch time: 20.99 s\n",
            "2024-03-12 17:29:44.457613: \n",
            "2024-03-12 17:29:44.457959: Epoch 42\n",
            "2024-03-12 17:29:44.458092: Current learning rate: 0.00612\n",
            "2024-03-12 17:30:05.302522: train_loss -0.8675\n",
            "2024-03-12 17:30:05.302868: val_loss -0.7682\n",
            "2024-03-12 17:30:05.303046: Pseudo dice [0.8309]\n",
            "2024-03-12 17:30:05.303234: Epoch time: 20.85 s\n",
            "2024-03-12 17:30:05.303402: Yayy! New best EMA pseudo Dice: 0.7915\n",
            "2024-03-12 17:30:07.291978: \n",
            "2024-03-12 17:30:07.292166: Epoch 43\n",
            "2024-03-12 17:30:07.292325: Current learning rate: 0.00603\n",
            "2024-03-12 17:30:28.548720: train_loss -0.867\n",
            "2024-03-12 17:30:28.549147: val_loss -0.7532\n",
            "2024-03-12 17:30:28.549491: Pseudo dice [0.8152]\n",
            "2024-03-12 17:30:28.549738: Epoch time: 21.26 s\n",
            "2024-03-12 17:30:28.550039: Yayy! New best EMA pseudo Dice: 0.7939\n",
            "2024-03-12 17:30:30.623919: \n",
            "2024-03-12 17:30:30.624108: Epoch 44\n",
            "2024-03-12 17:30:30.624235: Current learning rate: 0.00593\n",
            "2024-03-12 17:30:51.579882: train_loss -0.8657\n",
            "2024-03-12 17:30:51.580260: val_loss -0.7492\n",
            "2024-03-12 17:30:51.580526: Pseudo dice [0.8139]\n",
            "2024-03-12 17:30:51.580756: Epoch time: 20.96 s\n",
            "2024-03-12 17:30:51.580952: Yayy! New best EMA pseudo Dice: 0.7959\n",
            "2024-03-12 17:30:53.607269: \n",
            "2024-03-12 17:30:53.607489: Epoch 45\n",
            "2024-03-12 17:30:53.607669: Current learning rate: 0.00584\n",
            "2024-03-12 17:31:14.464640: train_loss -0.8592\n",
            "2024-03-12 17:31:14.464878: val_loss -0.7258\n",
            "2024-03-12 17:31:14.464972: Pseudo dice [0.8006]\n",
            "2024-03-12 17:31:14.465077: Epoch time: 20.86 s\n",
            "2024-03-12 17:31:14.465152: Yayy! New best EMA pseudo Dice: 0.7963\n",
            "2024-03-12 17:31:16.455009: \n",
            "2024-03-12 17:31:16.455201: Epoch 46\n",
            "2024-03-12 17:31:16.455346: Current learning rate: 0.00574\n",
            "2024-03-12 17:31:37.627500: train_loss -0.867\n",
            "2024-03-12 17:31:37.633616: val_loss -0.7336\n",
            "2024-03-12 17:31:37.633801: Pseudo dice [0.8042]\n",
            "2024-03-12 17:31:37.633977: Epoch time: 21.17 s\n",
            "2024-03-12 17:31:37.634258: Yayy! New best EMA pseudo Dice: 0.7971\n",
            "2024-03-12 17:31:39.903865: \n",
            "2024-03-12 17:31:39.904137: Epoch 47\n",
            "2024-03-12 17:31:39.904317: Current learning rate: 0.00565\n",
            "2024-03-12 17:32:01.098264: train_loss -0.8702\n",
            "2024-03-12 17:32:01.098594: val_loss -0.7438\n",
            "2024-03-12 17:32:01.098756: Pseudo dice [0.8093]\n",
            "2024-03-12 17:32:01.098902: Epoch time: 21.2 s\n",
            "2024-03-12 17:32:01.099035: Yayy! New best EMA pseudo Dice: 0.7984\n",
            "2024-03-12 17:32:03.030105: \n",
            "2024-03-12 17:32:03.030369: Epoch 48\n",
            "2024-03-12 17:32:03.030547: Current learning rate: 0.00555\n",
            "2024-03-12 17:32:24.075923: train_loss -0.8742\n",
            "2024-03-12 17:32:24.076248: val_loss -0.744\n",
            "2024-03-12 17:32:24.076451: Pseudo dice [0.8097]\n",
            "2024-03-12 17:32:24.076656: Epoch time: 21.05 s\n",
            "2024-03-12 17:32:24.076791: Yayy! New best EMA pseudo Dice: 0.7995\n",
            "2024-03-12 17:32:26.128614: \n",
            "2024-03-12 17:32:26.128879: Epoch 49\n",
            "2024-03-12 17:32:26.129027: Current learning rate: 0.00546\n",
            "2024-03-12 17:32:47.302314: train_loss -0.8744\n",
            "2024-03-12 17:32:47.302654: val_loss -0.712\n",
            "2024-03-12 17:32:47.302835: Pseudo dice [0.7823]\n",
            "2024-03-12 17:32:47.302991: Epoch time: 21.17 s\n",
            "2024-03-12 17:32:49.159512: \n",
            "2024-03-12 17:32:49.159746: Epoch 50\n",
            "2024-03-12 17:32:49.159886: Current learning rate: 0.00536\n",
            "2024-03-12 17:33:10.222739: train_loss -0.8747\n",
            "2024-03-12 17:33:10.223081: val_loss -0.732\n",
            "2024-03-12 17:33:10.223259: Pseudo dice [0.8045]\n",
            "2024-03-12 17:33:10.223434: Epoch time: 21.06 s\n",
            "2024-03-12 17:33:11.969327: \n",
            "2024-03-12 17:33:11.969571: Epoch 51\n",
            "2024-03-12 17:33:11.969702: Current learning rate: 0.00526\n",
            "2024-03-12 17:33:33.025541: train_loss -0.8797\n",
            "2024-03-12 17:33:33.025925: val_loss -0.6978\n",
            "2024-03-12 17:33:33.026202: Pseudo dice [0.774]\n",
            "2024-03-12 17:33:33.026437: Epoch time: 21.06 s\n",
            "2024-03-12 17:33:34.628923: \n",
            "2024-03-12 17:33:34.629103: Epoch 52\n",
            "2024-03-12 17:33:34.629233: Current learning rate: 0.00517\n",
            "2024-03-12 17:33:55.660816: train_loss -0.875\n",
            "2024-03-12 17:33:55.661070: val_loss -0.7466\n",
            "2024-03-12 17:33:55.661192: Pseudo dice [0.8182]\n",
            "2024-03-12 17:33:55.661305: Epoch time: 21.03 s\n",
            "2024-03-12 17:33:57.247539: \n",
            "2024-03-12 17:33:57.247729: Epoch 53\n",
            "2024-03-12 17:33:57.247881: Current learning rate: 0.00507\n",
            "2024-03-12 17:34:18.362997: train_loss -0.8759\n",
            "2024-03-12 17:34:18.368901: val_loss -0.7219\n",
            "2024-03-12 17:34:18.369119: Pseudo dice [0.7944]\n",
            "2024-03-12 17:34:18.369215: Epoch time: 21.12 s\n",
            "2024-03-12 17:34:19.832603: \n",
            "2024-03-12 17:34:19.832788: Epoch 54\n",
            "2024-03-12 17:34:19.832910: Current learning rate: 0.00497\n",
            "2024-03-12 17:34:40.774021: train_loss -0.8738\n",
            "2024-03-12 17:34:40.774365: val_loss -0.7219\n",
            "2024-03-12 17:34:40.774525: Pseudo dice [0.7957]\n",
            "2024-03-12 17:34:40.774864: Epoch time: 20.94 s\n",
            "2024-03-12 17:34:42.403677: \n",
            "2024-03-12 17:34:42.403920: Epoch 55\n",
            "2024-03-12 17:34:42.404052: Current learning rate: 0.00487\n",
            "2024-03-12 17:35:03.587602: train_loss -0.8685\n",
            "2024-03-12 17:35:03.587970: val_loss -0.7302\n",
            "2024-03-12 17:35:03.588264: Pseudo dice [0.8024]\n",
            "2024-03-12 17:35:03.588612: Epoch time: 21.19 s\n",
            "2024-03-12 17:35:05.138360: \n",
            "2024-03-12 17:35:05.138544: Epoch 56\n",
            "2024-03-12 17:35:05.138669: Current learning rate: 0.00478\n",
            "2024-03-12 17:35:25.958416: train_loss -0.8752\n",
            "2024-03-12 17:35:25.958884: val_loss -0.7477\n",
            "2024-03-12 17:35:25.959151: Pseudo dice [0.8101]\n",
            "2024-03-12 17:35:25.959414: Epoch time: 20.82 s\n",
            "2024-03-12 17:35:27.590557: \n",
            "2024-03-12 17:35:27.590749: Epoch 57\n",
            "2024-03-12 17:35:27.590878: Current learning rate: 0.00468\n",
            "2024-03-12 17:35:48.287834: train_loss -0.8808\n",
            "2024-03-12 17:35:48.288169: val_loss -0.7549\n",
            "2024-03-12 17:35:48.288366: Pseudo dice [0.8212]\n",
            "2024-03-12 17:35:48.290651: Epoch time: 20.7 s\n",
            "2024-03-12 17:35:48.290898: Yayy! New best EMA pseudo Dice: 0.8015\n",
            "2024-03-12 17:35:50.295103: \n",
            "2024-03-12 17:35:50.295508: Epoch 58\n",
            "2024-03-12 17:35:50.295641: Current learning rate: 0.00458\n",
            "2024-03-12 17:36:11.130061: train_loss -0.8827\n",
            "2024-03-12 17:36:11.130396: val_loss -0.7186\n",
            "2024-03-12 17:36:11.130573: Pseudo dice [0.7863]\n",
            "2024-03-12 17:36:11.130733: Epoch time: 20.84 s\n",
            "2024-03-12 17:36:12.741963: \n",
            "2024-03-12 17:36:12.742488: Epoch 59\n",
            "2024-03-12 17:36:12.742663: Current learning rate: 0.00448\n",
            "2024-03-12 17:36:33.590773: train_loss -0.8846\n",
            "2024-03-12 17:36:33.591373: val_loss -0.6789\n",
            "2024-03-12 17:36:33.591665: Pseudo dice [0.7618]\n",
            "2024-03-12 17:36:33.591889: Epoch time: 20.85 s\n",
            "2024-03-12 17:36:35.392329: \n",
            "2024-03-12 17:36:35.392554: Epoch 60\n",
            "2024-03-12 17:36:35.392753: Current learning rate: 0.00438\n",
            "2024-03-12 17:36:56.374475: train_loss -0.8825\n",
            "2024-03-12 17:36:56.374790: val_loss -0.7579\n",
            "2024-03-12 17:36:56.374955: Pseudo dice [0.8181]\n",
            "2024-03-12 17:36:56.375141: Epoch time: 20.98 s\n",
            "2024-03-12 17:36:57.996286: \n",
            "2024-03-12 17:36:57.996511: Epoch 61\n",
            "2024-03-12 17:36:57.996701: Current learning rate: 0.00429\n",
            "2024-03-12 17:37:18.973287: train_loss -0.8806\n",
            "2024-03-12 17:37:18.973643: val_loss -0.7178\n",
            "2024-03-12 17:37:18.973792: Pseudo dice [0.7947]\n",
            "2024-03-12 17:37:18.973923: Epoch time: 20.98 s\n",
            "2024-03-12 17:37:20.548134: \n",
            "2024-03-12 17:37:20.548383: Epoch 62\n",
            "2024-03-12 17:37:20.548561: Current learning rate: 0.00419\n",
            "2024-03-12 17:37:41.287086: train_loss -0.8834\n",
            "2024-03-12 17:37:41.287357: val_loss -0.6955\n",
            "2024-03-12 17:37:41.287504: Pseudo dice [0.7656]\n",
            "2024-03-12 17:37:41.287606: Epoch time: 20.74 s\n",
            "2024-03-12 17:37:42.939111: \n",
            "2024-03-12 17:37:42.939345: Epoch 63\n",
            "2024-03-12 17:37:42.939478: Current learning rate: 0.00409\n",
            "2024-03-12 17:38:03.925243: train_loss -0.8889\n",
            "2024-03-12 17:38:03.925615: val_loss -0.7279\n",
            "2024-03-12 17:38:03.925791: Pseudo dice [0.7954]\n",
            "2024-03-12 17:38:03.925958: Epoch time: 20.99 s\n",
            "2024-03-12 17:38:05.523751: \n",
            "2024-03-12 17:38:05.523969: Epoch 64\n",
            "2024-03-12 17:38:05.524112: Current learning rate: 0.00399\n",
            "2024-03-12 17:38:26.477494: train_loss -0.8896\n",
            "2024-03-12 17:38:26.477868: val_loss -0.7143\n",
            "2024-03-12 17:38:26.478135: Pseudo dice [0.7888]\n",
            "2024-03-12 17:38:26.478302: Epoch time: 20.95 s\n",
            "2024-03-12 17:38:28.045539: \n",
            "2024-03-12 17:38:28.045720: Epoch 65\n",
            "2024-03-12 17:38:28.045840: Current learning rate: 0.00389\n",
            "2024-03-12 17:38:49.053123: train_loss -0.8838\n",
            "2024-03-12 17:38:49.053798: val_loss -0.6896\n",
            "2024-03-12 17:38:49.054298: Pseudo dice [0.7658]\n",
            "2024-03-12 17:38:49.054629: Epoch time: 21.01 s\n",
            "2024-03-12 17:38:50.630339: \n",
            "2024-03-12 17:38:50.630591: Epoch 66\n",
            "2024-03-12 17:38:50.630730: Current learning rate: 0.00379\n",
            "2024-03-12 17:39:11.513454: train_loss -0.8859\n",
            "2024-03-12 17:39:11.514277: val_loss -0.7534\n",
            "2024-03-12 17:39:11.514616: Pseudo dice [0.8202]\n",
            "2024-03-12 17:39:11.515523: Epoch time: 20.88 s\n",
            "2024-03-12 17:39:13.278723: \n",
            "2024-03-12 17:39:13.278914: Epoch 67\n",
            "2024-03-12 17:39:13.279038: Current learning rate: 0.00369\n",
            "2024-03-12 17:39:34.172930: train_loss -0.8909\n",
            "2024-03-12 17:39:34.173173: val_loss -0.7321\n",
            "2024-03-12 17:39:34.173280: Pseudo dice [0.8047]\n",
            "2024-03-12 17:39:34.173430: Epoch time: 20.9 s\n",
            "2024-03-12 17:39:35.868495: \n",
            "2024-03-12 17:39:35.868697: Epoch 68\n",
            "2024-03-12 17:39:35.868832: Current learning rate: 0.00359\n",
            "2024-03-12 17:39:57.137161: train_loss -0.891\n",
            "2024-03-12 17:39:57.137552: val_loss -0.7547\n",
            "2024-03-12 17:39:57.137742: Pseudo dice [0.8152]\n",
            "2024-03-12 17:39:57.137912: Epoch time: 21.27 s\n",
            "2024-03-12 17:39:58.885810: \n",
            "2024-03-12 17:39:58.885985: Epoch 69\n",
            "2024-03-12 17:39:58.886109: Current learning rate: 0.00349\n",
            "2024-03-12 17:40:20.611266: train_loss -0.887\n",
            "2024-03-12 17:40:20.611616: val_loss -0.7213\n",
            "2024-03-12 17:40:20.611769: Pseudo dice [0.7965]\n",
            "2024-03-12 17:40:20.611912: Epoch time: 21.73 s\n",
            "2024-03-12 17:40:22.285224: \n",
            "2024-03-12 17:40:22.285552: Epoch 70\n",
            "2024-03-12 17:40:22.285689: Current learning rate: 0.00338\n",
            "2024-03-12 17:40:43.909807: train_loss -0.8912\n",
            "2024-03-12 17:40:43.910197: val_loss -0.7378\n",
            "2024-03-12 17:40:43.910395: Pseudo dice [0.8042]\n",
            "2024-03-12 17:40:43.910580: Epoch time: 21.63 s\n",
            "2024-03-12 17:40:45.563914: \n",
            "2024-03-12 17:40:45.564134: Epoch 71\n",
            "2024-03-12 17:40:45.564278: Current learning rate: 0.00328\n",
            "2024-03-12 17:41:06.746401: train_loss -0.8936\n",
            "2024-03-12 17:41:06.746704: val_loss -0.7601\n",
            "2024-03-12 17:41:06.746843: Pseudo dice [0.8256]\n",
            "2024-03-12 17:41:06.746982: Epoch time: 21.18 s\n",
            "2024-03-12 17:41:08.447159: \n",
            "2024-03-12 17:41:08.447350: Epoch 72\n",
            "2024-03-12 17:41:08.447476: Current learning rate: 0.00318\n",
            "2024-03-12 17:41:29.674416: train_loss -0.8949\n",
            "2024-03-12 17:41:29.675024: val_loss -0.7464\n",
            "2024-03-12 17:41:29.675497: Pseudo dice [0.8108]\n",
            "2024-03-12 17:41:29.675887: Epoch time: 21.23 s\n",
            "2024-03-12 17:41:29.676244: Yayy! New best EMA pseudo Dice: 0.8017\n",
            "2024-03-12 17:41:31.661943: \n",
            "2024-03-12 17:41:31.662177: Epoch 73\n",
            "2024-03-12 17:41:31.662362: Current learning rate: 0.00308\n",
            "2024-03-12 17:41:52.726580: train_loss -0.8942\n",
            "2024-03-12 17:41:52.726909: val_loss -0.7522\n",
            "2024-03-12 17:41:52.727071: Pseudo dice [0.8156]\n",
            "2024-03-12 17:41:52.727228: Epoch time: 21.07 s\n",
            "2024-03-12 17:41:52.727375: Yayy! New best EMA pseudo Dice: 0.8031\n",
            "2024-03-12 17:41:54.958423: \n",
            "2024-03-12 17:41:54.958658: Epoch 74\n",
            "2024-03-12 17:41:54.958791: Current learning rate: 0.00297\n",
            "2024-03-12 17:42:16.119308: train_loss -0.8934\n",
            "2024-03-12 17:42:16.119677: val_loss -0.7278\n",
            "2024-03-12 17:42:16.119854: Pseudo dice [0.7925]\n",
            "2024-03-12 17:42:16.120002: Epoch time: 21.16 s\n",
            "2024-03-12 17:42:17.771852: \n",
            "2024-03-12 17:42:17.772065: Epoch 75\n",
            "2024-03-12 17:42:17.772234: Current learning rate: 0.00287\n",
            "2024-03-12 17:42:39.030030: train_loss -0.8941\n",
            "2024-03-12 17:42:39.030411: val_loss -0.7096\n",
            "2024-03-12 17:42:39.030605: Pseudo dice [0.7837]\n",
            "2024-03-12 17:42:39.030777: Epoch time: 21.26 s\n",
            "2024-03-12 17:42:40.727769: \n",
            "2024-03-12 17:42:40.727965: Epoch 76\n",
            "2024-03-12 17:42:40.728105: Current learning rate: 0.00277\n",
            "2024-03-12 17:43:01.884618: train_loss -0.897\n",
            "2024-03-12 17:43:01.885101: val_loss -0.716\n",
            "2024-03-12 17:43:01.887776: Pseudo dice [0.7883]\n",
            "2024-03-12 17:43:01.887992: Epoch time: 21.16 s\n",
            "2024-03-12 17:43:03.460356: \n",
            "2024-03-12 17:43:03.460612: Epoch 77\n",
            "2024-03-12 17:43:03.460743: Current learning rate: 0.00266\n",
            "2024-03-12 17:43:24.490348: train_loss -0.9006\n",
            "2024-03-12 17:43:24.490658: val_loss -0.7324\n",
            "2024-03-12 17:43:24.490808: Pseudo dice [0.8017]\n",
            "2024-03-12 17:43:24.491009: Epoch time: 21.03 s\n",
            "2024-03-12 17:43:26.129277: \n",
            "2024-03-12 17:43:26.129498: Epoch 78\n",
            "2024-03-12 17:43:26.129635: Current learning rate: 0.00256\n",
            "2024-03-12 17:43:47.217588: train_loss -0.8942\n",
            "2024-03-12 17:43:47.217989: val_loss -0.6798\n",
            "2024-03-12 17:43:47.218281: Pseudo dice [0.7598]\n",
            "2024-03-12 17:43:47.218504: Epoch time: 21.09 s\n",
            "2024-03-12 17:43:48.900424: \n",
            "2024-03-12 17:43:48.900685: Epoch 79\n",
            "2024-03-12 17:43:48.900856: Current learning rate: 0.00245\n",
            "2024-03-12 17:44:10.386602: train_loss -0.8963\n",
            "2024-03-12 17:44:10.386992: val_loss -0.6751\n",
            "2024-03-12 17:44:10.393106: Pseudo dice [0.7602]\n",
            "2024-03-12 17:44:10.393337: Epoch time: 21.49 s\n",
            "2024-03-12 17:44:12.020679: \n",
            "2024-03-12 17:44:12.020868: Epoch 80\n",
            "2024-03-12 17:44:12.020990: Current learning rate: 0.00235\n",
            "2024-03-12 17:44:33.397163: train_loss -0.8944\n",
            "2024-03-12 17:44:33.397435: val_loss -0.7356\n",
            "2024-03-12 17:44:33.397543: Pseudo dice [0.8047]\n",
            "2024-03-12 17:44:33.397642: Epoch time: 21.38 s\n",
            "2024-03-12 17:44:35.169650: \n",
            "2024-03-12 17:44:35.169830: Epoch 81\n",
            "2024-03-12 17:44:35.169955: Current learning rate: 0.00224\n",
            "2024-03-12 17:44:56.361803: train_loss -0.9019\n",
            "2024-03-12 17:44:56.362168: val_loss -0.7494\n",
            "2024-03-12 17:44:56.362443: Pseudo dice [0.819]\n",
            "2024-03-12 17:44:56.362773: Epoch time: 21.19 s\n",
            "2024-03-12 17:44:58.140918: \n",
            "2024-03-12 17:44:58.141141: Epoch 82\n",
            "2024-03-12 17:44:58.141269: Current learning rate: 0.00214\n",
            "2024-03-12 17:45:19.220101: train_loss -0.8985\n",
            "2024-03-12 17:45:19.220409: val_loss -0.6936\n",
            "2024-03-12 17:45:19.220577: Pseudo dice [0.7686]\n",
            "2024-03-12 17:45:19.220739: Epoch time: 21.08 s\n",
            "2024-03-12 17:45:20.848123: \n",
            "2024-03-12 17:45:20.848343: Epoch 83\n",
            "2024-03-12 17:45:20.848500: Current learning rate: 0.00203\n",
            "2024-03-12 17:45:42.139547: train_loss -0.8979\n",
            "2024-03-12 17:45:42.139935: val_loss -0.7136\n",
            "2024-03-12 17:45:42.140085: Pseudo dice [0.7872]\n",
            "2024-03-12 17:45:42.140220: Epoch time: 21.29 s\n",
            "2024-03-12 17:45:43.617627: \n",
            "2024-03-12 17:45:43.617795: Epoch 84\n",
            "2024-03-12 17:45:43.617939: Current learning rate: 0.00192\n",
            "2024-03-12 17:46:05.061421: train_loss -0.8995\n",
            "2024-03-12 17:46:05.061820: val_loss -0.7225\n",
            "2024-03-12 17:46:05.062078: Pseudo dice [0.7947]\n",
            "2024-03-12 17:46:05.062278: Epoch time: 21.44 s\n",
            "2024-03-12 17:46:06.613804: \n",
            "2024-03-12 17:46:06.614052: Epoch 85\n",
            "2024-03-12 17:46:06.614208: Current learning rate: 0.00181\n",
            "2024-03-12 17:46:27.944626: train_loss -0.9021\n",
            "2024-03-12 17:46:27.944852: val_loss -0.7614\n",
            "2024-03-12 17:46:27.944944: Pseudo dice [0.8217]\n",
            "2024-03-12 17:46:27.945030: Epoch time: 21.33 s\n",
            "2024-03-12 17:46:29.480064: \n",
            "2024-03-12 17:46:29.480246: Epoch 86\n",
            "2024-03-12 17:46:29.480376: Current learning rate: 0.0017\n",
            "2024-03-12 17:46:50.657145: train_loss -0.8996\n",
            "2024-03-12 17:46:50.657923: val_loss -0.6851\n",
            "2024-03-12 17:46:50.658188: Pseudo dice [0.7588]\n",
            "2024-03-12 17:46:50.658394: Epoch time: 21.18 s\n",
            "2024-03-12 17:46:52.230001: \n",
            "2024-03-12 17:46:52.230222: Epoch 87\n",
            "2024-03-12 17:46:52.230423: Current learning rate: 0.00159\n",
            "2024-03-12 17:47:13.305618: train_loss -0.9008\n",
            "2024-03-12 17:47:13.305982: val_loss -0.676\n",
            "2024-03-12 17:47:13.306265: Pseudo dice [0.7541]\n",
            "2024-03-12 17:47:13.306520: Epoch time: 21.08 s\n",
            "2024-03-12 17:47:14.898418: \n",
            "2024-03-12 17:47:14.898807: Epoch 88\n",
            "2024-03-12 17:47:14.898940: Current learning rate: 0.00148\n",
            "2024-03-12 17:47:36.296757: train_loss -0.9056\n",
            "2024-03-12 17:47:36.297300: val_loss -0.7217\n",
            "2024-03-12 17:47:36.297692: Pseudo dice [0.7897]\n",
            "2024-03-12 17:47:36.298077: Epoch time: 21.4 s\n",
            "2024-03-12 17:47:37.748487: \n",
            "2024-03-12 17:47:37.748669: Epoch 89\n",
            "2024-03-12 17:47:37.748822: Current learning rate: 0.00137\n",
            "2024-03-12 17:47:58.846381: train_loss -0.9057\n",
            "2024-03-12 17:47:58.849539: val_loss -0.6978\n",
            "2024-03-12 17:47:58.849871: Pseudo dice [0.772]\n",
            "2024-03-12 17:47:58.850064: Epoch time: 21.1 s\n",
            "2024-03-12 17:48:00.383528: \n",
            "2024-03-12 17:48:00.383822: Epoch 90\n",
            "2024-03-12 17:48:00.383954: Current learning rate: 0.00126\n",
            "2024-03-12 17:48:21.704589: train_loss -0.9043\n",
            "2024-03-12 17:48:21.705186: val_loss -0.7087\n",
            "2024-03-12 17:48:21.705471: Pseudo dice [0.7784]\n",
            "2024-03-12 17:48:21.705691: Epoch time: 21.32 s\n",
            "2024-03-12 17:48:23.294543: \n",
            "2024-03-12 17:48:23.294735: Epoch 91\n",
            "2024-03-12 17:48:23.294857: Current learning rate: 0.00115\n",
            "2024-03-12 17:48:44.465412: train_loss -0.905\n",
            "2024-03-12 17:48:44.465739: val_loss -0.6959\n",
            "2024-03-12 17:48:44.465893: Pseudo dice [0.7755]\n",
            "2024-03-12 17:48:44.466054: Epoch time: 21.17 s\n",
            "2024-03-12 17:48:45.990282: \n",
            "2024-03-12 17:48:45.990507: Epoch 92\n",
            "2024-03-12 17:48:45.990632: Current learning rate: 0.00103\n",
            "2024-03-12 17:49:06.942156: train_loss -0.9063\n",
            "2024-03-12 17:49:06.942492: val_loss -0.7284\n",
            "2024-03-12 17:49:06.942675: Pseudo dice [0.7938]\n",
            "2024-03-12 17:49:06.942829: Epoch time: 20.95 s\n",
            "2024-03-12 17:49:08.454612: \n",
            "2024-03-12 17:49:08.454802: Epoch 93\n",
            "2024-03-12 17:49:08.454962: Current learning rate: 0.00091\n",
            "2024-03-12 17:49:29.480677: train_loss -0.905\n",
            "2024-03-12 17:49:29.481041: val_loss -0.7332\n",
            "2024-03-12 17:49:29.481156: Pseudo dice [0.8007]\n",
            "2024-03-12 17:49:29.481273: Epoch time: 21.03 s\n",
            "2024-03-12 17:49:31.064831: \n",
            "2024-03-12 17:49:31.065048: Epoch 94\n",
            "2024-03-12 17:49:31.065224: Current learning rate: 0.00079\n",
            "2024-03-12 17:49:51.676294: train_loss -0.9078\n",
            "2024-03-12 17:49:51.676563: val_loss -0.7296\n",
            "2024-03-12 17:49:51.676676: Pseudo dice [0.7942]\n",
            "2024-03-12 17:49:51.676790: Epoch time: 20.61 s\n",
            "2024-03-12 17:49:53.203437: \n",
            "2024-03-12 17:49:53.203777: Epoch 95\n",
            "2024-03-12 17:49:53.203919: Current learning rate: 0.00067\n",
            "2024-03-12 17:50:13.699874: train_loss -0.9052\n",
            "2024-03-12 17:50:13.700350: val_loss -0.731\n",
            "2024-03-12 17:50:13.700628: Pseudo dice [0.7998]\n",
            "2024-03-12 17:50:13.700829: Epoch time: 20.5 s\n",
            "2024-03-12 17:50:15.374507: \n",
            "2024-03-12 17:50:15.374762: Epoch 96\n",
            "2024-03-12 17:50:15.374900: Current learning rate: 0.00055\n",
            "2024-03-12 17:50:36.039834: train_loss -0.9064\n",
            "2024-03-12 17:50:36.040160: val_loss -0.7285\n",
            "2024-03-12 17:50:36.040354: Pseudo dice [0.7946]\n",
            "2024-03-12 17:50:36.040528: Epoch time: 20.67 s\n",
            "2024-03-12 17:50:37.657892: \n",
            "2024-03-12 17:50:37.658109: Epoch 97\n",
            "2024-03-12 17:50:37.658240: Current learning rate: 0.00043\n",
            "2024-03-12 17:50:58.481405: train_loss -0.9091\n",
            "2024-03-12 17:50:58.481735: val_loss -0.718\n",
            "2024-03-12 17:50:58.481909: Pseudo dice [0.7872]\n",
            "2024-03-12 17:50:58.482065: Epoch time: 20.82 s\n",
            "2024-03-12 17:51:00.054291: \n",
            "2024-03-12 17:51:00.054492: Epoch 98\n",
            "2024-03-12 17:51:00.054653: Current learning rate: 0.0003\n",
            "2024-03-12 17:51:20.913376: train_loss -0.908\n",
            "2024-03-12 17:51:20.913851: val_loss -0.7263\n",
            "2024-03-12 17:51:20.915342: Pseudo dice [0.7953]\n",
            "2024-03-12 17:51:20.915725: Epoch time: 20.86 s\n",
            "2024-03-12 17:51:22.569011: \n",
            "2024-03-12 17:51:22.569244: Epoch 99\n",
            "2024-03-12 17:51:22.569417: Current learning rate: 0.00016\n",
            "2024-03-12 17:51:43.100304: train_loss -0.9092\n",
            "2024-03-12 17:51:43.100772: val_loss -0.7405\n",
            "2024-03-12 17:51:43.100964: Pseudo dice [0.8084]\n",
            "2024-03-12 17:51:43.101171: Epoch time: 20.53 s\n",
            "2024-03-12 17:51:45.053451: Training done.\n",
            "2024-03-12 17:51:45.162302: Using splits from existing split file: /content/nnUNet_preprocessed/Dataset007_Kidney/splits_final.json\n",
            "2024-03-12 17:51:45.162748: The split file contains 5 splits.\n",
            "2024-03-12 17:51:45.162866: Desired fold for training: 2\n",
            "2024-03-12 17:51:45.162956: This split has 80 training and 20 validation cases.\n",
            "2024-03-12 17:51:45.163324: predicting case_00052\n",
            "2024-03-12 17:51:45.164614: case_00052, shape torch.Size([1, 673, 109, 157]), rank 0\n",
            "2024-03-12 17:55:05.364740: predicting case_00073\n",
            "2024-03-12 17:55:05.366946: case_00073, shape torch.Size([1, 145, 234, 141]), rank 0\n",
            "2024-03-12 17:56:43.641909: predicting case_00084\n",
            "2024-03-12 17:56:43.643859: case_00084, shape torch.Size([1, 274, 177, 160]), rank 0\n",
            "2024-03-12 17:58:56.157899: predicting case_00093\n",
            "2024-03-12 17:58:56.159622: case_00093, shape torch.Size([1, 787, 128, 149]), rank 0\n",
            "2024-03-12 18:02:45.509279: predicting case_00099\n",
            "2024-03-12 18:02:45.511858: case_00099, shape torch.Size([1, 105, 169, 116]), rank 0\n",
            "2024-03-12 18:03:24.379864: predicting case_00104\n",
            "2024-03-12 18:03:24.381131: case_00104, shape torch.Size([1, 114, 184, 128]), rank 0\n",
            "2024-03-12 18:04:06.478158: predicting case_00109\n",
            "2024-03-12 18:04:06.479785: case_00109, shape torch.Size([1, 76, 61, 96]), rank 0\n",
            "2024-03-12 18:04:10.385227: predicting case_00114\n",
            "2024-03-12 18:04:10.386458: case_00114, shape torch.Size([1, 304, 98, 132]), rank 0\n",
            "2024-03-12 18:05:38.937274: predicting case_00135\n",
            "2024-03-12 18:05:38.939481: case_00135, shape torch.Size([1, 634, 103, 137]), rank 0\n",
            "2024-03-12 18:08:44.605565: predicting case_00215\n",
            "2024-03-12 18:08:44.607422: case_00215, shape torch.Size([1, 82, 99, 154]), rank 0\n",
            "2024-03-12 18:09:09.589856: predicting case_00256\n",
            "2024-03-12 18:09:09.591479: case_00256, shape torch.Size([1, 75, 90, 148]), rank 0\n",
            "2024-03-12 18:09:24.518633: predicting case_00276\n",
            "2024-03-12 18:09:24.520202: case_00276, shape torch.Size([1, 727, 118, 140]), rank 0\n",
            "2024-03-12 18:12:57.517831: predicting case_00427\n",
            "2024-03-12 18:12:57.520074: case_00427, shape torch.Size([1, 47, 75, 115]), rank 0\n",
            "2024-03-12 18:13:04.712289: predicting case_00467\n",
            "2024-03-12 18:13:04.713756: case_00467, shape torch.Size([1, 100, 69, 126]), rank 0\n",
            "2024-03-12 18:13:19.723455: predicting case_00492\n",
            "2024-03-12 18:13:19.725046: case_00492, shape torch.Size([1, 98, 158, 133]), rank 0\n",
            "2024-03-12 18:13:58.316482: predicting case_00507\n",
            "2024-03-12 18:13:58.318100: case_00507, shape torch.Size([1, 89, 143, 131]), rank 0\n",
            "2024-03-12 18:14:33.214851: predicting case_00515\n",
            "2024-03-12 18:14:33.216467: case_00515, shape torch.Size([1, 325, 105, 146]), rank 0\n",
            "2024-03-12 18:16:08.875542: predicting case_00517\n",
            "2024-03-12 18:16:08.877316: case_00517, shape torch.Size([1, 525, 170, 139]), rank 0\n",
            "2024-03-12 18:20:19.173827: predicting case_00542\n",
            "2024-03-12 18:20:19.176775: case_00542, shape torch.Size([1, 226, 146, 115]), rank 0\n",
            "2024-03-12 18:21:25.485673: predicting case_00566\n",
            "2024-03-12 18:21:25.487281: case_00566, shape torch.Size([1, 151, 97, 160]), rank 0\n",
            "2024-03-12 18:22:19.143488: Validation complete\n",
            "2024-03-12 18:22:19.143639: Mean Validation Dice:  0.42148308606911156\n"
          ]
        }
      ],
      "source": [
        "# ! nnUNetv2_train 07 3d_fullres 2 -device cuda\n",
        "! nnUNetv2_train 07 2d 2 -device cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRy1Et9FN1Wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678ef153-0371-458b-8346-46b9173f3940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 49, 'patch_size': [256, 256], 'median_image_size_in_voxels': [256.0, 256.0], 'spacing': [1.615686297416687, 1.565563678741455], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset007_Kidney', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5376923084259033, 1.615686297416687, 1.565563678741455], 'original_median_shape_after_transp': [106, 256, 256], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 99.2938232421875, 'median': 98.77884674072266, 'min': -963.5069580078125, 'percentile_00_5': -49.010292053222656, 'percentile_99_5': 287.46734619140625, 'std': 69.02969360351562}}} \n",
            "\n",
            "2024-03-21 15:33:07.596682: unpacking dataset...\n",
            "2024-03-21 15:34:28.151750: unpacking done...\n",
            "2024-03-21 15:34:28.164921: do_dummy_2d_data_aug: False\n",
            "2024-03-21 15:34:28.167348: Creating new 5-fold cross-validation split...\n",
            "2024-03-21 15:34:28.170683: Desired fold for training: 2\n",
            "2024-03-21 15:34:28.170810: This split has 239 training and 60 validation cases.\n",
            "2024-03-21 15:34:28.202456: Unable to plot network architecture:\n",
            "2024-03-21 15:34:28.202569: No module named 'hiddenlayer'\n",
            "2024-03-21 15:34:28.241820: \n",
            "2024-03-21 15:34:28.241954: Epoch 0\n",
            "2024-03-21 15:34:28.242115: Current learning rate: 0.01\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-03-21 15:36:16.031064: train_loss -0.0816\n",
            "2024-03-21 15:36:16.031526: val_loss -0.6391\n",
            "2024-03-21 15:36:16.031718: Pseudo dice [0.7002, 0.7144]\n",
            "2024-03-21 15:36:16.031918: Epoch time: 107.79 s\n",
            "2024-03-21 15:36:16.032085: Yayy! New best EMA pseudo Dice: 0.7073\n",
            "2024-03-21 15:36:18.455263: \n",
            "2024-03-21 15:36:18.455455: Epoch 1\n",
            "2024-03-21 15:36:18.455612: Current learning rate: 0.00997\n",
            "2024-03-21 15:37:50.259127: train_loss -0.7038\n",
            "2024-03-21 15:37:50.259550: val_loss -0.8189\n",
            "2024-03-21 15:37:50.259694: Pseudo dice [0.8537, 0.8591]\n",
            "2024-03-21 15:37:50.259821: Epoch time: 91.81 s\n",
            "2024-03-21 15:37:50.259919: Yayy! New best EMA pseudo Dice: 0.7223\n",
            "2024-03-21 15:37:53.163106: \n",
            "2024-03-21 15:37:53.163533: Epoch 2\n",
            "2024-03-21 15:37:53.163735: Current learning rate: 0.00994\n",
            "2024-03-21 15:39:23.762571: train_loss -0.8016\n",
            "2024-03-21 15:39:23.762876: val_loss -0.8566\n",
            "2024-03-21 15:39:23.763045: Pseudo dice [0.8873, 0.888]\n",
            "2024-03-21 15:39:23.763169: Epoch time: 90.6 s\n",
            "2024-03-21 15:39:23.763267: Yayy! New best EMA pseudo Dice: 0.7388\n",
            "2024-03-21 15:39:26.732036: \n",
            "2024-03-21 15:39:26.732224: Epoch 3\n",
            "2024-03-21 15:39:26.732427: Current learning rate: 0.00991\n",
            "2024-03-21 15:40:57.287623: train_loss -0.838\n",
            "2024-03-21 15:40:57.287998: val_loss -0.8862\n",
            "2024-03-21 15:40:57.288181: Pseudo dice [0.9252, 0.9005]\n",
            "2024-03-21 15:40:57.288400: Epoch time: 90.56 s\n",
            "2024-03-21 15:40:57.288522: Yayy! New best EMA pseudo Dice: 0.7562\n",
            "2024-03-21 15:41:00.126118: \n",
            "2024-03-21 15:41:00.126678: Epoch 4\n",
            "2024-03-21 15:41:00.126828: Current learning rate: 0.00988\n",
            "2024-03-21 15:42:30.303798: train_loss -0.858\n",
            "2024-03-21 15:42:30.304185: val_loss -0.886\n",
            "2024-03-21 15:42:30.304419: Pseudo dice [0.9205, 0.9019]\n",
            "2024-03-21 15:42:30.304647: Epoch time: 90.18 s\n",
            "2024-03-21 15:42:30.304867: Yayy! New best EMA pseudo Dice: 0.7717\n",
            "2024-03-21 15:42:32.928607: \n",
            "2024-03-21 15:42:32.929032: Epoch 5\n",
            "2024-03-21 15:42:32.929161: Current learning rate: 0.00985\n",
            "2024-03-21 15:44:04.846046: train_loss -0.8721\n",
            "2024-03-21 15:44:04.846491: val_loss -0.8873\n",
            "2024-03-21 15:44:04.846691: Pseudo dice [0.919, 0.9064]\n",
            "2024-03-21 15:44:04.846891: Epoch time: 91.92 s\n",
            "2024-03-21 15:44:04.847059: Yayy! New best EMA pseudo Dice: 0.7858\n",
            "2024-03-21 15:44:07.826561: \n",
            "2024-03-21 15:44:07.826755: Epoch 6\n",
            "2024-03-21 15:44:07.826890: Current learning rate: 0.00982\n",
            "2024-03-21 15:45:37.929006: train_loss -0.8729\n",
            "2024-03-21 15:45:37.929506: val_loss -0.8763\n",
            "2024-03-21 15:45:37.929830: Pseudo dice [0.903, 0.8978]\n",
            "2024-03-21 15:45:37.930077: Epoch time: 90.1 s\n",
            "2024-03-21 15:45:37.930259: Yayy! New best EMA pseudo Dice: 0.7973\n",
            "2024-03-21 15:45:40.578648: \n",
            "2024-03-21 15:45:40.578856: Epoch 7\n",
            "2024-03-21 15:45:40.579038: Current learning rate: 0.00979\n",
            "2024-03-21 15:47:10.931533: train_loss -0.8813\n",
            "2024-03-21 15:47:10.931851: val_loss -0.9049\n",
            "2024-03-21 15:47:10.931962: Pseudo dice [0.9399, 0.909]\n",
            "2024-03-21 15:47:10.932065: Epoch time: 90.35 s\n",
            "2024-03-21 15:47:10.932149: Yayy! New best EMA pseudo Dice: 0.81\n",
            "2024-03-21 15:47:13.550935: \n",
            "2024-03-21 15:47:13.551178: Epoch 8\n",
            "2024-03-21 15:47:13.551337: Current learning rate: 0.00976\n",
            "2024-03-21 15:48:43.650935: train_loss -0.8883\n",
            "2024-03-21 15:48:43.651389: val_loss -0.9139\n",
            "2024-03-21 15:48:43.651625: Pseudo dice [0.945, 0.9187]\n",
            "2024-03-21 15:48:43.651820: Epoch time: 90.1 s\n",
            "2024-03-21 15:48:43.651965: Yayy! New best EMA pseudo Dice: 0.8222\n",
            "2024-03-21 15:48:46.493025: \n",
            "2024-03-21 15:48:46.493210: Epoch 9\n",
            "2024-03-21 15:48:46.493357: Current learning rate: 0.00973\n",
            "2024-03-21 15:50:15.889193: train_loss -0.8877\n",
            "2024-03-21 15:50:15.889493: val_loss -0.9055\n",
            "2024-03-21 15:50:15.889635: Pseudo dice [0.9385, 0.911]\n",
            "2024-03-21 15:50:15.889763: Epoch time: 89.4 s\n",
            "2024-03-21 15:50:15.889873: Yayy! New best EMA pseudo Dice: 0.8324\n",
            "2024-03-21 15:50:18.744508: \n",
            "2024-03-21 15:50:18.744701: Epoch 10\n",
            "2024-03-21 15:50:18.744842: Current learning rate: 0.0097\n",
            "2024-03-21 15:51:48.935739: train_loss -0.9012\n",
            "2024-03-21 15:51:48.936258: val_loss -0.9208\n",
            "2024-03-21 15:51:48.936568: Pseudo dice [0.9496, 0.9253]\n",
            "2024-03-21 15:51:48.936734: Epoch time: 90.19 s\n",
            "2024-03-21 15:51:48.936895: Yayy! New best EMA pseudo Dice: 0.8429\n",
            "2024-03-21 15:51:51.918383: \n",
            "2024-03-21 15:51:51.918560: Epoch 11\n",
            "2024-03-21 15:51:51.918704: Current learning rate: 0.00967\n",
            "2024-03-21 15:53:22.437447: train_loss -0.8975\n",
            "2024-03-21 15:53:22.437847: val_loss -0.9134\n",
            "2024-03-21 15:53:22.437992: Pseudo dice [0.9447, 0.9161]\n",
            "2024-03-21 15:53:22.438133: Epoch time: 90.52 s\n",
            "2024-03-21 15:53:22.438250: Yayy! New best EMA pseudo Dice: 0.8517\n",
            "2024-03-21 15:53:25.140766: \n",
            "2024-03-21 15:53:25.141327: Epoch 12\n",
            "2024-03-21 15:53:25.141489: Current learning rate: 0.00964\n",
            "2024-03-21 15:54:55.624041: train_loss -0.904\n",
            "2024-03-21 15:54:55.624434: val_loss -0.9132\n",
            "2024-03-21 15:54:55.624559: Pseudo dice [0.9449, 0.9157]\n",
            "2024-03-21 15:54:55.624661: Epoch time: 90.48 s\n",
            "2024-03-21 15:54:55.624756: Yayy! New best EMA pseudo Dice: 0.8595\n",
            "2024-03-21 15:54:58.526063: \n",
            "2024-03-21 15:54:58.526269: Epoch 13\n",
            "2024-03-21 15:54:58.526431: Current learning rate: 0.00961\n",
            "2024-03-21 15:56:28.220975: train_loss -0.9064\n",
            "2024-03-21 15:56:28.221830: val_loss -0.9098\n",
            "2024-03-21 15:56:28.222123: Pseudo dice [0.9446, 0.9101]\n",
            "2024-03-21 15:56:28.222260: Epoch time: 89.7 s\n",
            "2024-03-21 15:56:28.222498: Yayy! New best EMA pseudo Dice: 0.8663\n",
            "2024-03-21 15:56:31.169317: \n",
            "2024-03-21 15:56:31.169494: Epoch 14\n",
            "2024-03-21 15:56:31.169631: Current learning rate: 0.00958\n",
            "2024-03-21 15:58:00.569470: train_loss -0.9009\n",
            "2024-03-21 15:58:00.569893: val_loss -0.913\n",
            "2024-03-21 15:58:00.570082: Pseudo dice [0.9441, 0.9144]\n",
            "2024-03-21 15:58:00.570240: Epoch time: 89.4 s\n",
            "2024-03-21 15:58:00.570408: Yayy! New best EMA pseudo Dice: 0.8726\n",
            "2024-03-21 15:58:03.430699: \n",
            "2024-03-21 15:58:03.430889: Epoch 15\n",
            "2024-03-21 15:58:03.431030: Current learning rate: 0.00955\n",
            "2024-03-21 15:59:33.058506: train_loss -0.9061\n",
            "2024-03-21 15:59:33.058894: val_loss -0.9209\n",
            "2024-03-21 15:59:33.059031: Pseudo dice [0.9527, 0.9206]\n",
            "2024-03-21 15:59:33.059149: Epoch time: 89.63 s\n",
            "2024-03-21 15:59:33.059250: Yayy! New best EMA pseudo Dice: 0.879\n",
            "2024-03-21 15:59:35.981657: \n",
            "2024-03-21 15:59:35.981963: Epoch 16\n",
            "2024-03-21 15:59:35.982124: Current learning rate: 0.00952\n",
            "2024-03-21 16:01:04.808450: train_loss -0.9031\n",
            "2024-03-21 16:01:04.809268: val_loss -0.9055\n",
            "2024-03-21 16:01:04.809554: Pseudo dice [0.9394, 0.9072]\n",
            "2024-03-21 16:01:04.809909: Epoch time: 88.83 s\n",
            "2024-03-21 16:01:04.810327: Yayy! New best EMA pseudo Dice: 0.8834\n",
            "2024-03-21 16:01:07.388109: \n",
            "2024-03-21 16:01:07.388436: Epoch 17\n",
            "2024-03-21 16:01:07.388570: Current learning rate: 0.00949\n",
            "2024-03-21 16:02:36.571333: train_loss -0.9085\n",
            "2024-03-21 16:02:36.571575: val_loss -0.9174\n",
            "2024-03-21 16:02:36.571677: Pseudo dice [0.9482, 0.9196]\n",
            "2024-03-21 16:02:36.571778: Epoch time: 89.18 s\n",
            "2024-03-21 16:02:36.571857: Yayy! New best EMA pseudo Dice: 0.8885\n",
            "2024-03-21 16:02:39.659183: \n",
            "2024-03-21 16:02:39.659385: Epoch 18\n",
            "2024-03-21 16:02:39.659504: Current learning rate: 0.00946\n",
            "2024-03-21 16:04:09.099677: train_loss -0.9109\n",
            "2024-03-21 16:04:09.100030: val_loss -0.9147\n",
            "2024-03-21 16:04:09.100176: Pseudo dice [0.9429, 0.9193]\n",
            "2024-03-21 16:04:09.100362: Epoch time: 89.44 s\n",
            "2024-03-21 16:04:09.100571: Yayy! New best EMA pseudo Dice: 0.8927\n",
            "2024-03-21 16:04:11.796070: \n",
            "2024-03-21 16:04:11.796241: Epoch 19\n",
            "2024-03-21 16:04:11.796395: Current learning rate: 0.00943\n",
            "2024-03-21 16:05:41.067615: train_loss -0.907\n",
            "2024-03-21 16:05:41.068122: val_loss -0.9197\n",
            "2024-03-21 16:05:41.068343: Pseudo dice [0.9469, 0.9222]\n",
            "2024-03-21 16:05:41.068473: Epoch time: 89.27 s\n",
            "2024-03-21 16:05:41.068574: Yayy! New best EMA pseudo Dice: 0.8969\n",
            "2024-03-21 16:05:43.924763: \n",
            "2024-03-21 16:05:43.924946: Epoch 20\n",
            "2024-03-21 16:05:43.925093: Current learning rate: 0.0094\n",
            "2024-03-21 16:07:13.490720: train_loss -0.9111\n",
            "2024-03-21 16:07:13.491069: val_loss -0.9228\n",
            "2024-03-21 16:07:13.491318: Pseudo dice [0.9519, 0.9236]\n",
            "2024-03-21 16:07:13.491518: Epoch time: 89.57 s\n",
            "2024-03-21 16:07:13.491680: Yayy! New best EMA pseudo Dice: 0.901\n",
            "2024-03-21 16:07:16.322144: \n",
            "2024-03-21 16:07:16.322333: Epoch 21\n",
            "2024-03-21 16:07:16.322473: Current learning rate: 0.00937\n",
            "2024-03-21 16:08:46.210381: train_loss -0.9138\n",
            "2024-03-21 16:08:46.210913: val_loss -0.9232\n",
            "2024-03-21 16:08:46.211212: Pseudo dice [0.9516, 0.9237]\n",
            "2024-03-21 16:08:46.211480: Epoch time: 89.89 s\n",
            "2024-03-21 16:08:46.211711: Yayy! New best EMA pseudo Dice: 0.9047\n",
            "2024-03-21 16:08:49.006784: \n",
            "2024-03-21 16:08:49.006963: Epoch 22\n",
            "2024-03-21 16:08:49.007077: Current learning rate: 0.00934\n",
            "2024-03-21 16:10:18.024066: train_loss -0.9176\n",
            "2024-03-21 16:10:18.024534: val_loss -0.9055\n",
            "2024-03-21 16:10:18.024791: Pseudo dice [0.9198, 0.9233]\n",
            "2024-03-21 16:10:18.025054: Epoch time: 89.02 s\n",
            "2024-03-21 16:10:18.029516: Yayy! New best EMA pseudo Dice: 0.9064\n",
            "2024-03-21 16:10:20.709836: \n",
            "2024-03-21 16:10:20.710020: Epoch 23\n",
            "2024-03-21 16:10:20.710143: Current learning rate: 0.00931\n",
            "2024-03-21 16:11:50.190689: train_loss -0.9147\n",
            "2024-03-21 16:11:50.191056: val_loss -0.9238\n",
            "2024-03-21 16:11:50.191270: Pseudo dice [0.9468, 0.9298]\n",
            "2024-03-21 16:11:50.191499: Epoch time: 89.48 s\n",
            "2024-03-21 16:11:50.191668: Yayy! New best EMA pseudo Dice: 0.9096\n",
            "2024-03-21 16:11:52.829164: \n",
            "2024-03-21 16:11:52.829424: Epoch 24\n",
            "2024-03-21 16:11:52.829545: Current learning rate: 0.00928\n",
            "2024-03-21 16:13:23.092119: train_loss -0.9163\n",
            "2024-03-21 16:13:23.092546: val_loss -0.9275\n",
            "2024-03-21 16:13:23.092743: Pseudo dice [0.9511, 0.9312]\n",
            "2024-03-21 16:13:23.092927: Epoch time: 90.26 s\n",
            "2024-03-21 16:13:23.093081: Yayy! New best EMA pseudo Dice: 0.9127\n",
            "2024-03-21 16:13:25.608110: \n",
            "2024-03-21 16:13:25.608369: Epoch 25\n",
            "2024-03-21 16:13:25.608506: Current learning rate: 0.00925\n",
            "2024-03-21 16:14:54.142165: train_loss -0.9204\n",
            "2024-03-21 16:14:54.142547: val_loss -0.9256\n",
            "2024-03-21 16:14:54.142689: Pseudo dice [0.9537, 0.9251]\n",
            "2024-03-21 16:14:54.142915: Epoch time: 88.54 s\n",
            "2024-03-21 16:14:54.143114: Yayy! New best EMA pseudo Dice: 0.9154\n",
            "2024-03-21 16:14:57.053484: \n",
            "2024-03-21 16:14:57.053689: Epoch 26\n",
            "2024-03-21 16:14:57.053845: Current learning rate: 0.00922\n",
            "2024-03-21 16:16:26.034551: train_loss -0.9216\n",
            "2024-03-21 16:16:26.035044: val_loss -0.9263\n",
            "2024-03-21 16:16:26.035233: Pseudo dice [0.9511, 0.9292]\n",
            "2024-03-21 16:16:26.035385: Epoch time: 88.98 s\n",
            "2024-03-21 16:16:26.035497: Yayy! New best EMA pseudo Dice: 0.9179\n",
            "2024-03-21 16:16:28.750362: \n",
            "2024-03-21 16:16:28.750565: Epoch 27\n",
            "2024-03-21 16:16:28.750721: Current learning rate: 0.00919\n",
            "2024-03-21 16:17:57.580368: train_loss -0.9195\n",
            "2024-03-21 16:17:57.580721: val_loss -0.9244\n",
            "2024-03-21 16:17:57.580870: Pseudo dice [0.9555, 0.9217]\n",
            "2024-03-21 16:17:57.581006: Epoch time: 88.83 s\n",
            "2024-03-21 16:17:57.581133: Yayy! New best EMA pseudo Dice: 0.9199\n",
            "2024-03-21 16:18:00.322858: \n",
            "2024-03-21 16:18:00.323046: Epoch 28\n",
            "2024-03-21 16:18:00.323188: Current learning rate: 0.00916\n",
            "2024-03-21 16:19:30.226360: train_loss -0.9185\n",
            "2024-03-21 16:19:30.226722: val_loss -0.919\n",
            "2024-03-21 16:19:30.227029: Pseudo dice [0.9441, 0.924]\n",
            "2024-03-21 16:19:30.227279: Epoch time: 89.9 s\n",
            "2024-03-21 16:19:30.227536: Yayy! New best EMA pseudo Dice: 0.9213\n",
            "2024-03-21 16:19:32.988977: \n",
            "2024-03-21 16:19:32.989162: Epoch 29\n",
            "2024-03-21 16:19:32.989325: Current learning rate: 0.00913\n",
            "2024-03-21 16:21:02.253853: train_loss -0.918\n",
            "2024-03-21 16:21:02.254595: val_loss -0.9254\n",
            "2024-03-21 16:21:02.255044: Pseudo dice [0.9492, 0.9277]\n",
            "2024-03-21 16:21:02.255560: Epoch time: 89.27 s\n",
            "2024-03-21 16:21:02.256002: Yayy! New best EMA pseudo Dice: 0.9231\n",
            "2024-03-21 16:21:05.171109: \n",
            "2024-03-21 16:21:05.171316: Epoch 30\n",
            "2024-03-21 16:21:05.171475: Current learning rate: 0.0091\n",
            "2024-03-21 16:22:34.726395: train_loss -0.9194\n",
            "2024-03-21 16:22:34.726794: val_loss -0.9282\n",
            "2024-03-21 16:22:34.726937: Pseudo dice [0.9548, 0.9277]\n",
            "2024-03-21 16:22:34.727068: Epoch time: 89.56 s\n",
            "2024-03-21 16:22:34.727175: Yayy! New best EMA pseudo Dice: 0.9249\n",
            "2024-03-21 16:22:37.373145: \n",
            "2024-03-21 16:22:37.373460: Epoch 31\n",
            "2024-03-21 16:22:37.373593: Current learning rate: 0.00907\n",
            "2024-03-21 16:24:06.145905: train_loss -0.9243\n",
            "2024-03-21 16:24:06.146319: val_loss -0.9269\n",
            "2024-03-21 16:24:06.146558: Pseudo dice [0.9514, 0.9293]\n",
            "2024-03-21 16:24:06.146755: Epoch time: 88.77 s\n",
            "2024-03-21 16:24:06.146879: Yayy! New best EMA pseudo Dice: 0.9264\n",
            "2024-03-21 16:24:08.989702: \n",
            "2024-03-21 16:24:08.989980: Epoch 32\n",
            "2024-03-21 16:24:08.990126: Current learning rate: 0.00903\n",
            "2024-03-21 16:25:38.477051: train_loss -0.922\n",
            "2024-03-21 16:25:38.477420: val_loss -0.9311\n",
            "2024-03-21 16:25:38.477582: Pseudo dice [0.9568, 0.9303]\n",
            "2024-03-21 16:25:38.477714: Epoch time: 89.49 s\n",
            "2024-03-21 16:25:38.477818: Yayy! New best EMA pseudo Dice: 0.9281\n",
            "2024-03-21 16:25:40.995824: \n",
            "2024-03-21 16:25:40.996234: Epoch 33\n",
            "2024-03-21 16:25:40.996385: Current learning rate: 0.009\n",
            "2024-03-21 16:27:11.453402: train_loss -0.9225\n",
            "2024-03-21 16:27:11.453898: val_loss -0.9257\n",
            "2024-03-21 16:27:11.454025: Pseudo dice [0.9523, 0.9268]\n",
            "2024-03-21 16:27:11.454175: Epoch time: 90.46 s\n",
            "2024-03-21 16:27:11.454309: Yayy! New best EMA pseudo Dice: 0.9293\n",
            "2024-03-21 16:27:14.330970: \n",
            "2024-03-21 16:27:14.331151: Epoch 34\n",
            "2024-03-21 16:27:14.331317: Current learning rate: 0.00897\n",
            "2024-03-21 16:28:43.894223: train_loss -0.9244\n",
            "2024-03-21 16:28:43.894635: val_loss -0.9333\n",
            "2024-03-21 16:28:43.894788: Pseudo dice [0.9558, 0.9346]\n",
            "2024-03-21 16:28:43.894920: Epoch time: 89.56 s\n",
            "2024-03-21 16:28:43.895077: Yayy! New best EMA pseudo Dice: 0.9309\n",
            "2024-03-21 16:28:46.522132: \n",
            "2024-03-21 16:28:46.522367: Epoch 35\n",
            "2024-03-21 16:28:46.522543: Current learning rate: 0.00894\n",
            "2024-03-21 16:30:15.857784: train_loss -0.9251\n",
            "2024-03-21 16:30:15.858196: val_loss -0.9281\n",
            "2024-03-21 16:30:15.858374: Pseudo dice [0.951, 0.9313]\n",
            "2024-03-21 16:30:15.858525: Epoch time: 89.34 s\n",
            "2024-03-21 16:30:15.858638: Yayy! New best EMA pseudo Dice: 0.9319\n",
            "2024-03-21 16:30:18.548377: \n",
            "2024-03-21 16:30:18.548653: Epoch 36\n",
            "2024-03-21 16:30:18.548785: Current learning rate: 0.00891\n",
            "2024-03-21 16:31:47.631348: train_loss -0.9276\n",
            "2024-03-21 16:31:47.631840: val_loss -0.9282\n",
            "2024-03-21 16:31:47.631985: Pseudo dice [0.9528, 0.9299]\n",
            "2024-03-21 16:31:47.632119: Epoch time: 89.08 s\n",
            "2024-03-21 16:31:47.632250: Yayy! New best EMA pseudo Dice: 0.9328\n",
            "2024-03-21 16:31:50.695780: \n",
            "2024-03-21 16:31:50.695988: Epoch 37\n",
            "2024-03-21 16:31:50.696138: Current learning rate: 0.00888\n",
            "2024-03-21 16:33:20.219885: train_loss -0.9271\n",
            "2024-03-21 16:33:20.220549: val_loss -0.9304\n",
            "2024-03-21 16:33:20.221042: Pseudo dice [0.9547, 0.9326]\n",
            "2024-03-21 16:33:20.221541: Epoch time: 89.53 s\n",
            "2024-03-21 16:33:20.221775: Yayy! New best EMA pseudo Dice: 0.9339\n",
            "2024-03-21 16:33:22.886154: \n",
            "2024-03-21 16:33:22.886353: Epoch 38\n",
            "2024-03-21 16:33:22.886491: Current learning rate: 0.00885\n",
            "2024-03-21 16:34:52.644886: train_loss -0.9278\n",
            "2024-03-21 16:34:52.645322: val_loss -0.9263\n",
            "2024-03-21 16:34:52.645537: Pseudo dice [0.9523, 0.9269]\n",
            "2024-03-21 16:34:52.645781: Epoch time: 89.76 s\n",
            "2024-03-21 16:34:52.645975: Yayy! New best EMA pseudo Dice: 0.9345\n",
            "2024-03-21 16:34:55.337087: \n",
            "2024-03-21 16:34:55.337266: Epoch 39\n",
            "2024-03-21 16:34:55.337418: Current learning rate: 0.00882\n",
            "2024-03-21 16:36:24.281295: train_loss -0.9279\n",
            "2024-03-21 16:36:24.281853: val_loss -0.93\n",
            "2024-03-21 16:36:24.282039: Pseudo dice [0.9518, 0.9335]\n",
            "2024-03-21 16:36:24.282176: Epoch time: 88.95 s\n",
            "2024-03-21 16:36:24.282299: Yayy! New best EMA pseudo Dice: 0.9353\n",
            "2024-03-21 16:36:27.157123: \n",
            "2024-03-21 16:36:27.157430: Epoch 40\n",
            "2024-03-21 16:36:27.157565: Current learning rate: 0.00879\n",
            "2024-03-21 16:37:57.095268: train_loss -0.9211\n",
            "2024-03-21 16:37:57.095659: val_loss -0.9302\n",
            "2024-03-21 16:37:57.095874: Pseudo dice [0.9555, 0.9296]\n",
            "2024-03-21 16:37:57.096083: Epoch time: 89.94 s\n",
            "2024-03-21 16:37:57.096266: Yayy! New best EMA pseudo Dice: 0.936\n",
            "2024-03-21 16:38:00.059070: \n",
            "2024-03-21 16:38:00.059328: Epoch 41\n",
            "2024-03-21 16:38:00.059536: Current learning rate: 0.00876\n",
            "2024-03-21 16:39:29.668402: train_loss -0.9267\n",
            "2024-03-21 16:39:29.669040: val_loss -0.929\n",
            "2024-03-21 16:39:29.669626: Pseudo dice [0.9553, 0.9293]\n",
            "2024-03-21 16:39:29.670068: Epoch time: 89.61 s\n",
            "2024-03-21 16:39:29.670483: Yayy! New best EMA pseudo Dice: 0.9367\n",
            "2024-03-21 16:39:32.453607: \n",
            "2024-03-21 16:39:32.453895: Epoch 42\n",
            "2024-03-21 16:39:32.454057: Current learning rate: 0.00873\n",
            "2024-03-21 16:41:01.183884: train_loss -0.9264\n",
            "2024-03-21 16:41:01.184388: val_loss -0.9316\n",
            "2024-03-21 16:41:01.184528: Pseudo dice [0.9553, 0.9331]\n",
            "2024-03-21 16:41:01.184640: Epoch time: 88.73 s\n",
            "2024-03-21 16:41:01.184735: Yayy! New best EMA pseudo Dice: 0.9374\n",
            "2024-03-21 16:41:03.744559: \n",
            "2024-03-21 16:41:03.744739: Epoch 43\n",
            "2024-03-21 16:41:03.744881: Current learning rate: 0.0087\n",
            "2024-03-21 16:42:33.532881: train_loss -0.9273\n",
            "2024-03-21 16:42:33.533267: val_loss -0.9322\n",
            "2024-03-21 16:42:33.533448: Pseudo dice [0.955, 0.9343]\n",
            "2024-03-21 16:42:33.533682: Epoch time: 89.79 s\n",
            "2024-03-21 16:42:33.533876: Yayy! New best EMA pseudo Dice: 0.9381\n",
            "2024-03-21 16:42:36.511419: \n",
            "2024-03-21 16:42:36.511595: Epoch 44\n",
            "2024-03-21 16:42:36.511717: Current learning rate: 0.00867\n",
            "2024-03-21 16:44:05.500136: train_loss -0.9217\n",
            "2024-03-21 16:44:05.500597: val_loss -0.9205\n",
            "2024-03-21 16:44:05.500752: Pseudo dice [0.9417, 0.9275]\n",
            "2024-03-21 16:44:05.500861: Epoch time: 88.99 s\n",
            "2024-03-21 16:44:07.342598: \n",
            "2024-03-21 16:44:07.342787: Epoch 45\n",
            "2024-03-21 16:44:07.342950: Current learning rate: 0.00864\n",
            "2024-03-21 16:45:36.318605: train_loss -0.9238\n",
            "2024-03-21 16:45:36.319199: val_loss -0.9285\n",
            "2024-03-21 16:45:36.319446: Pseudo dice [0.9551, 0.9273]\n",
            "2024-03-21 16:45:36.319592: Epoch time: 88.98 s\n",
            "2024-03-21 16:45:38.258410: \n",
            "2024-03-21 16:45:38.258593: Epoch 46\n",
            "2024-03-21 16:45:38.258735: Current learning rate: 0.00861\n",
            "2024-03-21 16:47:07.168632: train_loss -0.9273\n",
            "2024-03-21 16:47:07.168982: val_loss -0.9323\n",
            "2024-03-21 16:47:07.169252: Pseudo dice [0.9565, 0.9324]\n",
            "2024-03-21 16:47:07.169415: Epoch time: 88.91 s\n",
            "2024-03-21 16:47:07.169526: Yayy! New best EMA pseudo Dice: 0.9388\n",
            "2024-03-21 16:47:09.849927: \n",
            "2024-03-21 16:47:09.850131: Epoch 47\n",
            "2024-03-21 16:47:09.850276: Current learning rate: 0.00858\n",
            "2024-03-21 16:48:39.089747: train_loss -0.9292\n",
            "2024-03-21 16:48:39.090361: val_loss -0.9345\n",
            "2024-03-21 16:48:39.090656: Pseudo dice [0.959, 0.9322]\n",
            "2024-03-21 16:48:39.090901: Epoch time: 89.24 s\n",
            "2024-03-21 16:48:39.091110: Yayy! New best EMA pseudo Dice: 0.9394\n",
            "2024-03-21 16:48:41.688417: \n",
            "2024-03-21 16:48:41.688733: Epoch 48\n",
            "2024-03-21 16:48:41.688895: Current learning rate: 0.00855\n",
            "2024-03-21 16:50:10.589440: train_loss -0.932\n",
            "2024-03-21 16:50:10.589748: val_loss -0.9344\n",
            "2024-03-21 16:50:10.589890: Pseudo dice [0.9579, 0.9347]\n",
            "2024-03-21 16:50:10.590011: Epoch time: 88.9 s\n",
            "2024-03-21 16:50:10.590116: Yayy! New best EMA pseudo Dice: 0.9401\n",
            "2024-03-21 16:50:13.362076: \n",
            "2024-03-21 16:50:13.362300: Epoch 49\n",
            "2024-03-21 16:50:13.362456: Current learning rate: 0.00852\n",
            "2024-03-21 16:51:41.783986: train_loss -0.9314\n",
            "2024-03-21 16:51:41.784694: val_loss -0.9288\n",
            "2024-03-21 16:51:41.785220: Pseudo dice [0.9554, 0.9275]\n",
            "2024-03-21 16:51:41.785967: Epoch time: 88.42 s\n",
            "2024-03-21 16:51:42.251954: Yayy! New best EMA pseudo Dice: 0.9403\n",
            "2024-03-21 16:51:44.794531: \n",
            "2024-03-21 16:51:44.794723: Epoch 50\n",
            "2024-03-21 16:51:44.794865: Current learning rate: 0.00849\n",
            "2024-03-21 16:53:11.392585: train_loss -0.9296\n",
            "2024-03-21 16:53:11.392896: val_loss -0.9331\n",
            "2024-03-21 16:53:11.393008: Pseudo dice [0.9534, 0.9369]\n",
            "2024-03-21 16:53:11.393153: Epoch time: 86.6 s\n",
            "2024-03-21 16:53:11.393254: Yayy! New best EMA pseudo Dice: 0.9407\n",
            "2024-03-21 16:53:13.816646: \n",
            "2024-03-21 16:53:13.816822: Epoch 51\n",
            "2024-03-21 16:53:13.816971: Current learning rate: 0.00846\n",
            "2024-03-21 16:54:38.620001: train_loss -0.9329\n",
            "2024-03-21 16:54:38.620375: val_loss -0.9324\n",
            "2024-03-21 16:54:38.620583: Pseudo dice [0.9549, 0.9337]\n",
            "2024-03-21 16:54:38.620740: Epoch time: 84.8 s\n",
            "2024-03-21 16:54:38.620858: Yayy! New best EMA pseudo Dice: 0.9411\n",
            "2024-03-21 16:54:41.408179: \n",
            "2024-03-21 16:54:41.408358: Epoch 52\n",
            "2024-03-21 16:54:41.408484: Current learning rate: 0.00843\n",
            "2024-03-21 16:56:06.128375: train_loss -0.932\n",
            "2024-03-21 16:56:06.128764: val_loss -0.9311\n",
            "2024-03-21 16:56:06.128955: Pseudo dice [0.956, 0.9307]\n",
            "2024-03-21 16:56:06.129109: Epoch time: 84.72 s\n",
            "2024-03-21 16:56:06.129203: Yayy! New best EMA pseudo Dice: 0.9413\n",
            "2024-03-21 16:56:08.764526: \n",
            "2024-03-21 16:56:08.764689: Epoch 53\n",
            "2024-03-21 16:56:08.764808: Current learning rate: 0.00839\n",
            "2024-03-21 16:57:32.963367: train_loss -0.9335\n",
            "2024-03-21 16:57:32.963701: val_loss -0.9315\n",
            "2024-03-21 16:57:32.963840: Pseudo dice [0.9529, 0.9342]\n",
            "2024-03-21 16:57:32.964009: Epoch time: 84.2 s\n",
            "2024-03-21 16:57:32.964209: Yayy! New best EMA pseudo Dice: 0.9416\n",
            "2024-03-21 16:57:35.724768: \n",
            "2024-03-21 16:57:35.725008: Epoch 54\n",
            "2024-03-21 16:57:35.725166: Current learning rate: 0.00836\n",
            "2024-03-21 16:59:00.107710: train_loss -0.9328\n",
            "2024-03-21 16:59:00.107996: val_loss -0.9272\n",
            "2024-03-21 16:59:00.108100: Pseudo dice [0.9539, 0.9265]\n",
            "2024-03-21 16:59:00.108248: Epoch time: 84.38 s\n",
            "2024-03-21 16:59:02.077932: \n",
            "2024-03-21 16:59:02.078145: Epoch 55\n",
            "2024-03-21 16:59:02.078267: Current learning rate: 0.00833\n",
            "2024-03-21 17:00:26.987260: train_loss -0.9337\n",
            "2024-03-21 17:00:26.987777: val_loss -0.9382\n",
            "2024-03-21 17:00:26.987965: Pseudo dice [0.9605, 0.9382]\n",
            "2024-03-21 17:00:26.988223: Epoch time: 84.91 s\n",
            "2024-03-21 17:00:26.988450: Yayy! New best EMA pseudo Dice: 0.9422\n",
            "2024-03-21 17:00:29.928851: \n",
            "2024-03-21 17:00:29.929043: Epoch 56\n",
            "2024-03-21 17:00:29.929176: Current learning rate: 0.0083\n",
            "2024-03-21 17:01:54.178217: train_loss -0.9322\n",
            "2024-03-21 17:01:54.178708: val_loss -0.9388\n",
            "2024-03-21 17:01:54.178908: Pseudo dice [0.9598, 0.9386]\n",
            "2024-03-21 17:01:54.179085: Epoch time: 84.25 s\n",
            "2024-03-21 17:01:54.179546: Yayy! New best EMA pseudo Dice: 0.9429\n",
            "2024-03-21 17:01:57.064373: \n",
            "2024-03-21 17:01:57.064544: Epoch 57\n",
            "2024-03-21 17:01:57.064660: Current learning rate: 0.00827\n",
            "2024-03-21 17:03:22.241552: train_loss -0.9332\n",
            "2024-03-21 17:03:22.241988: val_loss -0.9272\n",
            "2024-03-21 17:03:22.242246: Pseudo dice [0.9482, 0.9312]\n",
            "2024-03-21 17:03:22.242478: Epoch time: 85.18 s\n",
            "2024-03-21 17:03:24.131940: \n",
            "2024-03-21 17:03:24.132099: Epoch 58\n",
            "2024-03-21 17:03:24.132221: Current learning rate: 0.00824\n",
            "2024-03-21 17:04:49.480024: train_loss -0.9343\n",
            "2024-03-21 17:04:49.480390: val_loss -0.9353\n",
            "2024-03-21 17:04:49.480530: Pseudo dice [0.9578, 0.9353]\n",
            "2024-03-21 17:04:49.480684: Epoch time: 85.35 s\n",
            "2024-03-21 17:04:49.480784: Yayy! New best EMA pseudo Dice: 0.943\n",
            "2024-03-21 17:04:52.132761: \n",
            "2024-03-21 17:04:52.132971: Epoch 59\n",
            "2024-03-21 17:04:52.133093: Current learning rate: 0.00821\n",
            "2024-03-21 17:06:17.907178: train_loss -0.9352\n",
            "2024-03-21 17:06:17.907703: val_loss -0.9332\n",
            "2024-03-21 17:06:17.908169: Pseudo dice [0.9578, 0.9321]\n",
            "2024-03-21 17:06:17.908412: Epoch time: 85.78 s\n",
            "2024-03-21 17:06:17.908540: Yayy! New best EMA pseudo Dice: 0.9432\n",
            "2024-03-21 17:06:20.525901: \n",
            "2024-03-21 17:06:20.526147: Epoch 60\n",
            "2024-03-21 17:06:20.526274: Current learning rate: 0.00818\n",
            "2024-03-21 17:07:45.896428: train_loss -0.9336\n",
            "2024-03-21 17:07:45.896725: val_loss -0.9332\n",
            "2024-03-21 17:07:45.896864: Pseudo dice [0.9553, 0.9335]\n",
            "2024-03-21 17:07:45.896986: Epoch time: 85.37 s\n",
            "2024-03-21 17:07:45.897106: Yayy! New best EMA pseudo Dice: 0.9433\n",
            "2024-03-21 17:07:48.435964: \n",
            "2024-03-21 17:07:48.436131: Epoch 61\n",
            "2024-03-21 17:07:48.436249: Current learning rate: 0.00815\n",
            "2024-03-21 17:09:13.623065: train_loss -0.9352\n",
            "2024-03-21 17:09:13.623527: val_loss -0.9353\n",
            "2024-03-21 17:09:13.623792: Pseudo dice [0.958, 0.9344]\n",
            "2024-03-21 17:09:13.624061: Epoch time: 85.19 s\n",
            "2024-03-21 17:09:13.624311: Yayy! New best EMA pseudo Dice: 0.9436\n",
            "2024-03-21 17:09:16.226645: \n",
            "2024-03-21 17:09:16.226815: Epoch 62\n",
            "2024-03-21 17:09:16.226930: Current learning rate: 0.00812\n",
            "2024-03-21 17:10:41.923518: train_loss -0.9358\n",
            "2024-03-21 17:10:41.923819: val_loss -0.9332\n",
            "2024-03-21 17:10:41.923932: Pseudo dice [0.954, 0.9363]\n",
            "2024-03-21 17:10:41.924035: Epoch time: 85.7 s\n",
            "2024-03-21 17:10:41.924117: Yayy! New best EMA pseudo Dice: 0.9438\n",
            "2024-03-21 17:10:44.522560: \n",
            "2024-03-21 17:10:44.522792: Epoch 63\n",
            "2024-03-21 17:10:44.522911: Current learning rate: 0.00809\n",
            "2024-03-21 17:12:09.738508: train_loss -0.9343\n",
            "2024-03-21 17:12:09.738851: val_loss -0.9288\n",
            "2024-03-21 17:12:09.739000: Pseudo dice [0.952, 0.9295]\n",
            "2024-03-21 17:12:09.739133: Epoch time: 85.22 s\n",
            "2024-03-21 17:12:11.828375: \n",
            "2024-03-21 17:12:11.828660: Epoch 64\n",
            "2024-03-21 17:12:11.828795: Current learning rate: 0.00806\n",
            "2024-03-21 17:13:36.875008: train_loss -0.934\n",
            "2024-03-21 17:13:36.875371: val_loss -0.922\n",
            "2024-03-21 17:13:36.875514: Pseudo dice [0.95, 0.9211]\n",
            "2024-03-21 17:13:36.875666: Epoch time: 85.05 s\n",
            "2024-03-21 17:13:39.117197: \n",
            "2024-03-21 17:13:39.117391: Epoch 65\n",
            "2024-03-21 17:13:39.117516: Current learning rate: 0.00803\n",
            "2024-03-21 17:15:04.037973: train_loss -0.9349\n",
            "2024-03-21 17:15:04.038361: val_loss -0.9316\n",
            "2024-03-21 17:15:04.038591: Pseudo dice [0.9548, 0.9304]\n",
            "2024-03-21 17:15:04.038772: Epoch time: 84.92 s\n",
            "2024-03-21 17:15:06.067349: \n",
            "2024-03-21 17:15:06.067592: Epoch 66\n",
            "2024-03-21 17:15:06.067727: Current learning rate: 0.008\n",
            "2024-03-21 17:16:31.346948: train_loss -0.9335\n",
            "2024-03-21 17:16:31.347377: val_loss -0.9363\n",
            "2024-03-21 17:16:31.347597: Pseudo dice [0.9591, 0.9344]\n",
            "2024-03-21 17:16:31.347800: Epoch time: 85.28 s\n",
            "2024-03-21 17:16:33.154175: \n",
            "2024-03-21 17:16:33.154354: Epoch 67\n",
            "2024-03-21 17:16:33.154495: Current learning rate: 0.00797\n",
            "2024-03-21 17:17:57.538673: train_loss -0.9369\n",
            "2024-03-21 17:17:57.538934: val_loss -0.9382\n",
            "2024-03-21 17:17:57.539040: Pseudo dice [0.9611, 0.9367]\n",
            "2024-03-21 17:17:57.539135: Epoch time: 84.39 s\n",
            "2024-03-21 17:17:59.589827: \n",
            "2024-03-21 17:17:59.590078: Epoch 68\n",
            "2024-03-21 17:17:59.590204: Current learning rate: 0.00793\n",
            "2024-03-21 17:19:24.638273: train_loss -0.9361\n",
            "2024-03-21 17:19:24.638642: val_loss -0.9317\n",
            "2024-03-21 17:19:24.638966: Pseudo dice [0.9529, 0.9332]\n",
            "2024-03-21 17:19:24.639106: Epoch time: 85.05 s\n",
            "2024-03-21 17:19:26.720743: \n",
            "2024-03-21 17:19:26.720923: Epoch 69\n",
            "2024-03-21 17:19:26.721043: Current learning rate: 0.0079\n",
            "2024-03-21 17:20:52.947617: train_loss -0.9363\n",
            "2024-03-21 17:20:52.947981: val_loss -0.9347\n",
            "2024-03-21 17:20:52.948155: Pseudo dice [0.958, 0.9339]\n",
            "2024-03-21 17:20:52.948416: Epoch time: 86.23 s\n",
            "2024-03-21 17:20:52.948590: Yayy! New best EMA pseudo Dice: 0.9438\n",
            "2024-03-21 17:20:55.576587: \n",
            "2024-03-21 17:20:55.576756: Epoch 70\n",
            "2024-03-21 17:20:55.576902: Current learning rate: 0.00787\n",
            "2024-03-21 17:22:21.009199: train_loss -0.9372\n",
            "2024-03-21 17:22:21.009557: val_loss -0.935\n",
            "2024-03-21 17:22:21.009746: Pseudo dice [0.9571, 0.9345]\n",
            "2024-03-21 17:22:21.009924: Epoch time: 85.43 s\n",
            "2024-03-21 17:22:21.010081: Yayy! New best EMA pseudo Dice: 0.944\n",
            "2024-03-21 17:22:23.490923: \n",
            "2024-03-21 17:22:23.491091: Epoch 71\n",
            "2024-03-21 17:22:23.491221: Current learning rate: 0.00784\n",
            "2024-03-21 17:23:48.231011: train_loss -0.9379\n",
            "2024-03-21 17:23:48.231760: val_loss -0.9367\n",
            "2024-03-21 17:23:48.232060: Pseudo dice [0.9577, 0.9368]\n",
            "2024-03-21 17:23:48.232463: Epoch time: 84.74 s\n",
            "2024-03-21 17:23:48.232897: Yayy! New best EMA pseudo Dice: 0.9443\n",
            "2024-03-21 17:23:50.999019: \n",
            "2024-03-21 17:23:50.999182: Epoch 72\n",
            "2024-03-21 17:23:50.999311: Current learning rate: 0.00781\n",
            "2024-03-21 17:25:16.008412: train_loss -0.9374\n",
            "2024-03-21 17:25:16.008933: val_loss -0.9322\n",
            "2024-03-21 17:25:16.009086: Pseudo dice [0.9504, 0.939]\n",
            "2024-03-21 17:25:16.009225: Epoch time: 85.01 s\n",
            "2024-03-21 17:25:16.009369: Yayy! New best EMA pseudo Dice: 0.9444\n",
            "2024-03-21 17:25:18.616313: \n",
            "2024-03-21 17:25:18.616522: Epoch 73\n",
            "2024-03-21 17:25:18.616704: Current learning rate: 0.00778\n",
            "2024-03-21 17:26:45.350817: train_loss -0.9366\n",
            "2024-03-21 17:26:45.351217: val_loss -0.9356\n",
            "2024-03-21 17:26:45.351427: Pseudo dice [0.9553, 0.9374]\n",
            "2024-03-21 17:26:45.351568: Epoch time: 86.74 s\n",
            "2024-03-21 17:26:45.351678: Yayy! New best EMA pseudo Dice: 0.9446\n",
            "2024-03-21 17:26:48.173826: \n",
            "2024-03-21 17:26:48.173994: Epoch 74\n",
            "2024-03-21 17:26:48.174111: Current learning rate: 0.00775\n",
            "2024-03-21 17:28:13.287443: train_loss -0.9327\n",
            "2024-03-21 17:28:13.287796: val_loss -0.9316\n",
            "2024-03-21 17:28:13.288012: Pseudo dice [0.9538, 0.9326]\n",
            "2024-03-21 17:28:13.288234: Epoch time: 85.11 s\n",
            "2024-03-21 17:28:15.156749: \n",
            "2024-03-21 17:28:15.156920: Epoch 75\n",
            "2024-03-21 17:28:15.157036: Current learning rate: 0.00772\n",
            "2024-03-21 17:29:40.278457: train_loss -0.9353\n",
            "2024-03-21 17:29:40.278805: val_loss -0.93\n",
            "2024-03-21 17:29:40.278941: Pseudo dice [0.9524, 0.9308]\n",
            "2024-03-21 17:29:40.279060: Epoch time: 85.12 s\n",
            "2024-03-21 17:29:42.569217: \n",
            "2024-03-21 17:29:42.569521: Epoch 76\n",
            "2024-03-21 17:29:42.569647: Current learning rate: 0.00769\n",
            "2024-03-21 17:31:07.508245: train_loss -0.9339\n",
            "2024-03-21 17:31:07.508661: val_loss -0.9338\n",
            "2024-03-21 17:31:07.508922: Pseudo dice [0.9581, 0.9325]\n",
            "2024-03-21 17:31:07.509191: Epoch time: 84.94 s\n",
            "2024-03-21 17:31:09.630234: \n",
            "2024-03-21 17:31:09.630419: Epoch 77\n",
            "2024-03-21 17:31:09.630542: Current learning rate: 0.00766\n",
            "2024-03-21 17:32:33.549002: train_loss -0.9337\n",
            "2024-03-21 17:32:33.549394: val_loss -0.9339\n",
            "2024-03-21 17:32:33.549574: Pseudo dice [0.955, 0.9357]\n",
            "2024-03-21 17:32:33.549700: Epoch time: 83.92 s\n",
            "2024-03-21 17:32:35.685160: \n",
            "2024-03-21 17:32:35.685343: Epoch 78\n",
            "2024-03-21 17:32:35.685466: Current learning rate: 0.00763\n",
            "2024-03-21 17:34:00.637125: train_loss -0.9363\n",
            "2024-03-21 17:34:00.637433: val_loss -0.934\n",
            "2024-03-21 17:34:00.637557: Pseudo dice [0.955, 0.935]\n",
            "2024-03-21 17:34:00.637665: Epoch time: 84.95 s\n",
            "2024-03-21 17:34:02.638362: \n",
            "2024-03-21 17:34:02.638592: Epoch 79\n",
            "2024-03-21 17:34:02.638722: Current learning rate: 0.0076\n",
            "2024-03-21 17:35:27.734643: train_loss -0.9381\n",
            "2024-03-21 17:35:27.735079: val_loss -0.9357\n",
            "2024-03-21 17:35:27.735311: Pseudo dice [0.9582, 0.9341]\n",
            "2024-03-21 17:35:27.735478: Epoch time: 85.1 s\n",
            "2024-03-21 17:35:27.735598: Yayy! New best EMA pseudo Dice: 0.9446\n",
            "2024-03-21 17:35:30.759583: \n",
            "2024-03-21 17:35:30.759765: Epoch 80\n",
            "2024-03-21 17:35:30.759887: Current learning rate: 0.00756\n",
            "2024-03-21 17:36:56.388199: train_loss -0.9381\n",
            "2024-03-21 17:36:56.388606: val_loss -0.9378\n",
            "2024-03-21 17:36:56.388773: Pseudo dice [0.9625, 0.9337]\n",
            "2024-03-21 17:36:56.388883: Epoch time: 85.63 s\n",
            "2024-03-21 17:36:56.389065: Yayy! New best EMA pseudo Dice: 0.945\n",
            "2024-03-21 17:36:59.153243: \n",
            "2024-03-21 17:36:59.153418: Epoch 81\n",
            "2024-03-21 17:36:59.153537: Current learning rate: 0.00753\n",
            "2024-03-21 17:38:24.397669: train_loss -0.9367\n",
            "2024-03-21 17:38:24.397955: val_loss -0.9363\n",
            "2024-03-21 17:38:24.398074: Pseudo dice [0.9571, 0.9371]\n",
            "2024-03-21 17:38:24.398183: Epoch time: 85.25 s\n",
            "2024-03-21 17:38:24.398295: Yayy! New best EMA pseudo Dice: 0.9452\n",
            "2024-03-21 17:38:27.194458: \n",
            "2024-03-21 17:38:27.194669: Epoch 82\n",
            "2024-03-21 17:38:27.194802: Current learning rate: 0.0075\n",
            "2024-03-21 17:39:52.100563: train_loss -0.9373\n",
            "2024-03-21 17:39:52.100904: val_loss -0.9378\n",
            "2024-03-21 17:39:52.101105: Pseudo dice [0.9597, 0.9361]\n",
            "2024-03-21 17:39:52.101337: Epoch time: 84.91 s\n",
            "2024-03-21 17:39:52.101495: Yayy! New best EMA pseudo Dice: 0.9455\n",
            "2024-03-21 17:39:54.584993: \n",
            "2024-03-21 17:39:54.585228: Epoch 83\n",
            "2024-03-21 17:39:54.585393: Current learning rate: 0.00747\n",
            "2024-03-21 17:41:19.577590: train_loss -0.9361\n",
            "2024-03-21 17:41:19.577898: val_loss -0.9365\n",
            "2024-03-21 17:41:19.578058: Pseudo dice [0.9602, 0.9336]\n",
            "2024-03-21 17:41:19.578184: Epoch time: 84.99 s\n",
            "2024-03-21 17:41:19.578336: Yayy! New best EMA pseudo Dice: 0.9456\n",
            "2024-03-21 17:41:22.230728: \n",
            "2024-03-21 17:41:22.230894: Epoch 84\n",
            "2024-03-21 17:41:22.231034: Current learning rate: 0.00744\n",
            "2024-03-21 17:42:47.306373: train_loss -0.9374\n",
            "2024-03-21 17:42:47.306744: val_loss -0.9361\n",
            "2024-03-21 17:42:47.306886: Pseudo dice [0.9571, 0.9354]\n",
            "2024-03-21 17:42:47.307024: Epoch time: 85.08 s\n",
            "2024-03-21 17:42:47.307122: Yayy! New best EMA pseudo Dice: 0.9457\n",
            "2024-03-21 17:42:49.939076: \n",
            "2024-03-21 17:42:49.939320: Epoch 85\n",
            "2024-03-21 17:42:49.939458: Current learning rate: 0.00741\n",
            "2024-03-21 17:44:14.565302: train_loss -0.9366\n",
            "2024-03-21 17:44:14.565628: val_loss -0.9378\n",
            "2024-03-21 17:44:14.565757: Pseudo dice [0.9594, 0.9366]\n",
            "2024-03-21 17:44:14.565861: Epoch time: 84.63 s\n",
            "2024-03-21 17:44:14.565943: Yayy! New best EMA pseudo Dice: 0.9459\n",
            "2024-03-21 17:44:17.225098: \n",
            "2024-03-21 17:44:17.225405: Epoch 86\n",
            "2024-03-21 17:44:17.225544: Current learning rate: 0.00738\n",
            "2024-03-21 17:45:41.218857: train_loss -0.9357\n",
            "2024-03-21 17:45:41.219151: val_loss -0.937\n",
            "2024-03-21 17:45:41.219308: Pseudo dice [0.9574, 0.9367]\n",
            "2024-03-21 17:45:41.219440: Epoch time: 83.99 s\n",
            "2024-03-21 17:45:41.219546: Yayy! New best EMA pseudo Dice: 0.946\n",
            "2024-03-21 17:45:43.558656: \n",
            "2024-03-21 17:45:43.558906: Epoch 87\n",
            "2024-03-21 17:45:43.559028: Current learning rate: 0.00735\n",
            "2024-03-21 17:47:08.130033: train_loss -0.9373\n",
            "2024-03-21 17:47:08.130400: val_loss -0.9369\n",
            "2024-03-21 17:47:08.130546: Pseudo dice [0.9577, 0.9363]\n",
            "2024-03-21 17:47:08.130659: Epoch time: 84.57 s\n",
            "2024-03-21 17:47:08.130800: Yayy! New best EMA pseudo Dice: 0.9461\n",
            "2024-03-21 17:47:10.579356: \n",
            "2024-03-21 17:47:10.579682: Epoch 88\n",
            "2024-03-21 17:47:10.579805: Current learning rate: 0.00732\n",
            "2024-03-21 17:48:34.941734: train_loss -0.9373\n",
            "2024-03-21 17:48:34.942164: val_loss -0.933\n",
            "2024-03-21 17:48:34.942415: Pseudo dice [0.9562, 0.933]\n",
            "2024-03-21 17:48:34.942616: Epoch time: 84.36 s\n",
            "2024-03-21 17:48:36.947903: \n",
            "2024-03-21 17:48:36.948082: Epoch 89\n",
            "2024-03-21 17:48:36.948228: Current learning rate: 0.00729\n",
            "2024-03-21 17:50:01.790442: train_loss -0.9385\n",
            "2024-03-21 17:50:01.790719: val_loss -0.9376\n",
            "2024-03-21 17:50:01.790823: Pseudo dice [0.9596, 0.9359]\n",
            "2024-03-21 17:50:01.790931: Epoch time: 84.84 s\n",
            "2024-03-21 17:50:01.791003: Yayy! New best EMA pseudo Dice: 0.9461\n",
            "2024-03-21 17:50:04.233331: \n",
            "2024-03-21 17:50:04.233498: Epoch 90\n",
            "2024-03-21 17:50:04.233610: Current learning rate: 0.00725\n",
            "2024-03-21 17:51:28.208422: train_loss -0.9384\n",
            "2024-03-21 17:51:28.208803: val_loss -0.9358\n",
            "2024-03-21 17:51:28.208958: Pseudo dice [0.9606, 0.9321]\n",
            "2024-03-21 17:51:28.209080: Epoch time: 83.98 s\n",
            "2024-03-21 17:51:28.209179: Yayy! New best EMA pseudo Dice: 0.9462\n",
            "2024-03-21 17:51:30.861194: \n",
            "2024-03-21 17:51:30.861480: Epoch 91\n",
            "2024-03-21 17:51:30.861645: Current learning rate: 0.00722\n",
            "2024-03-21 17:52:55.037621: train_loss -0.9361\n",
            "2024-03-21 17:52:55.038131: val_loss -0.9304\n",
            "2024-03-21 17:52:55.038465: Pseudo dice [0.9529, 0.9309]\n",
            "2024-03-21 17:52:55.038634: Epoch time: 84.18 s\n",
            "2024-03-21 17:52:56.840021: \n",
            "2024-03-21 17:52:56.840182: Epoch 92\n",
            "2024-03-21 17:52:56.840328: Current learning rate: 0.00719\n",
            "2024-03-21 17:54:20.282494: train_loss -0.9342\n",
            "2024-03-21 17:54:20.282825: val_loss -0.9327\n",
            "2024-03-21 17:54:20.282979: Pseudo dice [0.9551, 0.9325]\n",
            "2024-03-21 17:54:20.283102: Epoch time: 83.44 s\n",
            "2024-03-21 17:54:22.046447: \n",
            "2024-03-21 17:54:22.046695: Epoch 93\n",
            "2024-03-21 17:54:22.046816: Current learning rate: 0.00716\n",
            "2024-03-21 17:55:45.432352: train_loss -0.9359\n",
            "2024-03-21 17:55:45.432672: val_loss -0.9343\n",
            "2024-03-21 17:55:45.432818: Pseudo dice [0.959, 0.9321]\n",
            "2024-03-21 17:55:45.432930: Epoch time: 83.39 s\n",
            "2024-03-21 17:55:47.391097: \n",
            "2024-03-21 17:55:47.391415: Epoch 94\n",
            "2024-03-21 17:55:47.391576: Current learning rate: 0.00713\n",
            "2024-03-21 17:57:10.830605: train_loss -0.938\n",
            "2024-03-21 17:57:10.831130: val_loss -0.9375\n",
            "2024-03-21 17:57:10.831439: Pseudo dice [0.9597, 0.9361]\n",
            "2024-03-21 17:57:10.831673: Epoch time: 83.44 s\n",
            "2024-03-21 17:57:12.717241: \n",
            "2024-03-21 17:57:12.717457: Epoch 95\n",
            "2024-03-21 17:57:12.717580: Current learning rate: 0.0071\n",
            "2024-03-21 17:58:36.123522: train_loss -0.9377\n",
            "2024-03-21 17:58:36.123910: val_loss -0.933\n",
            "2024-03-21 17:58:36.124194: Pseudo dice [0.9571, 0.9318]\n",
            "2024-03-21 17:58:36.124710: Epoch time: 83.41 s\n",
            "2024-03-21 17:58:37.989193: \n",
            "2024-03-21 17:58:37.989496: Epoch 96\n",
            "2024-03-21 17:58:37.989654: Current learning rate: 0.00707\n",
            "2024-03-21 18:00:00.579578: train_loss -0.9387\n",
            "2024-03-21 18:00:00.580010: val_loss -0.9362\n",
            "2024-03-21 18:00:00.580156: Pseudo dice [0.9594, 0.9344]\n",
            "2024-03-21 18:00:00.580293: Epoch time: 82.59 s\n",
            "2024-03-21 18:00:02.612714: \n",
            "2024-03-21 18:00:02.612916: Epoch 97\n",
            "2024-03-21 18:00:02.613029: Current learning rate: 0.00704\n",
            "2024-03-21 18:01:26.189955: train_loss -0.9382\n",
            "2024-03-21 18:01:26.190693: val_loss -0.9381\n",
            "2024-03-21 18:01:26.191009: Pseudo dice [0.9596, 0.9362]\n",
            "2024-03-21 18:01:26.191332: Epoch time: 83.58 s\n",
            "2024-03-21 18:01:28.055272: \n",
            "2024-03-21 18:01:28.055494: Epoch 98\n",
            "2024-03-21 18:01:28.055618: Current learning rate: 0.007\n",
            "2024-03-21 18:02:52.372767: train_loss -0.9383\n",
            "2024-03-21 18:02:52.373073: val_loss -0.9382\n",
            "2024-03-21 18:02:52.373186: Pseudo dice [0.9576, 0.9394]\n",
            "2024-03-21 18:02:52.373306: Epoch time: 84.32 s\n",
            "2024-03-21 18:02:52.373392: Yayy! New best EMA pseudo Dice: 0.9462\n",
            "2024-03-21 18:02:54.814680: \n",
            "2024-03-21 18:02:54.814841: Epoch 99\n",
            "2024-03-21 18:02:54.814968: Current learning rate: 0.00697\n",
            "2024-03-21 18:04:18.347160: train_loss -0.9404\n",
            "2024-03-21 18:04:18.347448: val_loss -0.9354\n",
            "2024-03-21 18:04:18.347560: Pseudo dice [0.9589, 0.9332]\n",
            "2024-03-21 18:04:18.347654: Epoch time: 83.53 s\n",
            "2024-03-21 18:04:20.856371: \n",
            "2024-03-21 18:04:20.856603: Epoch 100\n",
            "2024-03-21 18:04:20.856769: Current learning rate: 0.00694\n",
            "2024-03-21 18:05:44.806444: train_loss -0.9405\n",
            "2024-03-21 18:05:44.806731: val_loss -0.9329\n",
            "2024-03-21 18:05:44.806846: Pseudo dice [0.9579, 0.9294]\n",
            "2024-03-21 18:05:44.806943: Epoch time: 83.95 s\n",
            "2024-03-21 18:05:46.798738: \n",
            "2024-03-21 18:05:46.798915: Epoch 101\n",
            "2024-03-21 18:05:46.799020: Current learning rate: 0.00691\n",
            "2024-03-21 18:07:10.376522: train_loss -0.9384\n",
            "2024-03-21 18:07:10.376818: val_loss -0.9366\n",
            "2024-03-21 18:07:10.376944: Pseudo dice [0.9578, 0.9363]\n",
            "2024-03-21 18:07:10.377055: Epoch time: 83.58 s\n",
            "2024-03-21 18:07:12.568924: \n",
            "2024-03-21 18:07:12.569082: Epoch 102\n",
            "2024-03-21 18:07:12.569207: Current learning rate: 0.00688\n",
            "2024-03-21 18:08:35.551246: train_loss -0.9386\n",
            "2024-03-21 18:08:35.551618: val_loss -0.9347\n",
            "2024-03-21 18:08:35.551837: Pseudo dice [0.9595, 0.9315]\n",
            "2024-03-21 18:08:35.552003: Epoch time: 82.98 s\n",
            "2024-03-21 18:08:37.343487: \n",
            "2024-03-21 18:08:37.343752: Epoch 103\n",
            "2024-03-21 18:08:37.343870: Current learning rate: 0.00685\n",
            "2024-03-21 18:10:00.258260: train_loss -0.9399\n",
            "2024-03-21 18:10:00.258599: val_loss -0.9395\n",
            "2024-03-21 18:10:00.258790: Pseudo dice [0.9602, 0.9387]\n",
            "2024-03-21 18:10:00.258962: Epoch time: 82.92 s\n",
            "2024-03-21 18:10:00.259100: Yayy! New best EMA pseudo Dice: 0.9464\n",
            "2024-03-21 18:10:02.868366: \n",
            "2024-03-21 18:10:02.868544: Epoch 104\n",
            "2024-03-21 18:10:02.868711: Current learning rate: 0.00682\n",
            "2024-03-21 18:11:26.157049: train_loss -0.9422\n",
            "2024-03-21 18:11:26.157390: val_loss -0.9387\n",
            "2024-03-21 18:11:26.157535: Pseudo dice [0.9623, 0.9353]\n",
            "2024-03-21 18:11:26.157661: Epoch time: 83.29 s\n",
            "2024-03-21 18:11:26.157775: Yayy! New best EMA pseudo Dice: 0.9466\n",
            "2024-03-21 18:11:28.840724: \n",
            "2024-03-21 18:11:28.840882: Epoch 105\n",
            "2024-03-21 18:11:28.840999: Current learning rate: 0.00679\n",
            "2024-03-21 18:12:52.742406: train_loss -0.9398\n",
            "2024-03-21 18:12:52.742825: val_loss -0.935\n",
            "2024-03-21 18:12:52.743005: Pseudo dice [0.957, 0.9355]\n",
            "2024-03-21 18:12:52.743160: Epoch time: 83.9 s\n",
            "2024-03-21 18:12:54.550694: \n",
            "2024-03-21 18:12:54.550935: Epoch 106\n",
            "2024-03-21 18:12:54.551084: Current learning rate: 0.00675\n",
            "2024-03-21 18:14:18.333698: train_loss -0.9399\n",
            "2024-03-21 18:14:18.334061: val_loss -0.9327\n",
            "2024-03-21 18:14:18.334213: Pseudo dice [0.9548, 0.9327]\n",
            "2024-03-21 18:14:18.334443: Epoch time: 83.78 s\n",
            "2024-03-21 18:14:20.197562: \n",
            "2024-03-21 18:14:20.197738: Epoch 107\n",
            "2024-03-21 18:14:20.197858: Current learning rate: 0.00672\n",
            "2024-03-21 18:15:45.955685: train_loss -0.9412\n",
            "2024-03-21 18:15:45.956002: val_loss -0.9365\n",
            "2024-03-21 18:15:45.956134: Pseudo dice [0.9589, 0.9349]\n",
            "2024-03-21 18:15:45.956345: Epoch time: 85.76 s\n",
            "2024-03-21 18:15:48.172081: \n",
            "2024-03-21 18:15:48.172228: Epoch 108\n",
            "2024-03-21 18:15:48.172351: Current learning rate: 0.00669\n",
            "2024-03-21 18:17:12.636377: train_loss -0.9405\n",
            "2024-03-21 18:17:12.636853: val_loss -0.935\n",
            "2024-03-21 18:17:12.637137: Pseudo dice [0.9584, 0.9324]\n",
            "2024-03-21 18:17:12.637395: Epoch time: 84.47 s\n",
            "2024-03-21 18:17:14.400639: \n",
            "2024-03-21 18:17:14.400791: Epoch 109\n",
            "2024-03-21 18:17:14.400907: Current learning rate: 0.00666\n",
            "2024-03-21 18:18:37.957514: train_loss -0.9397\n",
            "2024-03-21 18:18:37.957803: val_loss -0.9333\n",
            "2024-03-21 18:18:37.957941: Pseudo dice [0.9567, 0.9312]\n",
            "2024-03-21 18:18:37.958061: Epoch time: 83.56 s\n",
            "2024-03-21 18:18:39.555361: \n",
            "2024-03-21 18:18:39.555610: Epoch 110\n",
            "2024-03-21 18:18:39.555735: Current learning rate: 0.00663\n",
            "2024-03-21 18:20:02.964236: train_loss -0.9411\n",
            "2024-03-21 18:20:02.964723: val_loss -0.9416\n",
            "2024-03-21 18:20:02.964952: Pseudo dice [0.9628, 0.9395]\n",
            "2024-03-21 18:20:02.965148: Epoch time: 83.41 s\n",
            "2024-03-21 18:20:04.814889: \n",
            "2024-03-21 18:20:04.815077: Epoch 111\n",
            "2024-03-21 18:20:04.815222: Current learning rate: 0.0066\n",
            "2024-03-21 18:21:29.086923: train_loss -0.941\n",
            "2024-03-21 18:21:29.087407: val_loss -0.9381\n",
            "2024-03-21 18:21:29.087533: Pseudo dice [0.9617, 0.9351]\n",
            "2024-03-21 18:21:29.087635: Epoch time: 84.27 s\n",
            "2024-03-21 18:21:29.087729: Yayy! New best EMA pseudo Dice: 0.9467\n",
            "2024-03-21 18:21:31.680337: \n",
            "2024-03-21 18:21:31.680501: Epoch 112\n",
            "2024-03-21 18:21:31.680619: Current learning rate: 0.00657\n",
            "2024-03-21 18:22:55.723166: train_loss -0.9401\n",
            "2024-03-21 18:22:55.723658: val_loss -0.9376\n",
            "2024-03-21 18:22:55.723941: Pseudo dice [0.9588, 0.9376]\n",
            "2024-03-21 18:22:55.724447: Epoch time: 84.04 s\n",
            "2024-03-21 18:22:55.724636: Yayy! New best EMA pseudo Dice: 0.9469\n",
            "2024-03-21 18:22:58.464854: \n",
            "2024-03-21 18:22:58.465041: Epoch 113\n",
            "2024-03-21 18:22:58.465199: Current learning rate: 0.00654\n",
            "2024-03-21 18:24:22.264217: train_loss -0.9403\n",
            "2024-03-21 18:24:22.264544: val_loss -0.9379\n",
            "2024-03-21 18:24:22.264703: Pseudo dice [0.96, 0.9368]\n",
            "2024-03-21 18:24:22.264834: Epoch time: 83.8 s\n",
            "2024-03-21 18:24:22.264952: Yayy! New best EMA pseudo Dice: 0.947\n",
            "2024-03-21 18:24:24.801210: \n",
            "2024-03-21 18:24:24.801390: Epoch 114\n",
            "2024-03-21 18:24:24.801503: Current learning rate: 0.0065\n",
            "2024-03-21 18:25:48.571577: train_loss -0.9408\n",
            "2024-03-21 18:25:48.571980: val_loss -0.9369\n",
            "2024-03-21 18:25:48.572155: Pseudo dice [0.9586, 0.9351]\n",
            "2024-03-21 18:25:48.572268: Epoch time: 83.77 s\n",
            "2024-03-21 18:25:50.594604: \n",
            "2024-03-21 18:25:50.594776: Epoch 115\n",
            "2024-03-21 18:25:50.594895: Current learning rate: 0.00647\n",
            "2024-03-21 18:27:13.977642: train_loss -0.9428\n",
            "2024-03-21 18:27:13.978023: val_loss -0.937\n",
            "2024-03-21 18:27:13.978161: Pseudo dice [0.96, 0.9346]\n",
            "2024-03-21 18:27:13.978305: Epoch time: 83.38 s\n",
            "2024-03-21 18:27:13.978407: Yayy! New best EMA pseudo Dice: 0.947\n",
            "2024-03-21 18:27:16.751459: \n",
            "2024-03-21 18:27:16.751622: Epoch 116\n",
            "2024-03-21 18:27:16.751742: Current learning rate: 0.00644\n",
            "2024-03-21 18:28:40.171630: train_loss -0.9416\n",
            "2024-03-21 18:28:40.171986: val_loss -0.9445\n",
            "2024-03-21 18:28:40.172162: Pseudo dice [0.9629, 0.9444]\n",
            "2024-03-21 18:28:40.172354: Epoch time: 83.42 s\n",
            "2024-03-21 18:28:40.172796: Yayy! New best EMA pseudo Dice: 0.9477\n",
            "2024-03-21 18:28:42.618440: \n",
            "2024-03-21 18:28:42.618713: Epoch 117\n",
            "2024-03-21 18:28:42.618854: Current learning rate: 0.00641\n",
            "2024-03-21 18:30:05.718884: train_loss -0.9431\n",
            "2024-03-21 18:30:05.719193: val_loss -0.9355\n",
            "2024-03-21 18:30:05.719343: Pseudo dice [0.9568, 0.9357]\n",
            "2024-03-21 18:30:05.719453: Epoch time: 83.1 s\n",
            "2024-03-21 18:30:07.392200: \n",
            "2024-03-21 18:30:07.392377: Epoch 118\n",
            "2024-03-21 18:30:07.392528: Current learning rate: 0.00638\n",
            "2024-03-21 18:31:30.854442: train_loss -0.9421\n",
            "2024-03-21 18:31:30.854858: val_loss -0.9352\n",
            "2024-03-21 18:31:30.855066: Pseudo dice [0.9555, 0.9364]\n",
            "2024-03-21 18:31:30.855224: Epoch time: 83.46 s\n",
            "2024-03-21 18:31:32.778751: \n",
            "2024-03-21 18:31:32.779021: Epoch 119\n",
            "2024-03-21 18:31:32.779156: Current learning rate: 0.00635\n",
            "2024-03-21 18:32:56.948097: train_loss -0.9401\n",
            "2024-03-21 18:32:56.948539: val_loss -0.9327\n",
            "2024-03-21 18:32:56.948689: Pseudo dice [0.9571, 0.9312]\n",
            "2024-03-21 18:32:56.948838: Epoch time: 84.17 s\n",
            "2024-03-21 18:32:59.068415: \n",
            "2024-03-21 18:32:59.068635: Epoch 120\n",
            "2024-03-21 18:32:59.068760: Current learning rate: 0.00631\n",
            "2024-03-21 18:34:24.526315: train_loss -0.9412\n",
            "2024-03-21 18:34:24.526588: val_loss -0.934\n",
            "2024-03-21 18:34:24.526691: Pseudo dice [0.956, 0.9351]\n",
            "2024-03-21 18:34:24.526785: Epoch time: 85.46 s\n",
            "2024-03-21 18:34:26.351177: \n",
            "2024-03-21 18:34:26.351355: Epoch 121\n",
            "2024-03-21 18:34:26.351467: Current learning rate: 0.00628\n",
            "2024-03-21 18:35:51.883157: train_loss -0.9415\n",
            "2024-03-21 18:35:51.883595: val_loss -0.9399\n",
            "2024-03-21 18:35:51.883870: Pseudo dice [0.9607, 0.9384]\n",
            "2024-03-21 18:35:51.884060: Epoch time: 85.53 s\n",
            "2024-03-21 18:35:53.707260: \n",
            "2024-03-21 18:35:53.707541: Epoch 122\n",
            "2024-03-21 18:35:53.707653: Current learning rate: 0.00625\n",
            "2024-03-21 18:37:19.264678: train_loss -0.941\n",
            "2024-03-21 18:37:19.265031: val_loss -0.9362\n",
            "2024-03-21 18:37:19.265214: Pseudo dice [0.9594, 0.9335]\n",
            "2024-03-21 18:37:19.265380: Epoch time: 85.56 s\n",
            "2024-03-21 18:37:21.244488: \n",
            "2024-03-21 18:37:21.244694: Epoch 123\n",
            "2024-03-21 18:37:21.244822: Current learning rate: 0.00622\n",
            "2024-03-21 18:38:46.125114: train_loss -0.9413\n",
            "2024-03-21 18:38:46.125548: val_loss -0.9406\n",
            "2024-03-21 18:38:46.125713: Pseudo dice [0.9612, 0.9395]\n",
            "2024-03-21 18:38:46.125865: Epoch time: 84.88 s\n",
            "2024-03-21 18:38:48.075053: \n",
            "2024-03-21 18:38:48.075298: Epoch 124\n",
            "2024-03-21 18:38:48.075459: Current learning rate: 0.00619\n",
            "2024-03-21 18:40:12.557926: train_loss -0.9416\n",
            "2024-03-21 18:40:12.558437: val_loss -0.9357\n",
            "2024-03-21 18:40:12.558709: Pseudo dice [0.9591, 0.9339]\n",
            "2024-03-21 18:40:12.558956: Epoch time: 84.48 s\n",
            "2024-03-21 18:40:14.688497: \n",
            "2024-03-21 18:40:14.688728: Epoch 125\n",
            "2024-03-21 18:40:14.688843: Current learning rate: 0.00616\n",
            "2024-03-21 18:41:39.622804: train_loss -0.941\n",
            "2024-03-21 18:41:39.623202: val_loss -0.9356\n",
            "2024-03-21 18:41:39.623422: Pseudo dice [0.9572, 0.9355]\n",
            "2024-03-21 18:41:39.623604: Epoch time: 84.94 s\n",
            "2024-03-21 18:41:41.382521: \n",
            "2024-03-21 18:41:41.382822: Epoch 126\n",
            "2024-03-21 18:41:41.382971: Current learning rate: 0.00612\n",
            "2024-03-21 18:43:06.220707: train_loss -0.9369\n",
            "2024-03-21 18:43:06.220990: val_loss -0.9403\n",
            "2024-03-21 18:43:06.221089: Pseudo dice [0.9612, 0.9388]\n",
            "2024-03-21 18:43:06.221178: Epoch time: 84.84 s\n",
            "2024-03-21 18:43:07.973926: \n",
            "2024-03-21 18:43:07.974110: Epoch 127\n",
            "2024-03-21 18:43:07.974303: Current learning rate: 0.00609\n",
            "2024-03-21 18:44:33.444375: train_loss -0.9417\n",
            "2024-03-21 18:44:33.444773: val_loss -0.9381\n",
            "2024-03-21 18:44:33.444945: Pseudo dice [0.9585, 0.9379]\n",
            "2024-03-21 18:44:33.445072: Epoch time: 85.47 s\n",
            "2024-03-21 18:44:35.522451: \n",
            "2024-03-21 18:44:35.522638: Epoch 128\n",
            "2024-03-21 18:44:35.522802: Current learning rate: 0.00606\n",
            "2024-03-21 18:46:01.121651: train_loss -0.9425\n",
            "2024-03-21 18:46:01.122171: val_loss -0.9369\n",
            "2024-03-21 18:46:01.122665: Pseudo dice [0.9561, 0.9373]\n",
            "2024-03-21 18:46:01.123084: Epoch time: 85.6 s\n",
            "2024-03-21 18:46:02.853282: \n",
            "2024-03-21 18:46:02.853467: Epoch 129\n",
            "2024-03-21 18:46:02.853629: Current learning rate: 0.00603\n",
            "2024-03-21 18:47:28.996872: train_loss -0.9422\n",
            "2024-03-21 18:47:28.997498: val_loss -0.936\n",
            "2024-03-21 18:47:28.997789: Pseudo dice [0.958, 0.9348]\n",
            "2024-03-21 18:47:28.998049: Epoch time: 86.14 s\n",
            "2024-03-21 18:47:31.102123: \n",
            "2024-03-21 18:47:31.102335: Epoch 130\n",
            "2024-03-21 18:47:31.102480: Current learning rate: 0.006\n",
            "2024-03-21 18:48:56.646595: train_loss -0.9425\n",
            "2024-03-21 18:48:56.646996: val_loss -0.94\n",
            "2024-03-21 18:48:56.647169: Pseudo dice [0.9613, 0.9386]\n",
            "2024-03-21 18:48:56.647324: Epoch time: 85.55 s\n",
            "2024-03-21 18:48:58.763166: \n",
            "2024-03-21 18:48:58.763357: Epoch 131\n",
            "2024-03-21 18:48:58.763485: Current learning rate: 0.00597\n",
            "2024-03-21 18:50:24.896846: train_loss -0.9415\n",
            "2024-03-21 18:50:24.897203: val_loss -0.9391\n",
            "2024-03-21 18:50:24.897437: Pseudo dice [0.9603, 0.9373]\n",
            "2024-03-21 18:50:24.897624: Epoch time: 86.13 s\n",
            "2024-03-21 18:50:24.897783: Yayy! New best EMA pseudo Dice: 0.9478\n",
            "2024-03-21 18:50:27.620689: \n",
            "2024-03-21 18:50:27.620896: Epoch 132\n",
            "2024-03-21 18:50:27.621058: Current learning rate: 0.00593\n",
            "2024-03-21 18:51:53.937922: train_loss -0.9409\n",
            "2024-03-21 18:51:53.938321: val_loss -0.9329\n",
            "2024-03-21 18:51:53.938483: Pseudo dice [0.9572, 0.9317]\n",
            "2024-03-21 18:51:53.938605: Epoch time: 86.32 s\n",
            "2024-03-21 18:51:55.828214: \n",
            "2024-03-21 18:51:55.828481: Epoch 133\n",
            "2024-03-21 18:51:55.828631: Current learning rate: 0.0059\n",
            "2024-03-21 18:53:21.536106: train_loss -0.9397\n",
            "2024-03-21 18:53:21.536438: val_loss -0.9389\n",
            "2024-03-21 18:53:21.536561: Pseudo dice [0.9606, 0.9367]\n",
            "2024-03-21 18:53:21.536660: Epoch time: 85.71 s\n",
            "2024-03-21 18:53:23.336537: \n",
            "2024-03-21 18:53:23.336704: Epoch 134\n",
            "2024-03-21 18:53:23.336859: Current learning rate: 0.00587\n",
            "2024-03-21 18:54:50.073657: train_loss -0.9417\n",
            "2024-03-21 18:54:50.074314: val_loss -0.943\n",
            "2024-03-21 18:54:50.074780: Pseudo dice [0.9629, 0.9413]\n",
            "2024-03-21 18:54:50.075058: Epoch time: 86.74 s\n",
            "2024-03-21 18:54:50.075360: Yayy! New best EMA pseudo Dice: 0.948\n",
            "2024-03-21 18:54:52.726587: \n",
            "2024-03-21 18:54:52.726824: Epoch 135\n",
            "2024-03-21 18:54:52.726969: Current learning rate: 0.00584\n",
            "2024-03-21 18:56:18.645838: train_loss -0.943\n",
            "2024-03-21 18:56:18.646152: val_loss -0.9429\n",
            "2024-03-21 18:56:18.646316: Pseudo dice [0.965, 0.9402]\n",
            "2024-03-21 18:56:18.646463: Epoch time: 85.92 s\n",
            "2024-03-21 18:56:18.646577: Yayy! New best EMA pseudo Dice: 0.9485\n",
            "2024-03-21 18:56:21.104268: \n",
            "2024-03-21 18:56:21.104444: Epoch 136\n",
            "2024-03-21 18:56:21.104562: Current learning rate: 0.00581\n",
            "2024-03-21 18:57:46.522875: train_loss -0.9421\n",
            "2024-03-21 18:57:46.523259: val_loss -0.9418\n",
            "2024-03-21 18:57:46.523434: Pseudo dice [0.9627, 0.9393]\n",
            "2024-03-21 18:57:46.523527: Epoch time: 85.42 s\n",
            "2024-03-21 18:57:46.523599: Yayy! New best EMA pseudo Dice: 0.9487\n",
            "2024-03-21 18:57:49.147386: \n",
            "2024-03-21 18:57:49.147571: Epoch 137\n",
            "2024-03-21 18:57:49.147790: Current learning rate: 0.00578\n",
            "2024-03-21 18:59:14.075936: train_loss -0.9432\n",
            "2024-03-21 18:59:14.076258: val_loss -0.9423\n",
            "2024-03-21 18:59:14.076433: Pseudo dice [0.9611, 0.9429]\n",
            "2024-03-21 18:59:14.076558: Epoch time: 84.93 s\n",
            "2024-03-21 18:59:14.076664: Yayy! New best EMA pseudo Dice: 0.949\n",
            "2024-03-21 18:59:16.533756: \n",
            "2024-03-21 18:59:16.533935: Epoch 138\n",
            "2024-03-21 18:59:16.534068: Current learning rate: 0.00574\n",
            "2024-03-21 19:00:40.831534: train_loss -0.9423\n",
            "2024-03-21 19:00:40.831991: val_loss -0.9361\n",
            "2024-03-21 19:00:40.832133: Pseudo dice [0.9576, 0.9346]\n",
            "2024-03-21 19:00:40.832340: Epoch time: 84.3 s\n",
            "2024-03-21 19:00:42.767786: \n",
            "2024-03-21 19:00:42.767994: Epoch 139\n",
            "2024-03-21 19:00:42.768130: Current learning rate: 0.00571\n",
            "2024-03-21 19:02:07.365997: train_loss -0.9436\n",
            "2024-03-21 19:02:07.366328: val_loss -0.9392\n",
            "2024-03-21 19:02:07.366461: Pseudo dice [0.9587, 0.9393]\n",
            "2024-03-21 19:02:07.366573: Epoch time: 84.6 s\n",
            "2024-03-21 19:02:09.340345: \n",
            "2024-03-21 19:02:09.340552: Epoch 140\n",
            "2024-03-21 19:02:09.340745: Current learning rate: 0.00568\n",
            "2024-03-21 19:03:32.135011: train_loss -0.9444\n",
            "2024-03-21 19:03:32.135387: val_loss -0.9394\n",
            "2024-03-21 19:03:32.135584: Pseudo dice [0.9575, 0.9407]\n",
            "2024-03-21 19:03:32.135731: Epoch time: 82.8 s\n",
            "2024-03-21 19:03:34.130896: \n",
            "2024-03-21 19:03:34.131075: Epoch 141\n",
            "2024-03-21 19:03:34.131224: Current learning rate: 0.00565\n",
            "2024-03-21 19:04:59.173627: train_loss -0.9433\n",
            "2024-03-21 19:04:59.173986: val_loss -0.9417\n",
            "2024-03-21 19:04:59.174099: Pseudo dice [0.9588, 0.9424]\n",
            "2024-03-21 19:04:59.174193: Epoch time: 85.04 s\n",
            "2024-03-21 19:05:01.099252: \n",
            "2024-03-21 19:05:01.099524: Epoch 142\n",
            "2024-03-21 19:05:01.099662: Current learning rate: 0.00562\n",
            "2024-03-21 19:06:27.350202: train_loss -0.9452\n",
            "2024-03-21 19:06:27.350557: val_loss -0.9388\n",
            "2024-03-21 19:06:27.350680: Pseudo dice [0.9607, 0.9368]\n",
            "2024-03-21 19:06:27.350793: Epoch time: 86.25 s\n",
            "2024-03-21 19:06:29.235054: \n",
            "2024-03-21 19:06:29.235275: Epoch 143\n",
            "2024-03-21 19:06:29.235404: Current learning rate: 0.00558\n",
            "2024-03-21 19:07:54.112168: train_loss -0.945\n",
            "2024-03-21 19:07:54.112506: val_loss -0.9352\n",
            "2024-03-21 19:07:54.112659: Pseudo dice [0.9567, 0.9349]\n",
            "2024-03-21 19:07:54.112817: Epoch time: 84.88 s\n",
            "2024-03-21 19:07:56.395379: \n",
            "2024-03-21 19:07:56.395532: Epoch 144\n",
            "2024-03-21 19:07:56.395652: Current learning rate: 0.00555\n",
            "2024-03-21 19:09:21.682916: train_loss -0.9435\n",
            "2024-03-21 19:09:21.683214: val_loss -0.9362\n",
            "2024-03-21 19:09:21.683476: Pseudo dice [0.9556, 0.9361]\n",
            "2024-03-21 19:09:21.683687: Epoch time: 85.29 s\n",
            "2024-03-21 19:09:23.586099: \n",
            "2024-03-21 19:09:23.586353: Epoch 145\n",
            "2024-03-21 19:09:23.586514: Current learning rate: 0.00552\n",
            "2024-03-21 19:10:48.417407: train_loss -0.9428\n",
            "2024-03-21 19:10:48.417932: val_loss -0.9367\n",
            "2024-03-21 19:10:48.418120: Pseudo dice [0.9562, 0.9379]\n",
            "2024-03-21 19:10:48.418262: Epoch time: 84.83 s\n",
            "2024-03-21 19:10:50.376011: \n",
            "2024-03-21 19:10:50.376328: Epoch 146\n",
            "2024-03-21 19:10:50.376515: Current learning rate: 0.00549\n",
            "2024-03-21 19:12:15.961668: train_loss -0.9435\n",
            "2024-03-21 19:12:15.962209: val_loss -0.9372\n",
            "2024-03-21 19:12:15.962794: Pseudo dice [0.957, 0.9383]\n",
            "2024-03-21 19:12:15.963120: Epoch time: 85.59 s\n",
            "2024-03-21 19:12:18.105652: \n",
            "2024-03-21 19:12:18.105877: Epoch 147\n",
            "2024-03-21 19:12:18.106011: Current learning rate: 0.00546\n",
            "2024-03-21 19:13:44.192096: train_loss -0.9442\n",
            "2024-03-21 19:13:44.192458: val_loss -0.9375\n",
            "2024-03-21 19:13:44.192617: Pseudo dice [0.9587, 0.9368]\n",
            "2024-03-21 19:13:44.192746: Epoch time: 86.09 s\n",
            "2024-03-21 19:13:46.375698: \n",
            "2024-03-21 19:13:46.375846: Epoch 148\n",
            "2024-03-21 19:13:46.375985: Current learning rate: 0.00542\n",
            "2024-03-21 19:15:13.000578: train_loss -0.9423\n",
            "2024-03-21 19:15:13.000962: val_loss -0.9411\n",
            "2024-03-21 19:15:13.001151: Pseudo dice [0.9603, 0.941]\n",
            "2024-03-21 19:15:13.001333: Epoch time: 86.63 s\n",
            "2024-03-21 19:15:15.109336: \n",
            "2024-03-21 19:15:15.109525: Epoch 149\n",
            "2024-03-21 19:15:15.109681: Current learning rate: 0.00539\n",
            "2024-03-21 19:16:41.535475: train_loss -0.9421\n",
            "2024-03-21 19:16:41.535867: val_loss -0.936\n",
            "2024-03-21 19:16:41.536013: Pseudo dice [0.9592, 0.9334]\n",
            "2024-03-21 19:16:41.536140: Epoch time: 86.43 s\n",
            "2024-03-21 19:16:44.338044: \n",
            "2024-03-21 19:16:44.338344: Epoch 150\n",
            "2024-03-21 19:16:44.338485: Current learning rate: 0.00536\n",
            "2024-03-21 19:18:11.899884: train_loss -0.9427\n",
            "2024-03-21 19:18:11.900254: val_loss -0.9327\n",
            "2024-03-21 19:18:11.900480: Pseudo dice [0.955, 0.9333]\n",
            "2024-03-21 19:18:11.900641: Epoch time: 87.56 s\n",
            "2024-03-21 19:18:13.852440: \n",
            "2024-03-21 19:18:13.852618: Epoch 151\n",
            "2024-03-21 19:18:13.852744: Current learning rate: 0.00533\n",
            "2024-03-21 19:19:41.119115: train_loss -0.9445\n",
            "2024-03-21 19:19:41.119528: val_loss -0.9409\n",
            "2024-03-21 19:19:41.119673: Pseudo dice [0.9609, 0.94]\n",
            "2024-03-21 19:19:41.119810: Epoch time: 87.27 s\n",
            "2024-03-21 19:19:43.273017: \n",
            "2024-03-21 19:19:43.273343: Epoch 152\n",
            "2024-03-21 19:19:43.273504: Current learning rate: 0.00529\n",
            "2024-03-21 19:21:09.128039: train_loss -0.9442\n",
            "2024-03-21 19:21:09.128595: val_loss -0.9382\n",
            "2024-03-21 19:21:09.128781: Pseudo dice [0.9578, 0.9383]\n",
            "2024-03-21 19:21:09.128920: Epoch time: 85.86 s\n",
            "2024-03-21 19:21:11.383562: \n",
            "2024-03-21 19:21:11.383736: Epoch 153\n",
            "2024-03-21 19:21:11.383871: Current learning rate: 0.00526\n",
            "2024-03-21 19:22:37.561188: train_loss -0.9436\n",
            "2024-03-21 19:22:37.561734: val_loss -0.9375\n",
            "2024-03-21 19:22:37.561956: Pseudo dice [0.9594, 0.9354]\n",
            "2024-03-21 19:22:37.562085: Epoch time: 86.18 s\n",
            "2024-03-21 19:22:39.522901: \n",
            "2024-03-21 19:22:39.523188: Epoch 154\n",
            "2024-03-21 19:22:39.523372: Current learning rate: 0.00523\n",
            "2024-03-21 19:24:06.269170: train_loss -0.9449\n",
            "2024-03-21 19:24:06.269703: val_loss -0.9377\n",
            "2024-03-21 19:24:06.269906: Pseudo dice [0.9601, 0.9358]\n",
            "2024-03-21 19:24:06.270066: Epoch time: 86.75 s\n",
            "2024-03-21 19:24:08.350237: \n",
            "2024-03-21 19:24:08.350423: Epoch 155\n",
            "2024-03-21 19:24:08.350578: Current learning rate: 0.0052\n",
            "2024-03-21 19:25:35.412339: train_loss -0.9444\n",
            "2024-03-21 19:25:35.412663: val_loss -0.9392\n",
            "2024-03-21 19:25:35.412797: Pseudo dice [0.9603, 0.9366]\n",
            "2024-03-21 19:25:35.412915: Epoch time: 87.06 s\n",
            "2024-03-21 19:25:37.397615: \n",
            "2024-03-21 19:25:37.397908: Epoch 156\n",
            "2024-03-21 19:25:37.398041: Current learning rate: 0.00517\n",
            "2024-03-21 19:27:04.364017: train_loss -0.9458\n",
            "2024-03-21 19:27:04.364532: val_loss -0.9417\n",
            "2024-03-21 19:27:04.364694: Pseudo dice [0.9625, 0.9399]\n",
            "2024-03-21 19:27:04.364811: Epoch time: 86.97 s\n",
            "2024-03-21 19:27:06.264635: \n",
            "2024-03-21 19:27:06.264816: Epoch 157\n",
            "2024-03-21 19:27:06.264960: Current learning rate: 0.00513\n",
            "2024-03-21 19:28:33.073334: train_loss -0.9442\n",
            "2024-03-21 19:28:33.073654: val_loss -0.9346\n",
            "2024-03-21 19:28:33.073753: Pseudo dice [0.9587, 0.9318]\n",
            "2024-03-21 19:28:33.073862: Epoch time: 86.81 s\n",
            "2024-03-21 19:28:35.015605: \n",
            "2024-03-21 19:28:35.015816: Epoch 158\n",
            "2024-03-21 19:28:35.015947: Current learning rate: 0.0051\n",
            "2024-03-21 19:30:01.917697: train_loss -0.9454\n",
            "2024-03-21 19:30:01.918093: val_loss -0.9393\n",
            "2024-03-21 19:30:01.918227: Pseudo dice [0.9593, 0.9401]\n",
            "2024-03-21 19:30:01.918387: Epoch time: 86.9 s\n",
            "2024-03-21 19:30:03.894491: \n",
            "2024-03-21 19:30:03.894704: Epoch 159\n",
            "2024-03-21 19:30:03.894867: Current learning rate: 0.00507\n",
            "2024-03-21 19:31:30.347625: train_loss -0.9447\n",
            "2024-03-21 19:31:30.347952: val_loss -0.936\n",
            "2024-03-21 19:31:30.348081: Pseudo dice [0.9566, 0.937]\n",
            "2024-03-21 19:31:30.348212: Epoch time: 86.45 s\n",
            "2024-03-21 19:31:32.442097: \n",
            "2024-03-21 19:31:32.442407: Epoch 160\n",
            "2024-03-21 19:31:32.442536: Current learning rate: 0.00504\n",
            "2024-03-21 19:32:58.091824: train_loss -0.9437\n",
            "2024-03-21 19:32:58.092273: val_loss -0.935\n",
            "2024-03-21 19:32:58.092487: Pseudo dice [0.9571, 0.9336]\n",
            "2024-03-21 19:32:58.092640: Epoch time: 85.65 s\n",
            "2024-03-21 19:32:59.978710: \n",
            "2024-03-21 19:32:59.978903: Epoch 161\n",
            "2024-03-21 19:32:59.979017: Current learning rate: 0.005\n",
            "2024-03-21 19:34:26.371084: train_loss -0.9415\n",
            "2024-03-21 19:34:26.371628: val_loss -0.9371\n",
            "2024-03-21 19:34:26.371930: Pseudo dice [0.958, 0.9358]\n",
            "2024-03-21 19:34:26.372168: Epoch time: 86.39 s\n",
            "2024-03-21 19:34:28.167849: \n",
            "2024-03-21 19:34:28.168023: Epoch 162\n",
            "2024-03-21 19:34:28.168134: Current learning rate: 0.00497\n",
            "2024-03-21 19:35:55.252381: train_loss -0.9436\n",
            "2024-03-21 19:35:55.252700: val_loss -0.9396\n",
            "2024-03-21 19:35:55.252805: Pseudo dice [0.9636, 0.9356]\n",
            "2024-03-21 19:35:55.252900: Epoch time: 87.09 s\n",
            "2024-03-21 19:35:57.114584: \n",
            "2024-03-21 19:35:57.114790: Epoch 163\n",
            "2024-03-21 19:35:57.114954: Current learning rate: 0.00494\n",
            "2024-03-21 19:37:21.505156: train_loss -0.9438\n",
            "2024-03-21 19:37:21.505541: val_loss -0.938\n",
            "2024-03-21 19:37:21.505747: Pseudo dice [0.959, 0.9372]\n",
            "2024-03-21 19:37:21.505911: Epoch time: 84.39 s\n",
            "2024-03-21 19:37:23.575379: \n",
            "2024-03-21 19:37:23.575552: Epoch 164\n",
            "2024-03-21 19:37:23.575721: Current learning rate: 0.00491\n",
            "2024-03-21 19:38:46.206843: train_loss -0.9452\n",
            "2024-03-21 19:38:46.207167: val_loss -0.9339\n",
            "2024-03-21 19:38:46.207395: Pseudo dice [0.9554, 0.9347]\n",
            "2024-03-21 19:38:46.207592: Epoch time: 82.63 s\n",
            "2024-03-21 19:38:48.112781: \n",
            "2024-03-21 19:38:48.113036: Epoch 165\n",
            "2024-03-21 19:38:48.113160: Current learning rate: 0.00487\n",
            "2024-03-21 19:40:12.607692: train_loss -0.9463\n",
            "2024-03-21 19:40:12.608016: val_loss -0.9348\n",
            "2024-03-21 19:40:12.608156: Pseudo dice [0.9567, 0.934]\n",
            "2024-03-21 19:40:12.608331: Epoch time: 84.5 s\n",
            "2024-03-21 19:40:14.337292: \n",
            "2024-03-21 19:40:14.337577: Epoch 166\n",
            "2024-03-21 19:40:14.337703: Current learning rate: 0.00484\n",
            "2024-03-21 19:41:38.718993: train_loss -0.9454\n",
            "2024-03-21 19:41:38.719579: val_loss -0.9406\n",
            "2024-03-21 19:41:38.719780: Pseudo dice [0.9596, 0.9406]\n",
            "2024-03-21 19:41:38.720117: Epoch time: 84.38 s\n",
            "2024-03-21 19:41:40.468831: \n",
            "2024-03-21 19:41:40.469127: Epoch 167\n",
            "2024-03-21 19:41:40.469252: Current learning rate: 0.00481\n",
            "2024-03-21 19:43:06.743413: train_loss -0.946\n",
            "2024-03-21 19:43:06.743721: val_loss -0.9406\n",
            "2024-03-21 19:43:06.743826: Pseudo dice [0.9589, 0.9411]\n",
            "2024-03-21 19:43:06.743919: Epoch time: 86.28 s\n",
            "2024-03-21 19:43:08.738529: \n",
            "2024-03-21 19:43:08.738883: Epoch 168\n",
            "2024-03-21 19:43:08.739015: Current learning rate: 0.00478\n",
            "2024-03-21 19:44:34.038350: train_loss -0.9452\n",
            "2024-03-21 19:44:34.038741: val_loss -0.9394\n",
            "2024-03-21 19:44:34.038889: Pseudo dice [0.9595, 0.9392]\n",
            "2024-03-21 19:44:34.039017: Epoch time: 85.3 s\n",
            "2024-03-21 19:44:36.093383: \n",
            "2024-03-21 19:44:36.093559: Epoch 169\n",
            "2024-03-21 19:44:36.093710: Current learning rate: 0.00474\n",
            "2024-03-21 19:46:00.342817: train_loss -0.9462\n",
            "2024-03-21 19:46:00.343165: val_loss -0.936\n",
            "2024-03-21 19:46:00.343309: Pseudo dice [0.9582, 0.935]\n",
            "2024-03-21 19:46:00.343454: Epoch time: 84.25 s\n",
            "2024-03-21 19:46:02.207306: \n",
            "2024-03-21 19:46:02.207554: Epoch 170\n",
            "2024-03-21 19:46:02.207686: Current learning rate: 0.00471\n",
            "2024-03-21 19:47:25.583598: train_loss -0.9462\n",
            "2024-03-21 19:47:25.583893: val_loss -0.9437\n",
            "2024-03-21 19:47:25.584018: Pseudo dice [0.9637, 0.943]\n",
            "2024-03-21 19:47:25.584154: Epoch time: 83.38 s\n",
            "2024-03-21 19:47:27.532022: \n",
            "2024-03-21 19:47:27.532196: Epoch 171\n",
            "2024-03-21 19:47:27.532357: Current learning rate: 0.00468\n",
            "2024-03-21 19:48:52.045976: train_loss -0.9459\n",
            "2024-03-21 19:48:52.046334: val_loss -0.9397\n",
            "2024-03-21 19:48:52.046471: Pseudo dice [0.96, 0.9386]\n",
            "2024-03-21 19:48:52.046588: Epoch time: 84.52 s\n",
            "2024-03-21 19:48:54.071320: \n",
            "2024-03-21 19:48:54.071467: Epoch 172\n",
            "2024-03-21 19:48:54.071582: Current learning rate: 0.00465\n",
            "2024-03-21 19:50:17.810657: train_loss -0.946\n",
            "2024-03-21 19:50:17.811247: val_loss -0.9393\n",
            "2024-03-21 19:50:17.811419: Pseudo dice [0.9616, 0.9362]\n",
            "2024-03-21 19:50:17.811541: Epoch time: 83.74 s\n",
            "2024-03-21 19:50:19.750182: \n",
            "2024-03-21 19:50:19.750364: Epoch 173\n",
            "2024-03-21 19:50:19.750476: Current learning rate: 0.00461\n",
            "2024-03-21 19:51:43.407456: train_loss -0.9463\n",
            "2024-03-21 19:51:43.407856: val_loss -0.9406\n",
            "2024-03-21 19:51:43.408016: Pseudo dice [0.9619, 0.9385]\n",
            "2024-03-21 19:51:43.408154: Epoch time: 83.66 s\n",
            "2024-03-21 19:51:45.209392: \n",
            "2024-03-21 19:51:45.209707: Epoch 174\n",
            "2024-03-21 19:51:45.209831: Current learning rate: 0.00458\n",
            "2024-03-21 19:53:08.577472: train_loss -0.9456\n",
            "2024-03-21 19:53:08.577739: val_loss -0.9414\n",
            "2024-03-21 19:53:08.577840: Pseudo dice [0.9608, 0.9416]\n",
            "2024-03-21 19:53:08.577938: Epoch time: 83.37 s\n",
            "2024-03-21 19:53:10.433127: \n",
            "2024-03-21 19:53:10.433410: Epoch 175\n",
            "2024-03-21 19:53:10.433557: Current learning rate: 0.00455\n",
            "2024-03-21 19:54:33.965097: train_loss -0.9429\n",
            "2024-03-21 19:54:33.965520: val_loss -0.939\n",
            "2024-03-21 19:54:33.965751: Pseudo dice [0.9595, 0.9388]\n",
            "2024-03-21 19:54:33.965938: Epoch time: 83.53 s\n",
            "2024-03-21 19:54:36.182068: \n",
            "2024-03-21 19:54:36.182349: Epoch 176\n",
            "2024-03-21 19:54:36.182501: Current learning rate: 0.00452\n",
            "2024-03-21 19:56:01.103990: train_loss -0.9452\n",
            "2024-03-21 19:56:01.104421: val_loss -0.9394\n",
            "2024-03-21 19:56:01.104672: Pseudo dice [0.9588, 0.9411]\n",
            "2024-03-21 19:56:01.104905: Epoch time: 84.92 s\n",
            "2024-03-21 19:56:01.105122: Yayy! New best EMA pseudo Dice: 0.9491\n",
            "2024-03-21 19:56:03.505763: \n",
            "2024-03-21 19:56:03.505983: Epoch 177\n",
            "2024-03-21 19:56:03.506123: Current learning rate: 0.00448\n",
            "2024-03-21 19:57:26.106095: train_loss -0.9458\n",
            "2024-03-21 19:57:26.106546: val_loss -0.9438\n",
            "2024-03-21 19:57:26.106810: Pseudo dice [0.9647, 0.9411]\n",
            "2024-03-21 19:57:26.107027: Epoch time: 82.6 s\n",
            "2024-03-21 19:57:26.107243: Yayy! New best EMA pseudo Dice: 0.9495\n",
            "2024-03-21 19:57:28.766751: \n",
            "2024-03-21 19:57:28.767149: Epoch 178\n",
            "2024-03-21 19:57:28.767309: Current learning rate: 0.00445\n",
            "2024-03-21 19:58:51.392455: train_loss -0.9468\n",
            "2024-03-21 19:58:51.392919: val_loss -0.9411\n",
            "2024-03-21 19:58:51.393151: Pseudo dice [0.9614, 0.9401]\n",
            "2024-03-21 19:58:51.393396: Epoch time: 82.63 s\n",
            "2024-03-21 19:58:51.393578: Yayy! New best EMA pseudo Dice: 0.9496\n",
            "2024-03-21 19:58:53.944830: \n",
            "2024-03-21 19:58:53.944999: Epoch 179\n",
            "2024-03-21 19:58:53.945130: Current learning rate: 0.00442\n",
            "2024-03-21 20:00:17.196242: train_loss -0.947\n",
            "2024-03-21 20:00:17.196700: val_loss -0.9413\n",
            "2024-03-21 20:00:17.196905: Pseudo dice [0.962, 0.9393]\n",
            "2024-03-21 20:00:17.197067: Epoch time: 83.25 s\n",
            "2024-03-21 20:00:17.197183: Yayy! New best EMA pseudo Dice: 0.9497\n",
            "2024-03-21 20:00:20.122519: \n",
            "2024-03-21 20:00:20.122771: Epoch 180\n",
            "2024-03-21 20:00:20.122936: Current learning rate: 0.00438\n",
            "2024-03-21 20:01:43.457543: train_loss -0.9466\n",
            "2024-03-21 20:01:43.457864: val_loss -0.9344\n",
            "2024-03-21 20:01:43.457992: Pseudo dice [0.9543, 0.9352]\n",
            "2024-03-21 20:01:43.458101: Epoch time: 83.34 s\n",
            "2024-03-21 20:01:45.344473: \n",
            "2024-03-21 20:01:45.344689: Epoch 181\n",
            "2024-03-21 20:01:45.344814: Current learning rate: 0.00435\n",
            "2024-03-21 20:03:09.301079: train_loss -0.9478\n",
            "2024-03-21 20:03:09.301540: val_loss -0.9421\n",
            "2024-03-21 20:03:09.301787: Pseudo dice [0.9597, 0.9427]\n",
            "2024-03-21 20:03:09.301972: Epoch time: 83.96 s\n",
            "2024-03-21 20:03:11.250869: \n",
            "2024-03-21 20:03:11.251044: Epoch 182\n",
            "2024-03-21 20:03:11.251155: Current learning rate: 0.00432\n",
            "2024-03-21 20:04:34.231621: train_loss -0.9475\n",
            "2024-03-21 20:04:34.231923: val_loss -0.9362\n",
            "2024-03-21 20:04:34.232060: Pseudo dice [0.955, 0.9383]\n",
            "2024-03-21 20:04:34.232177: Epoch time: 82.98 s\n",
            "2024-03-21 20:04:35.985079: \n",
            "2024-03-21 20:04:35.985392: Epoch 183\n",
            "2024-03-21 20:04:35.985528: Current learning rate: 0.00429\n",
            "2024-03-21 20:06:00.214657: train_loss -0.9474\n",
            "2024-03-21 20:06:00.215022: val_loss -0.939\n",
            "2024-03-21 20:06:00.215147: Pseudo dice [0.9574, 0.94]\n",
            "2024-03-21 20:06:00.215267: Epoch time: 84.23 s\n",
            "2024-03-21 20:06:02.609603: \n",
            "2024-03-21 20:06:02.609796: Epoch 184\n",
            "2024-03-21 20:06:02.609968: Current learning rate: 0.00425\n",
            "2024-03-21 20:07:24.521168: train_loss -0.9472\n",
            "2024-03-21 20:07:24.521565: val_loss -0.9394\n",
            "2024-03-21 20:07:24.521694: Pseudo dice [0.96, 0.9389]\n",
            "2024-03-21 20:07:24.521806: Epoch time: 81.91 s\n",
            "2024-03-21 20:07:26.529831: \n",
            "2024-03-21 20:07:26.530004: Epoch 185\n",
            "2024-03-21 20:07:26.530117: Current learning rate: 0.00422\n",
            "2024-03-21 20:08:48.643532: train_loss -0.9477\n",
            "2024-03-21 20:08:48.643912: val_loss -0.9377\n",
            "2024-03-21 20:08:48.644063: Pseudo dice [0.9573, 0.9383]\n",
            "2024-03-21 20:08:48.644181: Epoch time: 82.11 s\n",
            "2024-03-21 20:08:50.481229: \n",
            "2024-03-21 20:08:50.481508: Epoch 186\n",
            "2024-03-21 20:08:50.481628: Current learning rate: 0.00419\n",
            "2024-03-21 20:10:12.047963: train_loss -0.9481\n",
            "2024-03-21 20:10:12.048264: val_loss -0.9433\n",
            "2024-03-21 20:10:12.048461: Pseudo dice [0.9603, 0.9438]\n",
            "2024-03-21 20:10:12.048562: Epoch time: 81.57 s\n",
            "2024-03-21 20:10:14.078996: \n",
            "2024-03-21 20:10:14.079304: Epoch 187\n",
            "2024-03-21 20:10:14.079473: Current learning rate: 0.00415\n",
            "2024-03-21 20:11:36.267366: train_loss -0.9469\n",
            "2024-03-21 20:11:36.267666: val_loss -0.9423\n",
            "2024-03-21 20:11:36.267789: Pseudo dice [0.9647, 0.939]\n",
            "2024-03-21 20:11:36.267881: Epoch time: 82.19 s\n",
            "2024-03-21 20:11:38.381537: \n",
            "2024-03-21 20:11:38.381697: Epoch 188\n",
            "2024-03-21 20:11:38.381850: Current learning rate: 0.00412\n",
            "2024-03-21 20:13:00.269226: train_loss -0.948\n",
            "2024-03-21 20:13:00.269564: val_loss -0.944\n",
            "2024-03-21 20:13:00.269714: Pseudo dice [0.964, 0.9414]\n",
            "2024-03-21 20:13:00.269841: Epoch time: 81.89 s\n",
            "2024-03-21 20:13:00.269947: Yayy! New best EMA pseudo Dice: 0.9499\n",
            "2024-03-21 20:13:02.742011: \n",
            "2024-03-21 20:13:02.742183: Epoch 189\n",
            "2024-03-21 20:13:02.742346: Current learning rate: 0.00409\n",
            "2024-03-21 20:14:24.520757: train_loss -0.9482\n",
            "2024-03-21 20:14:24.521080: val_loss -0.9389\n",
            "2024-03-21 20:14:24.521213: Pseudo dice [0.9597, 0.938]\n",
            "2024-03-21 20:14:24.521348: Epoch time: 81.78 s\n",
            "2024-03-21 20:14:26.339978: \n",
            "2024-03-21 20:14:26.340156: Epoch 190\n",
            "2024-03-21 20:14:26.340272: Current learning rate: 0.00405\n",
            "2024-03-21 20:15:49.272357: train_loss -0.9476\n",
            "2024-03-21 20:15:49.272729: val_loss -0.9421\n",
            "2024-03-21 20:15:49.272870: Pseudo dice [0.9612, 0.941]\n",
            "2024-03-21 20:15:49.272991: Epoch time: 82.93 s\n",
            "2024-03-21 20:15:49.273078: Yayy! New best EMA pseudo Dice: 0.9499\n",
            "2024-03-21 20:15:51.930640: \n",
            "2024-03-21 20:15:51.930850: Epoch 191\n",
            "2024-03-21 20:15:51.930998: Current learning rate: 0.00402\n",
            "2024-03-21 20:17:15.881783: train_loss -0.9482\n",
            "2024-03-21 20:17:15.882093: val_loss -0.9435\n",
            "2024-03-21 20:17:15.882222: Pseudo dice [0.9634, 0.9413]\n",
            "2024-03-21 20:17:15.882363: Epoch time: 83.95 s\n",
            "2024-03-21 20:17:15.882466: Yayy! New best EMA pseudo Dice: 0.9501\n",
            "2024-03-21 20:17:18.633790: \n",
            "2024-03-21 20:17:18.633989: Epoch 192\n",
            "2024-03-21 20:17:18.634098: Current learning rate: 0.00399\n",
            "2024-03-21 20:18:41.074768: train_loss -0.9484\n",
            "2024-03-21 20:18:41.075086: val_loss -0.941\n",
            "2024-03-21 20:18:41.075216: Pseudo dice [0.9611, 0.9391]\n",
            "2024-03-21 20:18:41.075352: Epoch time: 82.44 s\n",
            "2024-03-21 20:18:42.787121: \n",
            "2024-03-21 20:18:42.787309: Epoch 193\n",
            "2024-03-21 20:18:42.787444: Current learning rate: 0.00395\n",
            "2024-03-21 20:20:05.383657: train_loss -0.9484\n",
            "2024-03-21 20:20:05.383963: val_loss -0.9435\n",
            "2024-03-21 20:20:05.384080: Pseudo dice [0.9627, 0.9421]\n",
            "2024-03-21 20:20:05.384193: Epoch time: 82.6 s\n",
            "2024-03-21 20:20:05.384292: Yayy! New best EMA pseudo Dice: 0.9504\n",
            "2024-03-21 20:20:07.989856: \n",
            "2024-03-21 20:20:07.990031: Epoch 194\n",
            "2024-03-21 20:20:07.990161: Current learning rate: 0.00392\n",
            "2024-03-21 20:21:31.036559: train_loss -0.9482\n",
            "2024-03-21 20:21:31.036946: val_loss -0.9371\n",
            "2024-03-21 20:21:31.037081: Pseudo dice [0.9563, 0.9386]\n",
            "2024-03-21 20:21:31.037217: Epoch time: 83.05 s\n",
            "2024-03-21 20:21:33.080714: \n",
            "2024-03-21 20:21:33.080904: Epoch 195\n",
            "2024-03-21 20:21:33.081019: Current learning rate: 0.00389\n",
            "2024-03-21 20:22:57.229618: train_loss -0.947\n",
            "2024-03-21 20:22:57.229982: val_loss -0.9436\n",
            "2024-03-21 20:22:57.230090: Pseudo dice [0.9629, 0.9421]\n",
            "2024-03-21 20:22:57.230217: Epoch time: 84.15 s\n",
            "2024-03-21 20:22:59.041027: \n",
            "2024-03-21 20:22:59.041214: Epoch 196\n",
            "2024-03-21 20:22:59.041351: Current learning rate: 0.00385\n",
            "2024-03-21 20:24:23.050388: train_loss -0.9481\n",
            "2024-03-21 20:24:23.050751: val_loss -0.9443\n",
            "2024-03-21 20:24:23.050898: Pseudo dice [0.9631, 0.9417]\n",
            "2024-03-21 20:24:23.051025: Epoch time: 84.01 s\n",
            "2024-03-21 20:24:23.051127: Yayy! New best EMA pseudo Dice: 0.9505\n",
            "2024-03-21 20:24:25.712106: \n",
            "2024-03-21 20:24:25.712502: Epoch 197\n",
            "2024-03-21 20:24:25.712660: Current learning rate: 0.00382\n",
            "2024-03-21 20:25:49.290208: train_loss -0.9486\n",
            "2024-03-21 20:25:49.290605: val_loss -0.9363\n",
            "2024-03-21 20:25:49.290756: Pseudo dice [0.9556, 0.9371]\n",
            "2024-03-21 20:25:49.290882: Epoch time: 83.58 s\n",
            "2024-03-21 20:25:51.215221: \n",
            "2024-03-21 20:25:51.215491: Epoch 198\n",
            "2024-03-21 20:25:51.215613: Current learning rate: 0.00379\n",
            "2024-03-21 20:27:14.120087: train_loss -0.948\n",
            "2024-03-21 20:27:14.120458: val_loss -0.9396\n",
            "2024-03-21 20:27:14.120683: Pseudo dice [0.9608, 0.9369]\n",
            "2024-03-21 20:27:14.120877: Epoch time: 82.91 s\n",
            "2024-03-21 20:27:15.984930: \n",
            "2024-03-21 20:27:15.985151: Epoch 199\n",
            "2024-03-21 20:27:15.985287: Current learning rate: 0.00375\n",
            "2024-03-21 20:28:38.720311: train_loss -0.9475\n",
            "2024-03-21 20:28:38.720654: val_loss -0.9396\n",
            "2024-03-21 20:28:38.720798: Pseudo dice [0.9582, 0.94]\n",
            "2024-03-21 20:28:38.720911: Epoch time: 82.74 s\n",
            "2024-03-21 20:28:41.293881: \n",
            "2024-03-21 20:28:41.294045: Epoch 200\n",
            "2024-03-21 20:28:41.294152: Current learning rate: 0.00372\n",
            "2024-03-21 20:30:04.748912: train_loss -0.9495\n",
            "2024-03-21 20:30:04.749228: val_loss -0.9383\n",
            "2024-03-21 20:30:04.749448: Pseudo dice [0.9599, 0.9363]\n",
            "2024-03-21 20:30:04.749607: Epoch time: 83.46 s\n",
            "2024-03-21 20:30:06.605646: \n",
            "2024-03-21 20:30:06.605924: Epoch 201\n",
            "2024-03-21 20:30:06.606061: Current learning rate: 0.00369\n",
            "2024-03-21 20:31:29.214961: train_loss -0.9486\n",
            "2024-03-21 20:31:29.215235: val_loss -0.9372\n",
            "2024-03-21 20:31:29.215371: Pseudo dice [0.9576, 0.937]\n",
            "2024-03-21 20:31:29.215468: Epoch time: 82.61 s\n",
            "2024-03-21 20:31:30.953197: \n",
            "2024-03-21 20:31:30.953382: Epoch 202\n",
            "2024-03-21 20:31:30.953497: Current learning rate: 0.00365\n",
            "2024-03-21 20:32:53.138933: train_loss -0.9492\n",
            "2024-03-21 20:32:53.139317: val_loss -0.9417\n",
            "2024-03-21 20:32:53.139463: Pseudo dice [0.9619, 0.9407]\n",
            "2024-03-21 20:32:53.139582: Epoch time: 82.19 s\n",
            "2024-03-21 20:32:55.113547: \n",
            "2024-03-21 20:32:55.113712: Epoch 203\n",
            "2024-03-21 20:32:55.113824: Current learning rate: 0.00362\n",
            "2024-03-21 20:34:17.932055: train_loss -0.9487\n",
            "2024-03-21 20:34:17.932446: val_loss -0.9402\n",
            "2024-03-21 20:34:17.932590: Pseudo dice [0.9609, 0.938]\n",
            "2024-03-21 20:34:17.932729: Epoch time: 82.82 s\n",
            "2024-03-21 20:34:19.624016: \n",
            "2024-03-21 20:34:19.624188: Epoch 204\n",
            "2024-03-21 20:34:19.624332: Current learning rate: 0.00359\n",
            "2024-03-21 20:35:42.120679: train_loss -0.9461\n",
            "2024-03-21 20:35:42.120998: val_loss -0.94\n",
            "2024-03-21 20:35:42.121128: Pseudo dice [0.9591, 0.9395]\n",
            "2024-03-21 20:35:42.121260: Epoch time: 82.5 s\n",
            "2024-03-21 20:35:44.165530: \n",
            "2024-03-21 20:35:44.165769: Epoch 205\n",
            "2024-03-21 20:35:44.165948: Current learning rate: 0.00355\n",
            "2024-03-21 20:37:06.795555: train_loss -0.9464\n",
            "2024-03-21 20:37:06.795841: val_loss -0.9434\n",
            "2024-03-21 20:37:06.795944: Pseudo dice [0.9626, 0.9417]\n",
            "2024-03-21 20:37:06.796039: Epoch time: 82.63 s\n",
            "2024-03-21 20:37:08.714986: \n",
            "2024-03-21 20:37:08.715147: Epoch 206\n",
            "2024-03-21 20:37:08.715258: Current learning rate: 0.00352\n",
            "2024-03-21 20:38:31.217247: train_loss -0.9478\n",
            "2024-03-21 20:38:31.217602: val_loss -0.9372\n",
            "2024-03-21 20:38:31.217742: Pseudo dice [0.959, 0.9345]\n",
            "2024-03-21 20:38:31.217890: Epoch time: 82.5 s\n",
            "2024-03-21 20:38:32.930915: \n",
            "2024-03-21 20:38:32.931125: Epoch 207\n",
            "2024-03-21 20:38:32.931238: Current learning rate: 0.00349\n",
            "2024-03-21 20:39:55.659483: train_loss -0.9486\n",
            "2024-03-21 20:39:55.659994: val_loss -0.9418\n",
            "2024-03-21 20:39:55.660439: Pseudo dice [0.9617, 0.9413]\n",
            "2024-03-21 20:39:55.660859: Epoch time: 82.73 s\n",
            "2024-03-21 20:39:57.190141: \n",
            "2024-03-21 20:39:57.190333: Epoch 208\n",
            "2024-03-21 20:39:57.190457: Current learning rate: 0.00345\n",
            "2024-03-21 20:41:20.676518: train_loss -0.9485\n",
            "2024-03-21 20:41:20.676883: val_loss -0.9394\n",
            "2024-03-21 20:41:20.677070: Pseudo dice [0.9598, 0.9372]\n",
            "2024-03-21 20:41:20.677371: Epoch time: 83.49 s\n",
            "2024-03-21 20:41:22.633666: \n",
            "2024-03-21 20:41:22.633878: Epoch 209\n",
            "2024-03-21 20:41:22.634009: Current learning rate: 0.00342\n",
            "2024-03-21 20:42:45.723924: train_loss -0.9495\n",
            "2024-03-21 20:42:45.724275: val_loss -0.9378\n",
            "2024-03-21 20:42:45.724452: Pseudo dice [0.9587, 0.9377]\n",
            "2024-03-21 20:42:45.724572: Epoch time: 83.09 s\n",
            "2024-03-21 20:42:47.484489: \n",
            "2024-03-21 20:42:47.484651: Epoch 210\n",
            "2024-03-21 20:42:47.484847: Current learning rate: 0.00338\n",
            "2024-03-21 20:44:12.679860: train_loss -0.9483\n",
            "2024-03-21 20:44:12.680230: val_loss -0.9399\n",
            "2024-03-21 20:44:12.680405: Pseudo dice [0.9583, 0.9411]\n",
            "2024-03-21 20:44:12.680543: Epoch time: 85.2 s\n",
            "2024-03-21 20:44:14.711748: \n",
            "2024-03-21 20:44:14.711962: Epoch 211\n",
            "2024-03-21 20:44:14.712128: Current learning rate: 0.00335\n",
            "2024-03-21 20:45:38.918547: train_loss -0.9493\n",
            "2024-03-21 20:45:38.918908: val_loss -0.9407\n",
            "2024-03-21 20:45:38.919053: Pseudo dice [0.9618, 0.9385]\n",
            "2024-03-21 20:45:38.919193: Epoch time: 84.21 s\n",
            "2024-03-21 20:45:40.629389: \n",
            "2024-03-21 20:45:40.629656: Epoch 212\n",
            "2024-03-21 20:45:40.629806: Current learning rate: 0.00332\n",
            "2024-03-21 20:47:05.395545: train_loss -0.9491\n",
            "2024-03-21 20:47:05.395894: val_loss -0.9446\n",
            "2024-03-21 20:47:05.396085: Pseudo dice [0.9631, 0.9436]\n",
            "2024-03-21 20:47:05.396269: Epoch time: 84.77 s\n",
            "2024-03-21 20:47:07.316792: \n",
            "2024-03-21 20:47:07.316971: Epoch 213\n",
            "2024-03-21 20:47:07.317083: Current learning rate: 0.00328\n",
            "2024-03-21 20:48:32.842817: train_loss -0.9491\n",
            "2024-03-21 20:48:32.843103: val_loss -0.9434\n",
            "2024-03-21 20:48:32.843212: Pseudo dice [0.9636, 0.9417]\n",
            "2024-03-21 20:48:32.843341: Epoch time: 85.53 s\n",
            "2024-03-21 20:48:34.560437: \n",
            "2024-03-21 20:48:34.560670: Epoch 214\n",
            "2024-03-21 20:48:34.560819: Current learning rate: 0.00325\n",
            "2024-03-21 20:49:58.287345: train_loss -0.9489\n",
            "2024-03-21 20:49:58.287667: val_loss -0.9445\n",
            "2024-03-21 20:49:58.287797: Pseudo dice [0.964, 0.9425]\n",
            "2024-03-21 20:49:58.287911: Epoch time: 83.73 s\n",
            "2024-03-21 20:50:00.307643: \n",
            "2024-03-21 20:50:00.307813: Epoch 215\n",
            "2024-03-21 20:50:00.307915: Current learning rate: 0.00321\n",
            "2024-03-21 20:51:24.468386: train_loss -0.9498\n",
            "2024-03-21 20:51:24.468806: val_loss -0.9424\n",
            "2024-03-21 20:51:24.468945: Pseudo dice [0.9623, 0.9408]\n",
            "2024-03-21 20:51:24.469062: Epoch time: 84.16 s\n",
            "2024-03-21 20:51:24.469165: Yayy! New best EMA pseudo Dice: 0.9506\n",
            "2024-03-21 20:51:27.145229: \n",
            "2024-03-21 20:51:27.145426: Epoch 216\n",
            "2024-03-21 20:51:27.145543: Current learning rate: 0.00318\n",
            "2024-03-21 20:52:51.105067: train_loss -0.9506\n",
            "2024-03-21 20:52:51.105585: val_loss -0.9436\n",
            "2024-03-21 20:52:51.105828: Pseudo dice [0.9652, 0.9399]\n",
            "2024-03-21 20:52:51.106091: Epoch time: 83.96 s\n",
            "2024-03-21 20:52:51.106324: Yayy! New best EMA pseudo Dice: 0.9508\n",
            "2024-03-21 20:52:53.519329: \n",
            "2024-03-21 20:52:53.519508: Epoch 217\n",
            "2024-03-21 20:52:53.519640: Current learning rate: 0.00315\n",
            "2024-03-21 20:54:17.714915: train_loss -0.9496\n",
            "2024-03-21 20:54:17.715412: val_loss -0.9418\n",
            "2024-03-21 20:54:17.715556: Pseudo dice [0.9599, 0.9415]\n",
            "2024-03-21 20:54:17.715685: Epoch time: 84.2 s\n",
            "2024-03-21 20:54:19.732179: \n",
            "2024-03-21 20:54:19.732515: Epoch 218\n",
            "2024-03-21 20:54:19.732635: Current learning rate: 0.00311\n",
            "2024-03-21 20:55:43.698360: train_loss -0.951\n",
            "2024-03-21 20:55:43.698761: val_loss -0.9424\n",
            "2024-03-21 20:55:43.698973: Pseudo dice [0.9605, 0.9429]\n",
            "2024-03-21 20:55:43.699127: Epoch time: 83.97 s\n",
            "2024-03-21 20:55:43.699259: Yayy! New best EMA pseudo Dice: 0.9509\n",
            "2024-03-21 20:55:46.439448: \n",
            "2024-03-21 20:55:46.439619: Epoch 219\n",
            "2024-03-21 20:55:46.439736: Current learning rate: 0.00308\n",
            "2024-03-21 20:57:09.916998: train_loss -0.9499\n",
            "2024-03-21 20:57:09.917589: val_loss -0.9445\n",
            "2024-03-21 20:57:09.917823: Pseudo dice [0.9648, 0.9416]\n",
            "2024-03-21 20:57:09.917973: Epoch time: 83.48 s\n",
            "2024-03-21 20:57:09.918219: Yayy! New best EMA pseudo Dice: 0.9511\n",
            "2024-03-21 20:57:12.354488: \n",
            "2024-03-21 20:57:12.354713: Epoch 220\n",
            "2024-03-21 20:57:12.354820: Current learning rate: 0.00304\n",
            "2024-03-21 20:58:35.282368: train_loss -0.9496\n",
            "2024-03-21 20:58:35.282684: val_loss -0.9426\n",
            "2024-03-21 20:58:35.282848: Pseudo dice [0.9635, 0.9394]\n",
            "2024-03-21 20:58:35.283059: Epoch time: 82.93 s\n",
            "2024-03-21 20:58:35.283456: Yayy! New best EMA pseudo Dice: 0.9512\n",
            "2024-03-21 20:58:38.100319: \n",
            "2024-03-21 20:58:38.100553: Epoch 221\n",
            "2024-03-21 20:58:38.100693: Current learning rate: 0.00301\n",
            "2024-03-21 21:00:00.641938: train_loss -0.9505\n",
            "2024-03-21 21:00:00.642251: val_loss -0.9397\n",
            "2024-03-21 21:00:00.642380: Pseudo dice [0.9598, 0.9379]\n",
            "2024-03-21 21:00:00.642481: Epoch time: 82.54 s\n",
            "2024-03-21 21:00:02.402896: \n",
            "2024-03-21 21:00:02.403152: Epoch 222\n",
            "2024-03-21 21:00:02.403275: Current learning rate: 0.00297\n",
            "2024-03-21 21:01:25.861370: train_loss -0.9499\n",
            "2024-03-21 21:01:25.861736: val_loss -0.9411\n",
            "2024-03-21 21:01:25.861916: Pseudo dice [0.9627, 0.9384]\n",
            "2024-03-21 21:01:25.862175: Epoch time: 83.46 s\n",
            "2024-03-21 21:01:27.830922: \n",
            "2024-03-21 21:01:27.831080: Epoch 223\n",
            "2024-03-21 21:01:27.831199: Current learning rate: 0.00294\n",
            "2024-03-21 21:02:51.061222: train_loss -0.9503\n",
            "2024-03-21 21:02:51.061693: val_loss -0.9423\n",
            "2024-03-21 21:02:51.061859: Pseudo dice [0.9628, 0.9395]\n",
            "2024-03-21 21:02:51.061996: Epoch time: 83.23 s\n",
            "2024-03-21 21:02:53.029546: \n",
            "2024-03-21 21:02:53.029826: Epoch 224\n",
            "2024-03-21 21:02:53.029966: Current learning rate: 0.00291\n"
          ]
        }
      ],
      "source": [
        "! nnUNetv2_train 07 2d 2 --c -device cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "smqYPe9rpEZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}