{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import threading\n",
        "from google.colab import files\n",
        "\n",
        "def download_checkpoint():\n",
        "    while True:\n",
        "        files_list = os.listdir(\"/nnunetresults/\")\n",
        "        for file in files_list:\n",
        "            if file.endswith(\".pth\"):\n",
        "                print(\"Checkpoint found. Downloading...\")\n",
        "                local_path = os.path.join(\"/nnunetresults/\", file)\n",
        "                files.download(local_path)\n",
        "                return\n",
        "        time.sleep(10)  # Check every 10 seconds\n",
        "\n",
        "def main():\n",
        "    # Start the download_checkpoint function in a separate thread\n",
        "    thread = threading.Thread(target=download_checkpoint)\n",
        "    thread.daemon = True  # Daemonize the thread so it terminates when the main thread terminates\n",
        "    thread.start()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"Background checkpoint download started.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkZG-toIysqa",
        "outputId": "2842aa30-b42e-40ac-d0b4-e71cee85948a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ncoCMi2Yhl"
      },
      "outputs": [],
      "source": [
        "! mkdir \"nnUNet_raw\"\n",
        "! mkdir \"nnUNet_preprocessed\"\n",
        "! mkdir \"nnUNet_results\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jRNXWxi3OC7"
      },
      "source": [
        "Hmm this should be giving an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyDmNgOjhdDk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set environment variable\n",
        "os.environ['nnUNet_raw'] = '/content/nnUNet_raw'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "os.environ['nnUNet_results'] = '/content/nnUNet_results'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3kgnbk8hl59",
        "outputId": "d32284db-5386-4f61-9589-ba916877f0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nnUNet_raw\n"
          ]
        }
      ],
      "source": [
        "!echo ${nnUNet_raw}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD_xh89m7zyQ",
        "outputId": "4d53791e-a322-4d71-d3e8-900677b7a4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchio\n",
            "  Downloading torchio-0.19.6-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m163.8/173.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from torchio)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.7.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.2)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (67.7.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]->torchio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]->torchio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]->torchio) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]->torchio) (0.1.2)\n",
            "Installing collected packages: SimpleITK, shellingham, Deprecated, colorama, torchio\n",
            "Successfully installed Deprecated-1.2.14 SimpleITK-2.3.1 colorama-0.4.6 shellingham-1.5.4 torchio-0.19.6\n"
          ]
        }
      ],
      "source": [
        "!pip install torchio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WW2REhSWAi6"
      },
      "outputs": [],
      "source": [
        "# ! mkdir 'nnUNet_raw/Task07_Kidney'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/imagesTs'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/imagesTr'\n",
        "# ! mkdir 'nnUNet_raw/Task07_Kidney/labelsTr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FizGjtm6tey"
      },
      "outputs": [],
      "source": [
        "! mkdir 'nnUNet_raw/Dataset007_Kidney'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/imagesTs'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/imagesTr'\n",
        "! mkdir 'nnUNet_raw/Dataset007_Kidney/labelsTr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwtDwyqwDCMP",
        "outputId": "6b1b442e-f1b8-4393-d14f-beb71d6cf464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'batchgenerators'...\n",
            "remote: Enumerating objects: 3204, done.\u001b[K\n",
            "remote: Counting objects: 100% (575/575), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 3204 (delta 480), reused 461 (delta 461), pack-reused 2629\u001b[K\n",
            "Receiving objects: 100% (3204/3204), 7.53 MiB | 15.40 MiB/s, done.\n",
            "Resolving deltas: 100% (2424/2424), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MIC-DKFZ/batchgenerators.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "tL3ko5HEDC_S",
        "outputId": "7e314baa-d486-40dd-edcc-c408a491ae3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/batchgenerators\n",
            "Processing /content/batchgenerators\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (0.18.3)\n",
            "Collecting unittest2 (from batchgenerators==0.25)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators==0.25) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->batchgenerators==0.25) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->batchgenerators==0.25) (1.3.2)\n",
            "Collecting argparse (from unittest2->batchgenerators==0.25)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.10/dist-packages (from unittest2->batchgenerators==0.25) (1.16.0)\n",
            "Collecting traceback2 (from unittest2->batchgenerators==0.25)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators==0.25)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: batchgenerators\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=92663 sha256=d6b74b0a91ec3e3a1ef6732bcbffc8a761f0c43da16df7d7a80857bd0cdfab0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s0jtar38/wheels/36/51/5d/3aa020578c0d1835119dcfda74d4432a5adf9470682aa6c1e1\n",
            "Successfully built batchgenerators\n",
            "Installing collected packages: linecache2, argparse, traceback2, unittest2, batchgenerators\n",
            "Successfully installed argparse-1.4.0 batchgenerators-0.25 linecache2-1.0.0 traceback2-1.4.0 unittest2-1.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4917ee34eff04895ae36e7fd89671a17",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd batchgenerators\n",
        "!pip install .\n",
        "\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VH8KeZk05e1",
        "outputId": "fb019bed-5ab8-4175-ceba-f30a26c5181b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'nnUNet'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (201/201), done.\u001b[K\n",
            "remote: Total 216 (delta 13), reused 216 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (216/216), 1.94 MiB | 6.12 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "# !pip install nnunetv2\n",
        "!git clone https://github.com/bennyjacob326/nnUNet.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "erVTFQUAUOdL",
        "outputId": "d8ffd59e-701f-4c83-a273-a243184ffdd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/nnUNet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.1.0+cu121)\n",
            "Collecting acvl-utils>=0.2 (from nnunetv2==2.2.1)\n",
            "  Downloading acvl_utils-0.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures>=0.2 (from nnunetv2==2.2.1)\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (4.66.2)\n",
            "Collecting dicom2nifti (from nnunetv2==2.2.1)\n",
            "  Downloading dicom2nifti-2.4.10-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.11.4)\n",
            "Requirement already satisfied: batchgenerators>=0.25 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.19.3)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (1.5.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.20.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2024.2.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (2.31.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (4.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2.1) (0.13.1)\n",
            "Collecting imagecodecs (from nnunetv2==2.2.1)\n",
            "  Downloading imagecodecs-2024.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs (from nnunetv2==2.2.1)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting connected-components-3d (from acvl-utils>=0.2->nnunetv2==2.2.1)\n",
            "  Downloading connected_components_3d-3.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (9.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (0.18.3)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1) (3.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (2.31.6)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2.1) (2.1.0)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2==2.2.1)\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-gdcm (from dicom2nifti->nnunetv2==2.2.1)\n",
            "  Downloading python_gdcm-3.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2.1) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2==2.2.1) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2==2.2.1) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2.1) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2==2.2.1) (1.3.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2==2.2.1) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.2.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->nnunetv2==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->nnunetv2==2.2.1) (1.3.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.10/dist-packages (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1) (1.4.0)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.10/dist-packages (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.2.1) (1.0.0)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, dynamic-network-architectures\n",
            "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.2.1-0.editable-py3-none-any.whl size=16231 sha256=3a3375036e954d2b870547fd66eccb91506554cf72cfddebb4c6969c4b382894\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ki8np_ed/wheels/66/a8/0c/d8553e2873068c742a2c91eadf0e7dbc86388a52232ce6319b\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22437 sha256=99fccb270e524ddc8b8aa602a5e18d438edaa5c9f56bcb070d1d2b83f0cbeba0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30050 sha256=a4b2f6993d7ac555f095461a3a4f3a50fc8272f9a8964fc9b85677f8e268dadc\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n",
            "Successfully built nnunetv2 acvl-utils dynamic-network-architectures\n",
            "Installing collected packages: argparse, yacs, python-gdcm, pydicom, imagecodecs, connected-components-3d, dicom2nifti, dynamic-network-architectures, acvl-utils, nnunetv2\n",
            "Successfully installed acvl-utils-0.2 argparse-1.4.0 connected-components-3d-3.12.4 dicom2nifti-2.4.10 dynamic-network-architectures-0.3.1 imagecodecs-2024.1.1 nnunetv2-2.2.1 pydicom-2.4.4 python-gdcm-3.0.23 yacs-0.1.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4e663d551bdc4bdbac706167fd0d7697",
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install -e /content/nnUNet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdcJeH2VG4um"
      },
      "outputs": [],
      "source": [
        "from nnUNet.nnunetv2.paths import nnUNet_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l8hxDajxYXz",
        "outputId": "fc709241-6352-4f18-cd66-644619c6591f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1stGE4-JbhsvvnMomRqAzDnUuqyALJO71\n",
            "From (redirected): https://drive.google.com/uc?id=1stGE4-JbhsvvnMomRqAzDnUuqyALJO71&confirm=t&uuid=e9581f9b-d74a-4cba-af67-b8725b12d07b\n",
            "To: /content/50 cases.zip\n",
            "100% 518M/518M [00:02<00:00, 221MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !gdown \"18unEvC86RnmzEjPPay5aH9dKaRTyR0r-\"\n",
        "! gdown \"1stGE4-JbhsvvnMomRqAzDnUuqyALJO71\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg3eat1tybHd",
        "outputId": "018aec2e-fd1a-43ca-b530-92a07dd4afeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  50 cases.zip\n",
            "   creating: 50 cases/\n",
            "  inflating: __MACOSX/._50 cases     \n",
            "   creating: 50 cases/case_00050/\n",
            "  inflating: __MACOSX/50 cases/._case_00050  \n",
            "  inflating: 50 cases/.DS_Store      \n",
            "  inflating: __MACOSX/50 cases/._.DS_Store  \n",
            "   creating: 50 cases/case_00035/\n",
            "  inflating: __MACOSX/50 cases/._case_00035  \n",
            "   creating: 50 cases/case_00032/\n",
            "  inflating: __MACOSX/50 cases/._case_00032  \n",
            "   creating: 50 cases/case_00004/\n",
            "  inflating: __MACOSX/50 cases/._case_00004  \n",
            "   creating: 50 cases/case_00003/\n",
            "  inflating: __MACOSX/50 cases/._case_00003  \n",
            "   creating: 50 cases/case_00002/\n",
            "  inflating: __MACOSX/50 cases/._case_00002  \n",
            "   creating: 50 cases/case_00005/\n",
            "  inflating: __MACOSX/50 cases/._case_00005  \n",
            "   creating: 50 cases/case_00033/\n",
            "  inflating: __MACOSX/50 cases/._case_00033  \n",
            "   creating: 50 cases/case_00034/\n",
            "  inflating: __MACOSX/50 cases/._case_00034  \n",
            "   creating: 50 cases/case_00029/\n",
            "  inflating: __MACOSX/50 cases/._case_00029  \n",
            "   creating: 50 cases/case_00016/\n",
            "  inflating: __MACOSX/50 cases/._case_00016  \n",
            "   creating: 50 cases/case_00011/\n",
            "  inflating: __MACOSX/50 cases/._case_00011  \n",
            "   creating: 50 cases/case_00018/\n",
            "  inflating: __MACOSX/50 cases/._case_00018  \n",
            "   creating: 50 cases/case_00027/\n",
            "  inflating: __MACOSX/50 cases/._case_00027  \n",
            "   creating: 50 cases/case_00020/\n",
            "  inflating: __MACOSX/50 cases/._case_00020  \n",
            "   creating: 50 cases/case_00045/\n",
            "  inflating: __MACOSX/50 cases/._case_00045  \n",
            "   creating: 50 cases/case_00042/\n",
            "  inflating: __MACOSX/50 cases/._case_00042  \n",
            "   creating: 50 cases/case_00021/\n",
            "  inflating: __MACOSX/50 cases/._case_00021  \n",
            "   creating: 50 cases/case_00019/\n",
            "  inflating: __MACOSX/50 cases/._case_00019  \n",
            "   creating: 50 cases/case_00026/\n",
            "  inflating: __MACOSX/50 cases/._case_00026  \n",
            "   creating: 50 cases/case_00010/\n",
            "  inflating: __MACOSX/50 cases/._case_00010  \n",
            "   creating: 50 cases/case_00028/\n",
            "  inflating: __MACOSX/50 cases/._case_00028  \n",
            "   creating: 50 cases/case_00017/\n",
            "  inflating: __MACOSX/50 cases/._case_00017  \n",
            "   creating: 50 cases/case_00043/\n",
            "  inflating: __MACOSX/50 cases/._case_00043  \n",
            "   creating: 50 cases/case_00044/\n",
            "  inflating: __MACOSX/50 cases/._case_00044  \n",
            "   creating: 50 cases/case_00031/\n",
            "  inflating: __MACOSX/50 cases/._case_00031  \n",
            "   creating: 50 cases/case_00036/\n",
            "  inflating: __MACOSX/50 cases/._case_00036  \n",
            "   creating: 50 cases/case_00009/\n",
            "  inflating: __MACOSX/50 cases/._case_00009  \n",
            "   creating: 50 cases/case_00000/\n",
            "  inflating: __MACOSX/50 cases/._case_00000  \n",
            "   creating: 50 cases/case_00007/\n",
            "  inflating: __MACOSX/50 cases/._case_00007  \n",
            "   creating: 50 cases/case_00038/\n",
            "  inflating: __MACOSX/50 cases/._case_00038  \n",
            "   creating: 50 cases/case_00006/\n",
            "  inflating: __MACOSX/50 cases/._case_00006  \n",
            "   creating: 50 cases/case_00039/\n",
            "  inflating: __MACOSX/50 cases/._case_00039  \n",
            "   creating: 50 cases/case_00001/\n",
            "  inflating: __MACOSX/50 cases/._case_00001  \n",
            "   creating: 50 cases/case_00037/\n",
            "  inflating: __MACOSX/50 cases/._case_00037  \n",
            "   creating: 50 cases/case_00008/\n",
            "  inflating: __MACOSX/50 cases/._case_00008  \n",
            "   creating: 50 cases/case_00030/\n",
            "  inflating: __MACOSX/50 cases/._case_00030  \n",
            "   creating: 50 cases/case_00048/\n",
            "  inflating: __MACOSX/50 cases/._case_00048  \n",
            "   creating: 50 cases/case_00041/\n",
            "  inflating: __MACOSX/50 cases/._case_00041  \n",
            "   creating: 50 cases/case_00046/\n",
            "  inflating: __MACOSX/50 cases/._case_00046  \n",
            "   creating: 50 cases/case_00012/\n",
            "  inflating: __MACOSX/50 cases/._case_00012  \n",
            "   creating: 50 cases/case_00015/\n",
            "  inflating: __MACOSX/50 cases/._case_00015  \n",
            "   creating: 50 cases/case_00023/\n",
            "  inflating: __MACOSX/50 cases/._case_00023  \n",
            "   creating: 50 cases/case_00024/\n",
            "  inflating: __MACOSX/50 cases/._case_00024  \n",
            "   creating: 50 cases/case_00047/\n",
            "  inflating: __MACOSX/50 cases/._case_00047  \n",
            "   creating: 50 cases/case_00040/\n",
            "  inflating: __MACOSX/50 cases/._case_00040  \n",
            "   creating: 50 cases/case_00049/\n",
            "  inflating: __MACOSX/50 cases/._case_00049  \n",
            "   creating: 50 cases/case_00025/\n",
            "  inflating: __MACOSX/50 cases/._case_00025  \n",
            "   creating: 50 cases/case_00022/\n",
            "  inflating: __MACOSX/50 cases/._case_00022  \n",
            "   creating: 50 cases/case_00014/\n",
            "  inflating: __MACOSX/50 cases/._case_00014  \n",
            "   creating: 50 cases/case_00013/\n",
            "  inflating: __MACOSX/50 cases/._case_00013  \n",
            "  inflating: 50 cases/case_00050/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00050/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00050/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00035/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00035/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00035/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00032/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00032/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00032/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00004/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00004/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00004/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00003/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00003/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00003/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00002/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00002/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00002/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00005/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00005/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00005/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00033/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00033/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00033/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00034/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00034/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00034/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00029/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00029/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00029/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00016/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00016/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00016/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00011/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00011/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00011/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00018/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00018/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00018/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00027/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00027/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00027/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00020/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00020/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00020/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00045/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00045/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00045/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00042/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00042/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00042/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00021/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00021/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00021/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00019/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00019/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00019/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00026/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00026/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00026/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00010/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00010/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00010/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00028/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00028/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00028/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00017/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00017/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00017/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00043/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00043/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00043/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00044/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00044/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00044/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00031/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00031/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00031/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00036/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00036/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00036/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00009/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00009/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00009/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00000/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00000/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00000/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00007/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00007/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00007/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00038/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00038/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00038/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00006/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00006/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00006/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00039/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00039/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00039/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00001/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00001/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00001/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00037/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00037/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00037/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00008/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00008/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00008/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00030/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00030/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00030/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00048/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00048/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00048/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00041/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00041/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00041/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00046/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00046/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00046/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00012/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00012/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00012/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00015/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00015/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00015/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00023/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00023/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00023/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00024/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00024/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00024/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00047/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00047/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00047/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00040/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00040/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00040/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00049/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00049/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00049/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00025/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00025/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00025/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00022/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00022/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00022/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00014/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00014/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00014/segmentation.nii.gz  \n",
            "  inflating: 50 cases/case_00013/imaging.nii.gz  \n",
            "  inflating: __MACOSX/50 cases/case_00013/._imaging.nii.gz  \n",
            "  inflating: 50 cases/case_00013/segmentation.nii.gz  \n"
          ]
        }
      ],
      "source": [
        "!unzip 50\\ cases.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKFYyb_fypv9",
        "outputId": "727fd51d-2c47-4d43-9ecc-7ff6fff0c927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imaging file for case_00018 moved successfully.\n",
            "Segmentation file for case_00018 moved successfully.\n",
            "Imaging file for case_00030 moved successfully.\n",
            "Segmentation file for case_00030 moved successfully.\n",
            "Imaging file for case_00024 moved successfully.\n",
            "Segmentation file for case_00024 moved successfully.\n",
            "Imaging file for case_00020 moved successfully.\n",
            "Segmentation file for case_00020 moved successfully.\n",
            "Imaging file for case_00008 moved successfully.\n",
            "Segmentation file for case_00008 moved successfully.\n",
            "Imaging file for case_00040 moved successfully.\n",
            "Segmentation file for case_00040 moved successfully.\n",
            "Imaging file for case_00050 moved successfully.\n",
            "Segmentation file for case_00050 moved successfully.\n",
            "Imaging file for case_00023 moved successfully.\n",
            "Segmentation file for case_00023 moved successfully.\n",
            "Imaging file for case_00035 moved successfully.\n",
            "Segmentation file for case_00035 moved successfully.\n",
            "Imaging file for case_00031 moved successfully.\n",
            "Segmentation file for case_00031 moved successfully.\n",
            "Imaging file for case_00046 moved successfully.\n",
            "Segmentation file for case_00046 moved successfully.\n",
            "Imaging file for case_00026 moved successfully.\n",
            "Segmentation file for case_00026 moved successfully.\n",
            "Imaging file for case_00022 moved successfully.\n",
            "Segmentation file for case_00022 moved successfully.\n",
            "Imaging file for case_00004 moved successfully.\n",
            "Segmentation file for case_00004 moved successfully.\n",
            "Imaging file for case_00012 moved successfully.\n",
            "Segmentation file for case_00012 moved successfully.\n",
            "Imaging file for case_00029 moved successfully.\n",
            "Segmentation file for case_00029 moved successfully.\n",
            "Imaging file for case_00042 moved successfully.\n",
            "Segmentation file for case_00042 moved successfully.\n",
            "Imaging file for case_00034 moved successfully.\n",
            "Segmentation file for case_00034 moved successfully.\n",
            "Imaging file for case_00027 moved successfully.\n",
            "Segmentation file for case_00027 moved successfully.\n",
            "Imaging file for case_00017 moved successfully.\n",
            "Segmentation file for case_00017 moved successfully.\n",
            "Imaging file for case_00028 moved successfully.\n",
            "Segmentation file for case_00028 moved successfully.\n",
            "Imaging file for case_00033 moved successfully.\n",
            "Segmentation file for case_00033 moved successfully.\n",
            "Imaging file for case_00045 moved successfully.\n",
            "Segmentation file for case_00045 moved successfully.\n",
            "Imaging file for case_00010 moved successfully.\n",
            "Segmentation file for case_00010 moved successfully.\n",
            "Imaging file for case_00036 moved successfully.\n",
            "Segmentation file for case_00036 moved successfully.\n",
            "Imaging file for case_00000 moved successfully.\n",
            "Segmentation file for case_00000 moved successfully.\n",
            "Imaging file for case_00048 moved successfully.\n",
            "Segmentation file for case_00048 moved successfully.\n",
            "Imaging file for case_00002 moved successfully.\n",
            "Segmentation file for case_00002 moved successfully.\n",
            "Imaging file for case_00044 moved successfully.\n",
            "Segmentation file for case_00044 moved successfully.\n",
            "Imaging file for case_00011 moved successfully.\n",
            "Segmentation file for case_00011 moved successfully.\n",
            "Imaging file for case_00041 moved successfully.\n",
            "Segmentation file for case_00041 moved successfully.\n",
            "Imaging file for case_00007 moved successfully.\n",
            "Segmentation file for case_00007 moved successfully.\n",
            "Imaging file for case_00019 moved successfully.\n",
            "Segmentation file for case_00019 moved successfully.\n",
            "Imaging file for case_00014 moved successfully.\n",
            "Segmentation file for case_00014 moved successfully.\n",
            "Imaging file for case_00009 moved successfully.\n",
            "Segmentation file for case_00009 moved successfully.\n",
            "Imaging file for case_00005 moved successfully.\n",
            "Segmentation file for case_00005 moved successfully.\n",
            "Imaging file for case_00047 moved successfully.\n",
            "Segmentation file for case_00047 moved successfully.\n",
            "Imaging file for case_00037 moved successfully.\n",
            "Segmentation file for case_00037 moved successfully.\n",
            "Imaging file for case_00043 moved successfully.\n",
            "Segmentation file for case_00043 moved successfully.\n",
            "Imaging file for case_00039 moved successfully.\n",
            "Segmentation file for case_00039 moved successfully.\n",
            "Imaging file for case_00006 moved successfully.\n",
            "Segmentation file for case_00006 moved successfully.\n",
            "Imaging file for case_00016 moved successfully.\n",
            "Segmentation file for case_00016 moved successfully.\n",
            "Imaging file for case_00013 moved successfully.\n",
            "Segmentation file for case_00013 moved successfully.\n",
            "Imaging file for case_00015 moved successfully.\n",
            "Segmentation file for case_00015 moved successfully.\n",
            "Imaging file for case_00021 moved successfully.\n",
            "Segmentation file for case_00021 moved successfully.\n",
            "Imaging file for case_00001 moved successfully.\n",
            "Segmentation file for case_00001 moved successfully.\n",
            "Imaging file for case_00038 moved successfully.\n",
            "Segmentation file for case_00038 moved successfully.\n",
            "Imaging file for case_00025 moved successfully.\n",
            "Segmentation file for case_00025 moved successfully.\n",
            "Imaging file for case_00003 moved successfully.\n",
            "Segmentation file for case_00003 moved successfully.\n",
            "Imaging file for case_00032 moved successfully.\n",
            "Segmentation file for case_00032 moved successfully.\n",
            "Imaging file for case_00049 moved successfully.\n",
            "Segmentation file for case_00049 moved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths to the source and destination folders\n",
        "source_folder = \"/content/50 cases\"\n",
        "destination_train_folder = \"/content/nnUNet_raw/Dataset007_Kidney/imagesTr\"\n",
        "destination_test_folder = \"/content/nnUNet_raw/Dataset007_Kidney/labelsTr\"\n",
        "\n",
        "# Create destination folders if they don't exist\n",
        "os.makedirs(destination_train_folder, exist_ok=True)\n",
        "os.makedirs(destination_test_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through each folder in the source directory\n",
        "for case_folder in os.listdir(source_folder):\n",
        "    case_folder_path = os.path.join(source_folder, case_folder)\n",
        "\n",
        "    # Check if the item in the source folder is a directory\n",
        "    if os.path.isdir(case_folder_path):\n",
        "        # Find the imaging.nii.gz and segmentation.nii.gz files\n",
        "        imaging_file = os.path.join(case_folder_path, \"imaging.nii.gz\")\n",
        "        segmentation_file = os.path.join(case_folder_path, \"segmentation.nii.gz\")\n",
        "\n",
        "        # Check if both files exist\n",
        "        if os.path.exists(imaging_file) and os.path.exists(segmentation_file):\n",
        "            # Rename and move the imaging file to the training folder\n",
        "            new_imaging_file = os.path.join(destination_train_folder, f\"{case_folder}_0000.nii.gz\")\n",
        "            try:\n",
        "                shutil.move(imaging_file, new_imaging_file)\n",
        "                print(f\"Imaging file for {case_folder} moved successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Imaging file not found for {case_folder}. Skipping...\")\n",
        "\n",
        "            # Rename and move the segmentation file to the testing folder\n",
        "            new_segmentation_file = os.path.join(destination_test_folder, f\"{case_folder}.nii.gz\")\n",
        "            try:\n",
        "                shutil.move(segmentation_file, new_segmentation_file)\n",
        "                print(f\"Segmentation file for {case_folder} moved successfully.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Segmentation file not found for {case_folder}. Skipping...\")\n",
        "        else:\n",
        "            print(f\"Files not found in {case_folder}. Skipping...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-WAYHlW4zry"
      },
      "source": [
        "Needed to redunce the number of workers for colab free. (`-np 4`. The default is 4 or 8 depending on the subtask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C-SsTqE7mQW",
        "outputId": "2737f112-efe2-4eec-e803-6d44fe02c291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON file saved to: /content/nnUNet_raw/Dataset007_Kidney/dataset.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Define the dataset information\n",
        "dataset_info = {\n",
        "    \"channel_names\": {\n",
        "        \"0\": \"CT\"\n",
        "    },\n",
        "    \"labels\": {\n",
        "        \"background\": 0,\n",
        "        # \"kidney\": [1, 2, 3],\n",
        "        \"kidney\": [1,2],\n",
        "        # \"masses\": [2, 3],\n",
        "        \"tumor\": 2\n",
        "    },\n",
        "    \"numTraining\": 51,\n",
        "    \"file_ending\": \".nii.gz\",\n",
        "    \"overwrite_image_reader_writer\": \"NibabelIOWithReorient\",\n",
        "    # \"regions_class_order\": [1, 3, 2]\n",
        "    \"regions_class_order\": [1, 2]\n",
        "}\n",
        "\n",
        "# Define the file path for saving the JSON file\n",
        "output_file = '/content/nnUNet_raw/Dataset007_Kidney/dataset.json'\n",
        "\n",
        "# Write the dataset information to the JSON file\n",
        "with open(output_file, 'w') as json_file:\n",
        "    json.dump(dataset_info, json_file, indent=4)\n",
        "\n",
        "print(f\"JSON file saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-dZFYRlwja-",
        "outputId": "2871ec0f-9b6a-42a3-8383-ba718227685b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset007_Kidney\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "100% 51/51 [00:09<00:00,  5.60it/s]\n",
            "Experiment planning...\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 198, 'patch_size': array([128, 128]), 'median_image_size_in_voxels': array([128., 128.]), 'spacing': array([3.24409437, 3.25347567]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': array([128, 128, 128]), 'median_image_size_in_voxels': array([113., 128., 128.]), 'spacing': array([3.68885899, 3.24409437, 3.25347567]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/nnUNet_preprocessed/Dataset007_Kidney/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset007_Kidney\n",
            "Configuration: 2d...\n",
            "100% 51/51 [00:38<00:00,  1.34it/s]\n",
            "Configuration: 3d_fullres...\n",
            "100% 51/51 [00:25<00:00,  1.97it/s]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset007_Kidney. Skipping.\n"
          ]
        }
      ],
      "source": [
        "! nnUNetv2_plan_and_preprocess -d 07 --verify_dataset_integrity -np 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmirhd2if1h"
      },
      "source": [
        "Train dataset 6, using 2d images, start with fold 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGyfVokAD2ob",
        "outputId": "b7206b12-6084-46fd-f455-a3ec41b4aff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [113.0, 128.0, 128.0], 'spacing': [3.688858985900879, 3.2440943717956543, 3.2534756660461426], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset007_Kidney', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.688858985900879, 3.2440943717956543, 3.2534756660461426], 'original_median_shape_after_transp': [110, 128, 128], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2089.895751953125, 'mean': 115.59651947021484, 'median': 116.08860778808594, 'min': -163.07736206054688, 'percentile_00_5': -47.866790428161586, 'percentile_99_5': 289.61480712890625, 'std': 72.87223815917969}}} \n",
            "\n",
            "2024-03-04 20:34:30.839364: unpacking dataset...\n",
            "2024-03-04 20:34:36.756903: unpacking done...\n",
            "2024-03-04 20:34:36.757623: do_dummy_2d_data_aug: False\n",
            "2024-03-04 20:34:36.758742: Creating new 5-fold cross-validation split...\n",
            "2024-03-04 20:34:36.760625: Desired fold for training: 2\n",
            "2024-03-04 20:34:36.760722: This split has 41 training and 10 validation cases.\n",
            "2024-03-04 20:34:36.766667: Unable to plot network architecture:\n",
            "2024-03-04 20:34:36.766742: No module named 'hiddenlayer'\n",
            "2024-03-04 20:34:36.927380: \n",
            "2024-03-04 20:34:36.927545: Epoch 0\n",
            "2024-03-04 20:34:36.927725: Current learning rate: 0.01\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-03-04 20:38:08.932502: train_loss -0.0542\n",
            "2024-03-04 20:38:08.932915: val_loss -0.228\n",
            "2024-03-04 20:38:08.933108: Pseudo dice [0.5703, 0.0]\n",
            "2024-03-04 20:38:08.933393: Epoch time: 212.01 s\n",
            "2024-03-04 20:38:08.933521: Yayy! New best EMA pseudo Dice: 0.2851\n",
            "2024-03-04 20:38:11.198485: \n",
            "2024-03-04 20:38:11.198682: Epoch 1\n",
            "2024-03-04 20:38:11.198837: Current learning rate: 0.00991\n",
            "2024-03-04 20:41:27.710995: train_loss -0.3522\n",
            "2024-03-04 20:41:27.711344: val_loss -0.3262\n",
            "2024-03-04 20:41:27.711468: Pseudo dice [0.7134, 0.0]\n",
            "2024-03-04 20:41:27.711579: Epoch time: 196.51 s\n",
            "2024-03-04 20:41:27.711670: Yayy! New best EMA pseudo Dice: 0.2923\n",
            "2024-03-04 20:41:30.612454: \n",
            "2024-03-04 20:41:30.612634: Epoch 2\n",
            "2024-03-04 20:41:30.612793: Current learning rate: 0.00982\n",
            "2024-03-04 20:44:41.491696: train_loss -0.4136\n",
            "2024-03-04 20:44:41.492092: val_loss -0.4116\n",
            "2024-03-04 20:44:41.492282: Pseudo dice [0.7283, 0.1716]\n",
            "2024-03-04 20:44:41.492409: Epoch time: 190.88 s\n",
            "2024-03-04 20:44:41.492508: Yayy! New best EMA pseudo Dice: 0.3081\n",
            "2024-03-04 20:44:44.224775: \n",
            "2024-03-04 20:44:44.224940: Epoch 3\n",
            "2024-03-04 20:44:44.225078: Current learning rate: 0.00973\n",
            "2024-03-04 20:48:02.947183: train_loss -0.4672\n",
            "2024-03-04 20:48:02.947529: val_loss -0.3982\n",
            "2024-03-04 20:48:02.947663: Pseudo dice [0.7248, 0.1454]\n",
            "2024-03-04 20:48:02.947774: Epoch time: 198.72 s\n",
            "2024-03-04 20:48:02.947862: Yayy! New best EMA pseudo Dice: 0.3208\n",
            "2024-03-04 20:48:06.122368: \n",
            "2024-03-04 20:48:06.122755: Epoch 4\n",
            "2024-03-04 20:48:06.122887: Current learning rate: 0.00964\n",
            "2024-03-04 20:51:16.960633: train_loss -0.5021\n",
            "2024-03-04 20:51:16.961019: val_loss -0.4642\n",
            "2024-03-04 20:51:16.961342: Pseudo dice [0.7501, 0.2752]\n",
            "2024-03-04 20:51:16.961464: Epoch time: 190.84 s\n",
            "2024-03-04 20:51:16.961555: Yayy! New best EMA pseudo Dice: 0.34\n",
            "2024-03-04 20:51:19.946120: \n",
            "2024-03-04 20:51:19.946297: Epoch 5\n",
            "2024-03-04 20:51:19.946422: Current learning rate: 0.00955\n",
            "2024-03-04 20:54:29.874694: train_loss -0.5324\n",
            "2024-03-04 20:54:29.875079: val_loss -0.4747\n",
            "2024-03-04 20:54:29.875221: Pseudo dice [0.7567, 0.257]\n",
            "2024-03-04 20:54:29.875338: Epoch time: 189.93 s\n",
            "2024-03-04 20:54:29.875429: Yayy! New best EMA pseudo Dice: 0.3566\n",
            "2024-03-04 20:54:32.389282: \n",
            "2024-03-04 20:54:32.389441: Epoch 6\n",
            "2024-03-04 20:54:32.389566: Current learning rate: 0.00946\n",
            "2024-03-04 20:57:43.139909: train_loss -0.5671\n",
            "2024-03-04 20:57:43.140274: val_loss -0.5072\n",
            "2024-03-04 20:57:43.140399: Pseudo dice [0.8049, 0.3215]\n",
            "2024-03-04 20:57:43.140515: Epoch time: 190.75 s\n",
            "2024-03-04 20:57:43.140613: Yayy! New best EMA pseudo Dice: 0.3773\n",
            "2024-03-04 20:57:46.918097: \n",
            "2024-03-04 20:57:46.918445: Epoch 7\n",
            "2024-03-04 20:57:46.918700: Current learning rate: 0.00937\n",
            "2024-03-04 21:01:01.748356: train_loss -0.6141\n",
            "2024-03-04 21:01:01.748701: val_loss -0.4548\n",
            "2024-03-04 21:01:01.748830: Pseudo dice [0.7458, 0.2705]\n",
            "2024-03-04 21:01:01.748948: Epoch time: 194.83 s\n",
            "2024-03-04 21:01:01.749063: Yayy! New best EMA pseudo Dice: 0.3904\n",
            "2024-03-04 21:01:04.383761: \n",
            "2024-03-04 21:01:04.383938: Epoch 8\n",
            "2024-03-04 21:01:04.384097: Current learning rate: 0.00928\n",
            "2024-03-04 21:04:20.265573: train_loss -0.6439\n",
            "2024-03-04 21:04:20.265897: val_loss -0.5433\n",
            "2024-03-04 21:04:20.266029: Pseudo dice [0.8071, 0.3954]\n",
            "2024-03-04 21:04:20.266154: Epoch time: 195.88 s\n",
            "2024-03-04 21:04:20.266244: Yayy! New best EMA pseudo Dice: 0.4115\n",
            "2024-03-04 21:04:23.079130: \n",
            "2024-03-04 21:04:23.079321: Epoch 9\n",
            "2024-03-04 21:04:23.079448: Current learning rate: 0.00919\n",
            "2024-03-04 21:07:24.000289: train_loss -0.6567\n",
            "2024-03-04 21:07:24.000645: val_loss -0.5682\n",
            "2024-03-04 21:07:24.000771: Pseudo dice [0.8363, 0.475]\n",
            "2024-03-04 21:07:24.000880: Epoch time: 180.92 s\n",
            "2024-03-04 21:07:24.000967: Yayy! New best EMA pseudo Dice: 0.4359\n",
            "2024-03-04 21:07:27.250211: \n",
            "2024-03-04 21:07:27.250394: Epoch 10\n",
            "2024-03-04 21:07:27.250546: Current learning rate: 0.0091\n",
            "2024-03-04 21:10:31.837075: train_loss -0.6537\n",
            "2024-03-04 21:10:31.837538: val_loss -0.4888\n",
            "2024-03-04 21:10:31.837792: Pseudo dice [0.7401, 0.2273]\n",
            "2024-03-04 21:10:31.838712: Epoch time: 184.59 s\n",
            "2024-03-04 21:10:31.838966: Yayy! New best EMA pseudo Dice: 0.4407\n",
            "2024-03-04 21:10:34.230015: \n",
            "2024-03-04 21:10:34.230188: Epoch 11\n",
            "2024-03-04 21:10:34.230316: Current learning rate: 0.009\n",
            "2024-03-04 21:13:39.319785: train_loss -0.6834\n",
            "2024-03-04 21:13:39.320222: val_loss -0.553\n",
            "2024-03-04 21:13:39.320662: Pseudo dice [0.8175, 0.5145]\n",
            "2024-03-04 21:13:39.320839: Epoch time: 185.09 s\n",
            "2024-03-04 21:13:39.320994: Yayy! New best EMA pseudo Dice: 0.4632\n",
            "2024-03-04 21:13:42.057056: \n",
            "2024-03-04 21:13:42.057233: Epoch 12\n",
            "2024-03-04 21:13:42.057358: Current learning rate: 0.00891\n",
            "2024-03-04 21:17:03.359024: train_loss -0.6995\n",
            "2024-03-04 21:17:03.373109: val_loss -0.5666\n",
            "2024-03-04 21:17:03.373525: Pseudo dice [0.8495, 0.5775]\n",
            "2024-03-04 21:17:03.373800: Epoch time: 201.3 s\n",
            "2024-03-04 21:17:03.373974: Yayy! New best EMA pseudo Dice: 0.4882\n",
            "2024-03-04 21:17:07.737708: \n",
            "2024-03-04 21:17:07.737899: Epoch 13\n",
            "2024-03-04 21:17:07.738078: Current learning rate: 0.00882\n",
            "2024-03-04 21:20:10.119626: train_loss -0.6876\n",
            "2024-03-04 21:20:10.119963: val_loss -0.5396\n",
            "2024-03-04 21:20:10.120134: Pseudo dice [0.7966, 0.3654]\n",
            "2024-03-04 21:20:10.120255: Epoch time: 182.38 s\n",
            "2024-03-04 21:20:10.120349: Yayy! New best EMA pseudo Dice: 0.4975\n",
            "2024-03-04 21:20:13.402483: \n",
            "2024-03-04 21:20:13.402667: Epoch 14\n",
            "2024-03-04 21:20:13.402784: Current learning rate: 0.00873\n",
            "2024-03-04 21:23:15.730757: train_loss -0.6893\n",
            "2024-03-04 21:23:15.731130: val_loss -0.6282\n",
            "2024-03-04 21:23:15.731264: Pseudo dice [0.8999, 0.6675]\n",
            "2024-03-04 21:23:15.731373: Epoch time: 182.33 s\n",
            "2024-03-04 21:23:15.731463: Yayy! New best EMA pseudo Dice: 0.5261\n",
            "2024-03-04 21:23:18.958736: \n",
            "2024-03-04 21:23:18.958901: Epoch 15\n",
            "2024-03-04 21:23:18.959050: Current learning rate: 0.00864\n",
            "2024-03-04 21:26:23.598401: train_loss -0.6968\n",
            "2024-03-04 21:26:23.598749: val_loss -0.5712\n",
            "2024-03-04 21:26:23.598876: Pseudo dice [0.7811, 0.4464]\n",
            "2024-03-04 21:26:23.599007: Epoch time: 184.64 s\n",
            "2024-03-04 21:26:23.599132: Yayy! New best EMA pseudo Dice: 0.5349\n",
            "2024-03-04 21:26:26.866715: \n",
            "2024-03-04 21:26:26.866880: Epoch 16\n",
            "2024-03-04 21:26:26.867006: Current learning rate: 0.00855\n",
            "2024-03-04 21:29:36.561692: train_loss -0.7263\n",
            "2024-03-04 21:29:36.562052: val_loss -0.5485\n",
            "2024-03-04 21:29:36.562196: Pseudo dice [0.8087, 0.3361]\n",
            "2024-03-04 21:29:36.562310: Epoch time: 189.7 s\n",
            "2024-03-04 21:29:36.562399: Yayy! New best EMA pseudo Dice: 0.5386\n",
            "2024-03-04 21:29:39.328955: \n",
            "2024-03-04 21:29:39.329140: Epoch 17\n",
            "2024-03-04 21:29:39.329271: Current learning rate: 0.00846\n",
            "2024-03-04 21:32:46.861184: train_loss -0.7506\n",
            "2024-03-04 21:32:46.872752: val_loss -0.4943\n",
            "2024-03-04 21:32:46.873073: Pseudo dice [0.7756, 0.1718]\n",
            "2024-03-04 21:32:46.873265: Epoch time: 187.53 s\n",
            "2024-03-04 21:32:50.471605: \n",
            "2024-03-04 21:32:50.471848: Epoch 18\n",
            "2024-03-04 21:32:50.472016: Current learning rate: 0.00836\n",
            "2024-03-04 21:35:56.802213: train_loss -0.7422\n",
            "2024-03-04 21:35:56.802696: val_loss -0.6466\n",
            "2024-03-04 21:35:56.802873: Pseudo dice [0.895, 0.6794]\n",
            "2024-03-04 21:35:56.803058: Epoch time: 186.33 s\n",
            "2024-03-04 21:35:56.803195: Yayy! New best EMA pseudo Dice: 0.5577\n",
            "2024-03-04 21:36:00.083992: \n",
            "2024-03-04 21:36:00.084209: Epoch 19\n",
            "2024-03-04 21:36:00.084337: Current learning rate: 0.00827\n",
            "2024-03-04 21:39:10.366049: train_loss -0.7486\n",
            "2024-03-04 21:39:10.366405: val_loss -0.6113\n",
            "2024-03-04 21:39:10.366533: Pseudo dice [0.8552, 0.5489]\n",
            "2024-03-04 21:39:10.366666: Epoch time: 190.28 s\n",
            "2024-03-04 21:39:10.366756: Yayy! New best EMA pseudo Dice: 0.5721\n",
            "2024-03-04 21:39:13.060580: \n",
            "2024-03-04 21:39:13.060777: Epoch 20\n",
            "2024-03-04 21:39:13.060924: Current learning rate: 0.00818\n",
            "2024-03-04 21:42:17.144823: train_loss -0.7746\n",
            "2024-03-04 21:42:17.145264: val_loss -0.6665\n",
            "2024-03-04 21:42:17.145445: Pseudo dice [0.902, 0.6698]\n",
            "2024-03-04 21:42:17.145580: Epoch time: 184.09 s\n",
            "2024-03-04 21:42:17.145693: Yayy! New best EMA pseudo Dice: 0.5935\n",
            "2024-03-04 21:42:20.616713: \n",
            "2024-03-04 21:42:20.616894: Epoch 21\n",
            "2024-03-04 21:42:20.617038: Current learning rate: 0.00809\n",
            "2024-03-04 21:45:33.600800: train_loss -0.7539\n",
            "2024-03-04 21:45:33.601489: val_loss -0.464\n",
            "2024-03-04 21:45:33.601665: Pseudo dice [0.6935, 0.2126]\n",
            "2024-03-04 21:45:33.601790: Epoch time: 192.99 s\n",
            "2024-03-04 21:45:36.312599: \n",
            "2024-03-04 21:45:36.312800: Epoch 22\n",
            "2024-03-04 21:45:36.312935: Current learning rate: 0.008\n",
            "2024-03-04 21:48:54.160387: train_loss -0.7617\n",
            "2024-03-04 21:48:54.160771: val_loss -0.6313\n",
            "2024-03-04 21:48:54.160903: Pseudo dice [0.8739, 0.6018]\n",
            "2024-03-04 21:48:54.161044: Epoch time: 197.85 s\n",
            "2024-03-04 21:48:54.161159: Yayy! New best EMA pseudo Dice: 0.5953\n",
            "2024-03-04 21:48:57.572443: \n",
            "2024-03-04 21:48:57.572647: Epoch 23\n",
            "2024-03-04 21:48:57.572820: Current learning rate: 0.0079\n",
            "2024-03-04 21:52:11.941893: train_loss -0.7574\n",
            "2024-03-04 21:52:11.943174: val_loss -0.5736\n",
            "2024-03-04 21:52:11.943345: Pseudo dice [0.8401, 0.5302]\n",
            "2024-03-04 21:52:11.943465: Epoch time: 194.37 s\n",
            "2024-03-04 21:52:11.943557: Yayy! New best EMA pseudo Dice: 0.6043\n",
            "2024-03-04 21:52:15.092520: \n",
            "2024-03-04 21:52:15.092694: Epoch 24\n",
            "2024-03-04 21:52:15.092819: Current learning rate: 0.00781\n",
            "2024-03-04 21:55:17.061177: train_loss -0.7844\n",
            "2024-03-04 21:55:17.082671: val_loss -0.7234\n",
            "2024-03-04 21:55:17.082940: Pseudo dice [0.9258, 0.7173]\n",
            "2024-03-04 21:55:17.083098: Epoch time: 181.97 s\n",
            "2024-03-04 21:55:17.083194: Yayy! New best EMA pseudo Dice: 0.626\n",
            "2024-03-04 21:55:21.619264: \n",
            "2024-03-04 21:55:21.619450: Epoch 25\n",
            "2024-03-04 21:55:21.619623: Current learning rate: 0.00772\n",
            "2024-03-04 21:58:36.555813: train_loss -0.7739\n",
            "2024-03-04 21:58:36.556233: val_loss -0.5766\n",
            "2024-03-04 21:58:36.556376: Pseudo dice [0.8396, 0.5335]\n",
            "2024-03-04 21:58:36.556489: Epoch time: 194.94 s\n",
            "2024-03-04 21:58:36.556580: Yayy! New best EMA pseudo Dice: 0.6321\n",
            "2024-03-04 21:58:39.700706: \n",
            "2024-03-04 21:58:39.700890: Epoch 26\n",
            "2024-03-04 21:58:39.701032: Current learning rate: 0.00763\n",
            "2024-03-04 22:01:38.210845: train_loss -0.7884\n",
            "2024-03-04 22:01:38.222635: val_loss -0.6918\n",
            "2024-03-04 22:01:38.222828: Pseudo dice [0.9261, 0.7354]\n",
            "2024-03-04 22:01:38.222952: Epoch time: 178.51 s\n",
            "2024-03-04 22:01:38.223076: Yayy! New best EMA pseudo Dice: 0.6519\n",
            "2024-03-04 22:01:40.871439: \n",
            "2024-03-04 22:01:40.871614: Epoch 27\n",
            "2024-03-04 22:01:40.871735: Current learning rate: 0.00753\n",
            "2024-03-04 22:04:54.092872: train_loss -0.7901\n",
            "2024-03-04 22:04:54.093327: val_loss -0.6724\n",
            "2024-03-04 22:04:54.093669: Pseudo dice [0.9119, 0.653]\n",
            "2024-03-04 22:04:54.093868: Epoch time: 193.22 s\n",
            "2024-03-04 22:04:54.094054: Yayy! New best EMA pseudo Dice: 0.665\n",
            "2024-03-04 22:04:57.851601: \n",
            "2024-03-04 22:04:57.851773: Epoch 28\n",
            "2024-03-04 22:04:57.851921: Current learning rate: 0.00744\n",
            "2024-03-04 22:08:16.561631: train_loss -0.7972\n",
            "2024-03-04 22:08:16.564821: val_loss -0.6625\n",
            "2024-03-04 22:08:16.565132: Pseudo dice [0.885, 0.5841]\n",
            "2024-03-04 22:08:16.565391: Epoch time: 198.71 s\n",
            "2024-03-04 22:08:16.565501: Yayy! New best EMA pseudo Dice: 0.6719\n",
            "2024-03-04 22:08:20.827532: \n",
            "2024-03-04 22:08:20.827829: Epoch 29\n",
            "2024-03-04 22:08:20.828003: Current learning rate: 0.00735\n",
            "2024-03-04 22:11:35.907510: train_loss -0.8141\n",
            "2024-03-04 22:11:35.907906: val_loss -0.7098\n",
            "2024-03-04 22:11:35.908132: Pseudo dice [0.9276, 0.6764]\n",
            "2024-03-04 22:11:35.908272: Epoch time: 195.08 s\n",
            "2024-03-04 22:11:35.908382: Yayy! New best EMA pseudo Dice: 0.6849\n",
            "2024-03-04 22:11:38.932762: \n",
            "2024-03-04 22:11:38.932936: Epoch 30\n",
            "2024-03-04 22:11:38.933088: Current learning rate: 0.00725\n",
            "2024-03-04 22:14:55.734008: train_loss -0.8104\n",
            "2024-03-04 22:14:55.734370: val_loss -0.6731\n",
            "2024-03-04 22:14:55.734520: Pseudo dice [0.8656, 0.6584]\n",
            "2024-03-04 22:14:55.734639: Epoch time: 196.8 s\n",
            "2024-03-04 22:14:55.734755: Yayy! New best EMA pseudo Dice: 0.6926\n",
            "2024-03-04 22:14:58.733180: \n",
            "2024-03-04 22:14:58.733340: Epoch 31\n",
            "2024-03-04 22:14:58.733468: Current learning rate: 0.00716\n",
            "2024-03-04 22:18:11.331465: train_loss -0.8092\n",
            "2024-03-04 22:18:11.331814: val_loss -0.6828\n",
            "2024-03-04 22:18:11.331945: Pseudo dice [0.8915, 0.6731]\n",
            "2024-03-04 22:18:11.332090: Epoch time: 192.6 s\n",
            "2024-03-04 22:18:11.332189: Yayy! New best EMA pseudo Dice: 0.7016\n",
            "2024-03-04 22:18:16.280650: \n",
            "2024-03-04 22:18:16.281065: Epoch 32\n",
            "2024-03-04 22:18:16.281235: Current learning rate: 0.00707\n",
            "2024-03-04 22:21:41.101808: train_loss -0.8223\n",
            "2024-03-04 22:21:41.115111: val_loss -0.6987\n",
            "2024-03-04 22:21:41.115379: Pseudo dice [0.8917, 0.6675]\n",
            "2024-03-04 22:21:41.115505: Epoch time: 204.82 s\n",
            "2024-03-04 22:21:41.115596: Yayy! New best EMA pseudo Dice: 0.7094\n",
            "2024-03-04 22:21:45.487204: \n",
            "2024-03-04 22:21:45.487373: Epoch 33\n",
            "2024-03-04 22:21:45.487502: Current learning rate: 0.00697\n",
            "2024-03-04 22:24:58.801887: train_loss -0.8178\n",
            "2024-03-04 22:24:58.808123: val_loss -0.6417\n",
            "2024-03-04 22:24:58.808308: Pseudo dice [0.8459, 0.5467]\n",
            "2024-03-04 22:24:58.808422: Epoch time: 193.32 s\n",
            "2024-03-04 22:25:01.046409: \n",
            "2024-03-04 22:25:01.046611: Epoch 34\n",
            "2024-03-04 22:25:01.046768: Current learning rate: 0.00688\n",
            "2024-03-04 22:28:08.687616: train_loss -0.8172\n",
            "2024-03-04 22:28:08.688004: val_loss -0.6851\n",
            "2024-03-04 22:28:08.688145: Pseudo dice [0.8821, 0.6022]\n",
            "2024-03-04 22:28:08.688261: Epoch time: 187.64 s\n",
            "2024-03-04 22:28:08.688351: Yayy! New best EMA pseudo Dice: 0.7115\n",
            "2024-03-04 22:28:11.565749: \n",
            "2024-03-04 22:28:11.565923: Epoch 35\n",
            "2024-03-04 22:28:11.566051: Current learning rate: 0.00679\n",
            "2024-03-04 22:31:21.979453: train_loss -0.8156\n",
            "2024-03-04 22:31:21.979819: val_loss -0.6595\n",
            "2024-03-04 22:31:21.979949: Pseudo dice [0.8718, 0.6159]\n",
            "2024-03-04 22:31:21.980091: Epoch time: 190.41 s\n",
            "2024-03-04 22:31:21.980206: Yayy! New best EMA pseudo Dice: 0.7147\n",
            "2024-03-04 22:31:24.628038: \n",
            "2024-03-04 22:31:24.628257: Epoch 36\n",
            "2024-03-04 22:31:24.628425: Current learning rate: 0.00669\n",
            "2024-03-04 22:34:42.456029: train_loss -0.8333\n",
            "2024-03-04 22:34:42.456393: val_loss -0.6965\n",
            "2024-03-04 22:34:42.456538: Pseudo dice [0.8777, 0.6544]\n",
            "2024-03-04 22:34:42.456681: Epoch time: 197.83 s\n",
            "2024-03-04 22:34:42.456799: Yayy! New best EMA pseudo Dice: 0.7199\n",
            "2024-03-04 22:34:46.840675: \n",
            "2024-03-04 22:34:46.840861: Epoch 37\n",
            "2024-03-04 22:34:46.841003: Current learning rate: 0.0066\n",
            "2024-03-04 22:38:08.591095: train_loss -0.8151\n",
            "2024-03-04 22:38:08.591489: val_loss -0.6397\n",
            "2024-03-04 22:38:08.591642: Pseudo dice [0.8665, 0.6244]\n",
            "2024-03-04 22:38:08.591785: Epoch time: 201.75 s\n",
            "2024-03-04 22:38:08.591882: Yayy! New best EMA pseudo Dice: 0.7224\n",
            "2024-03-04 22:38:12.344280: \n",
            "2024-03-04 22:38:12.344494: Epoch 38\n",
            "2024-03-04 22:38:12.344633: Current learning rate: 0.0065\n",
            "2024-03-04 22:41:24.839474: train_loss -0.8099\n",
            "2024-03-04 22:41:24.839873: val_loss -0.73\n",
            "2024-03-04 22:41:24.840066: Pseudo dice [0.9211, 0.6875]\n",
            "2024-03-04 22:41:24.840221: Epoch time: 192.5 s\n",
            "2024-03-04 22:41:24.840341: Yayy! New best EMA pseudo Dice: 0.7306\n",
            "2024-03-04 22:41:27.763870: \n",
            "2024-03-04 22:41:27.764098: Epoch 39\n",
            "2024-03-04 22:41:27.764232: Current learning rate: 0.00641\n",
            "2024-03-04 22:44:43.403724: train_loss -0.822\n",
            "2024-03-04 22:44:43.404262: val_loss -0.7279\n",
            "2024-03-04 22:44:43.404494: Pseudo dice [0.9297, 0.8064]\n",
            "2024-03-04 22:44:43.404704: Epoch time: 195.64 s\n",
            "2024-03-04 22:44:43.404889: Yayy! New best EMA pseudo Dice: 0.7444\n",
            "2024-03-04 22:44:46.378133: \n",
            "2024-03-04 22:44:46.378317: Epoch 40\n",
            "2024-03-04 22:44:46.378437: Current learning rate: 0.00631\n",
            "2024-03-04 22:48:03.485983: train_loss -0.8352\n",
            "2024-03-04 22:48:03.486362: val_loss -0.702\n",
            "2024-03-04 22:48:03.489029: Pseudo dice [0.909, 0.6514]\n",
            "2024-03-04 22:48:03.489428: Epoch time: 197.11 s\n",
            "2024-03-04 22:48:03.489544: Yayy! New best EMA pseudo Dice: 0.7479\n",
            "2024-03-04 22:48:07.300665: \n",
            "2024-03-04 22:48:07.300906: Epoch 41\n",
            "2024-03-04 22:48:07.301091: Current learning rate: 0.00622\n",
            "2024-03-04 22:51:25.613194: train_loss -0.8361\n",
            "2024-03-04 22:51:25.613545: val_loss -0.7145\n",
            "2024-03-04 22:51:25.613663: Pseudo dice [0.9143, 0.7278]\n",
            "2024-03-04 22:51:25.613775: Epoch time: 198.31 s\n",
            "2024-03-04 22:51:25.613864: Yayy! New best EMA pseudo Dice: 0.7553\n",
            "2024-03-04 22:51:28.250691: \n",
            "2024-03-04 22:51:28.250942: Epoch 42\n",
            "2024-03-04 22:51:28.251089: Current learning rate: 0.00612\n",
            "2024-03-04 22:54:41.263342: train_loss -0.844\n",
            "2024-03-04 22:54:41.263692: val_loss -0.7045\n",
            "2024-03-04 22:54:41.263824: Pseudo dice [0.9153, 0.69]\n",
            "2024-03-04 22:54:41.263937: Epoch time: 193.01 s\n",
            "2024-03-04 22:54:41.264051: Yayy! New best EMA pseudo Dice: 0.76\n",
            "2024-03-04 22:54:44.038219: \n",
            "2024-03-04 22:54:44.038416: Epoch 43\n",
            "2024-03-04 22:54:44.038543: Current learning rate: 0.00603\n",
            "2024-03-04 22:57:56.798063: train_loss -0.8441\n",
            "2024-03-04 22:57:56.798405: val_loss -0.6734\n",
            "2024-03-04 22:57:56.798540: Pseudo dice [0.8868, 0.6587]\n",
            "2024-03-04 22:57:56.798676: Epoch time: 192.76 s\n",
            "2024-03-04 22:57:56.798778: Yayy! New best EMA pseudo Dice: 0.7613\n",
            "2024-03-04 22:58:00.220019: \n",
            "2024-03-04 22:58:00.220196: Epoch 44\n",
            "2024-03-04 22:58:00.220322: Current learning rate: 0.00593\n",
            "2024-03-04 23:01:19.232179: train_loss -0.8521\n",
            "2024-03-04 23:01:19.245128: val_loss -0.7472\n",
            "2024-03-04 23:01:19.245600: Pseudo dice [0.9345, 0.6954]\n",
            "2024-03-04 23:01:19.245778: Epoch time: 199.01 s\n",
            "2024-03-04 23:01:19.245906: Yayy! New best EMA pseudo Dice: 0.7666\n",
            "2024-03-04 23:01:22.632633: \n",
            "2024-03-04 23:01:22.632814: Epoch 45\n",
            "2024-03-04 23:01:22.632990: Current learning rate: 0.00584\n",
            "2024-03-04 23:04:37.437681: train_loss -0.8497\n",
            "2024-03-04 23:04:37.438070: val_loss -0.7351\n",
            "2024-03-04 23:04:37.438205: Pseudo dice [0.93, 0.7575]\n",
            "2024-03-04 23:04:37.438317: Epoch time: 194.81 s\n",
            "2024-03-04 23:04:37.438403: Yayy! New best EMA pseudo Dice: 0.7743\n",
            "2024-03-04 23:04:41.012214: \n",
            "2024-03-04 23:04:41.012392: Epoch 46\n",
            "2024-03-04 23:04:41.012526: Current learning rate: 0.00574\n",
            "2024-03-04 23:08:00.159202: train_loss -0.8471\n",
            "2024-03-04 23:08:00.159617: val_loss -0.75\n",
            "2024-03-04 23:08:00.159765: Pseudo dice [0.9412, 0.7744]\n",
            "2024-03-04 23:08:00.159883: Epoch time: 199.15 s\n",
            "2024-03-04 23:08:00.159987: Yayy! New best EMA pseudo Dice: 0.7827\n",
            "2024-03-04 23:08:03.238161: \n",
            "2024-03-04 23:08:03.238346: Epoch 47\n",
            "2024-03-04 23:08:03.238532: Current learning rate: 0.00565\n",
            "2024-03-04 23:11:22.358598: train_loss -0.8415\n",
            "2024-03-04 23:11:22.358955: val_loss -0.7241\n",
            "2024-03-04 23:11:22.359128: Pseudo dice [0.9302, 0.7298]\n",
            "2024-03-04 23:11:22.359425: Epoch time: 199.12 s\n",
            "2024-03-04 23:11:22.359554: Yayy! New best EMA pseudo Dice: 0.7874\n",
            "2024-03-04 23:11:26.435914: \n",
            "2024-03-04 23:11:26.436319: Epoch 48\n",
            "2024-03-04 23:11:26.436561: Current learning rate: 0.00555\n",
            "2024-03-04 23:14:43.208265: train_loss -0.8392\n",
            "2024-03-04 23:14:43.208791: val_loss -0.7419\n",
            "2024-03-04 23:14:43.209057: Pseudo dice [0.9052, 0.6866]\n",
            "2024-03-04 23:14:43.209292: Epoch time: 196.77 s\n",
            "2024-03-04 23:14:43.209445: Yayy! New best EMA pseudo Dice: 0.7883\n",
            "2024-03-04 23:14:46.319078: \n",
            "2024-03-04 23:14:46.319253: Epoch 49\n",
            "2024-03-04 23:14:46.319373: Current learning rate: 0.00546\n",
            "2024-03-04 23:17:59.124329: train_loss -0.8526\n",
            "2024-03-04 23:17:59.124676: val_loss -0.6935\n",
            "2024-03-04 23:17:59.124808: Pseudo dice [0.9273, 0.7204]\n",
            "2024-03-04 23:17:59.124923: Epoch time: 192.81 s\n",
            "2024-03-04 23:18:00.066303: Yayy! New best EMA pseudo Dice: 0.7918\n",
            "2024-03-04 23:18:02.745557: \n",
            "2024-03-04 23:18:02.745766: Epoch 50\n",
            "2024-03-04 23:18:02.745898: Current learning rate: 0.00536\n",
            "2024-03-04 23:21:16.862570: train_loss -0.8489\n",
            "2024-03-04 23:21:16.862931: val_loss -0.7265\n",
            "2024-03-04 23:21:16.863076: Pseudo dice [0.9237, 0.7201]\n",
            "2024-03-04 23:21:16.863197: Epoch time: 194.12 s\n",
            "2024-03-04 23:21:16.863357: Yayy! New best EMA pseudo Dice: 0.7948\n",
            "2024-03-04 23:21:19.221286: \n",
            "2024-03-04 23:21:19.221461: Epoch 51\n",
            "2024-03-04 23:21:19.221587: Current learning rate: 0.00526\n",
            "2024-03-04 23:24:34.055589: train_loss -0.8518\n",
            "2024-03-04 23:24:34.074108: val_loss -0.7258\n",
            "2024-03-04 23:24:34.074400: Pseudo dice [0.9362, 0.7742]\n",
            "2024-03-04 23:24:34.074571: Epoch time: 194.84 s\n",
            "2024-03-04 23:24:34.074695: Yayy! New best EMA pseudo Dice: 0.8009\n",
            "2024-03-04 23:24:36.979171: \n",
            "2024-03-04 23:24:36.979362: Epoch 52\n",
            "2024-03-04 23:24:36.979502: Current learning rate: 0.00517\n",
            "2024-03-04 23:27:51.807083: train_loss -0.856\n",
            "2024-03-04 23:27:51.807448: val_loss -0.781\n",
            "2024-03-04 23:27:51.807616: Pseudo dice [0.9384, 0.7818]\n",
            "2024-03-04 23:27:51.807754: Epoch time: 194.83 s\n",
            "2024-03-04 23:27:51.807862: Yayy! New best EMA pseudo Dice: 0.8068\n",
            "2024-03-04 23:27:54.399263: \n",
            "2024-03-04 23:27:54.399447: Epoch 53\n",
            "2024-03-04 23:27:54.399590: Current learning rate: 0.00507\n",
            "2024-03-04 23:31:18.014212: train_loss -0.8511\n",
            "2024-03-04 23:31:18.014556: val_loss -0.7139\n",
            "2024-03-04 23:31:18.014702: Pseudo dice [0.9129, 0.6646]\n",
            "2024-03-04 23:31:18.014814: Epoch time: 203.62 s\n",
            "2024-03-04 23:31:20.925035: \n",
            "2024-03-04 23:31:20.925195: Epoch 54\n",
            "2024-03-04 23:31:20.925306: Current learning rate: 0.00497\n",
            "2024-03-04 23:34:34.031309: train_loss -0.8523\n",
            "2024-03-04 23:34:34.031665: val_loss -0.7141\n",
            "2024-03-04 23:34:34.031788: Pseudo dice [0.9457, 0.7238]\n",
            "2024-03-04 23:34:34.031899: Epoch time: 193.11 s\n",
            "2024-03-04 23:34:34.032026: Yayy! New best EMA pseudo Dice: 0.808\n",
            "2024-03-04 23:34:37.677118: \n",
            "2024-03-04 23:34:37.677313: Epoch 55\n",
            "2024-03-04 23:34:37.677459: Current learning rate: 0.00487\n",
            "2024-03-04 23:37:53.528806: train_loss -0.8616\n",
            "2024-03-04 23:37:53.529179: val_loss -0.7236\n",
            "2024-03-04 23:37:53.529313: Pseudo dice [0.9216, 0.6833]\n",
            "2024-03-04 23:37:53.529432: Epoch time: 195.85 s\n",
            "2024-03-04 23:37:55.378687: \n",
            "2024-03-04 23:37:55.378906: Epoch 56\n",
            "2024-03-04 23:37:55.379060: Current learning rate: 0.00478\n",
            "2024-03-04 23:40:52.216257: train_loss -0.8647\n",
            "2024-03-04 23:40:52.216621: val_loss -0.7185\n",
            "2024-03-04 23:40:52.216754: Pseudo dice [0.9293, 0.7268]\n",
            "2024-03-04 23:40:52.216864: Epoch time: 176.84 s\n",
            "2024-03-04 23:40:52.216952: Yayy! New best EMA pseudo Dice: 0.8095\n",
            "2024-03-04 23:40:54.670969: \n",
            "2024-03-04 23:40:54.671143: Epoch 57\n",
            "2024-03-04 23:40:54.671285: Current learning rate: 0.00468\n",
            "2024-03-04 23:43:57.000409: train_loss -0.8614\n",
            "2024-03-04 23:43:57.000725: val_loss -0.762\n",
            "2024-03-04 23:43:57.000848: Pseudo dice [0.9358, 0.7847]\n",
            "2024-03-04 23:43:57.000956: Epoch time: 182.33 s\n",
            "2024-03-04 23:43:57.001068: Yayy! New best EMA pseudo Dice: 0.8146\n",
            "2024-03-04 23:44:00.320604: \n",
            "2024-03-04 23:44:00.320776: Epoch 58\n",
            "2024-03-04 23:44:00.320960: Current learning rate: 0.00458\n",
            "2024-03-04 23:47:22.209308: train_loss -0.8593\n",
            "2024-03-04 23:47:22.209669: val_loss -0.7483\n",
            "2024-03-04 23:47:22.209799: Pseudo dice [0.9193, 0.7278]\n",
            "2024-03-04 23:47:22.209909: Epoch time: 201.89 s\n",
            "2024-03-04 23:47:22.210031: Yayy! New best EMA pseudo Dice: 0.8155\n",
            "2024-03-04 23:47:25.064252: \n",
            "2024-03-04 23:47:25.064416: Epoch 59\n",
            "2024-03-04 23:47:25.064568: Current learning rate: 0.00448\n",
            "2024-03-04 23:50:27.035341: train_loss -0.8648\n",
            "2024-03-04 23:50:27.035846: val_loss -0.7732\n",
            "2024-03-04 23:50:27.036136: Pseudo dice [0.9473, 0.7751]\n",
            "2024-03-04 23:50:27.036394: Epoch time: 181.97 s\n",
            "2024-03-04 23:50:27.036663: Yayy! New best EMA pseudo Dice: 0.82\n",
            "2024-03-04 23:50:31.249787: \n",
            "2024-03-04 23:50:31.249964: Epoch 60\n",
            "2024-03-04 23:50:31.250097: Current learning rate: 0.00438\n",
            "2024-03-04 23:53:36.055212: train_loss -0.8643\n",
            "2024-03-04 23:53:36.055545: val_loss -0.7489\n",
            "2024-03-04 23:53:36.055674: Pseudo dice [0.9372, 0.7705]\n",
            "2024-03-04 23:53:36.055787: Epoch time: 184.81 s\n",
            "2024-03-04 23:53:36.055888: Yayy! New best EMA pseudo Dice: 0.8234\n",
            "2024-03-04 23:53:39.557068: \n",
            "2024-03-04 23:53:39.557245: Epoch 61\n",
            "2024-03-04 23:53:39.557397: Current learning rate: 0.00429\n",
            "2024-03-04 23:56:46.180274: train_loss -0.8667\n",
            "2024-03-04 23:56:46.180623: val_loss -0.7469\n",
            "2024-03-04 23:56:46.180744: Pseudo dice [0.9334, 0.7511]\n",
            "2024-03-04 23:56:46.180855: Epoch time: 186.62 s\n",
            "2024-03-04 23:56:46.180941: Yayy! New best EMA pseudo Dice: 0.8253\n",
            "2024-03-04 23:56:48.673816: \n",
            "2024-03-04 23:56:48.674050: Epoch 62\n",
            "2024-03-04 23:56:48.674217: Current learning rate: 0.00419\n",
            "2024-03-05 00:00:00.668360: train_loss -0.8703\n",
            "2024-03-05 00:00:00.668708: val_loss -0.7336\n",
            "2024-03-05 00:00:00.668837: Pseudo dice [0.9371, 0.6375]\n",
            "2024-03-05 00:00:00.669164: Epoch time: 192.0 s\n",
            "2024-03-05 00:00:03.515898: \n",
            "2024-03-05 00:00:03.516118: Epoch 63\n",
            "2024-03-05 00:00:03.516261: Current learning rate: 0.00409\n",
            "2024-03-05 00:03:14.366889: train_loss -0.8702\n",
            "2024-03-05 00:03:14.367241: val_loss -0.7397\n",
            "2024-03-05 00:03:14.367365: Pseudo dice [0.9342, 0.7526]\n",
            "2024-03-05 00:03:14.367475: Epoch time: 190.85 s\n",
            "2024-03-05 00:03:18.238603: \n",
            "2024-03-05 00:03:18.238855: Epoch 64\n",
            "2024-03-05 00:03:18.239038: Current learning rate: 0.00399\n",
            "2024-03-05 00:06:35.552281: train_loss -0.8669\n",
            "2024-03-05 00:06:35.552830: val_loss -0.7497\n",
            "2024-03-05 00:06:35.553000: Pseudo dice [0.9331, 0.7254]\n",
            "2024-03-05 00:06:35.553137: Epoch time: 197.32 s\n",
            "2024-03-05 00:06:38.588817: \n",
            "2024-03-05 00:06:38.589031: Epoch 65\n",
            "2024-03-05 00:06:38.589193: Current learning rate: 0.00389\n",
            "2024-03-05 00:09:52.490213: train_loss -0.8705\n",
            "2024-03-05 00:09:52.490553: val_loss -0.7478\n",
            "2024-03-05 00:09:52.490686: Pseudo dice [0.9336, 0.696]\n",
            "2024-03-05 00:09:52.490798: Epoch time: 193.9 s\n",
            "2024-03-05 00:09:55.226457: \n",
            "2024-03-05 00:09:55.226689: Epoch 66\n",
            "2024-03-05 00:09:55.226858: Current learning rate: 0.00379\n",
            "2024-03-05 00:13:04.698743: train_loss -0.8697\n",
            "2024-03-05 00:13:04.699186: val_loss -0.7281\n",
            "2024-03-05 00:13:04.699350: Pseudo dice [0.9382, 0.7427]\n",
            "2024-03-05 00:13:04.699489: Epoch time: 189.47 s\n",
            "2024-03-05 00:13:06.893841: \n",
            "2024-03-05 00:13:06.894089: Epoch 67\n",
            "2024-03-05 00:13:06.894255: Current learning rate: 0.00369\n",
            "2024-03-05 00:16:15.584137: train_loss -0.8768\n",
            "2024-03-05 00:16:15.584494: val_loss -0.7076\n",
            "2024-03-05 00:16:15.584688: Pseudo dice [0.9311, 0.6597]\n",
            "2024-03-05 00:16:15.584822: Epoch time: 188.69 s\n",
            "2024-03-05 00:16:17.832590: \n",
            "2024-03-05 00:16:17.832840: Epoch 68\n",
            "2024-03-05 00:16:17.833014: Current learning rate: 0.00359\n",
            "2024-03-05 00:19:29.161257: train_loss -0.8715\n",
            "2024-03-05 00:19:29.161636: val_loss -0.7581\n",
            "2024-03-05 00:19:29.161760: Pseudo dice [0.9292, 0.6791]\n",
            "2024-03-05 00:19:29.161876: Epoch time: 191.33 s\n",
            "2024-03-05 00:19:31.971287: \n",
            "2024-03-05 00:19:31.971827: Epoch 69\n",
            "2024-03-05 00:19:31.971995: Current learning rate: 0.00349\n",
            "2024-03-05 00:22:47.040875: train_loss -0.8753\n",
            "2024-03-05 00:22:47.041243: val_loss -0.7705\n",
            "2024-03-05 00:22:47.041387: Pseudo dice [0.9468, 0.7323]\n",
            "2024-03-05 00:22:47.041513: Epoch time: 195.07 s\n",
            "2024-03-05 00:22:49.386463: \n",
            "2024-03-05 00:22:49.386735: Epoch 70\n",
            "2024-03-05 00:22:49.386990: Current learning rate: 0.00338\n",
            "2024-03-05 00:25:56.527136: train_loss -0.8745\n",
            "2024-03-05 00:25:56.527613: val_loss -0.7736\n",
            "2024-03-05 00:25:56.527755: Pseudo dice [0.9401, 0.8066]\n",
            "2024-03-05 00:25:56.527875: Epoch time: 187.14 s\n",
            "2024-03-05 00:25:56.527983: Yayy! New best EMA pseudo Dice: 0.8273\n",
            "2024-03-05 00:25:59.689366: \n",
            "2024-03-05 00:25:59.689587: Epoch 71\n",
            "2024-03-05 00:25:59.689775: Current learning rate: 0.00328\n",
            "2024-03-05 00:29:02.421593: train_loss -0.8797\n",
            "2024-03-05 00:29:02.421931: val_loss -0.7493\n",
            "2024-03-05 00:29:02.422077: Pseudo dice [0.9486, 0.8152]\n",
            "2024-03-05 00:29:02.422190: Epoch time: 182.73 s\n",
            "2024-03-05 00:29:02.422276: Yayy! New best EMA pseudo Dice: 0.8328\n",
            "2024-03-05 00:29:04.970389: \n",
            "2024-03-05 00:29:04.970562: Epoch 72\n",
            "2024-03-05 00:29:04.970721: Current learning rate: 0.00318\n",
            "2024-03-05 00:32:14.224999: train_loss -0.8765\n",
            "2024-03-05 00:32:14.225367: val_loss -0.7142\n",
            "2024-03-05 00:32:14.247343: Pseudo dice [0.928, 0.7668]\n",
            "2024-03-05 00:32:14.247600: Epoch time: 189.26 s\n",
            "2024-03-05 00:32:14.247768: Yayy! New best EMA pseudo Dice: 0.8342\n",
            "2024-03-05 00:32:17.347000: \n",
            "2024-03-05 00:32:17.347180: Epoch 73\n",
            "2024-03-05 00:32:17.347326: Current learning rate: 0.00308\n",
            "2024-03-05 00:35:35.581273: train_loss -0.8715\n",
            "2024-03-05 00:35:35.581677: val_loss -0.7347\n",
            "2024-03-05 00:35:35.581816: Pseudo dice [0.9265, 0.771]\n",
            "2024-03-05 00:35:35.581930: Epoch time: 198.24 s\n",
            "2024-03-05 00:35:35.582304: Yayy! New best EMA pseudo Dice: 0.8357\n",
            "2024-03-05 00:35:38.007642: \n",
            "2024-03-05 00:35:38.007875: Epoch 74\n",
            "2024-03-05 00:35:38.008021: Current learning rate: 0.00297\n",
            "2024-03-05 00:38:43.245360: train_loss -0.8761\n",
            "2024-03-05 00:38:43.245752: val_loss -0.7192\n",
            "2024-03-05 00:38:43.245893: Pseudo dice [0.9271, 0.7286]\n",
            "2024-03-05 00:38:43.246062: Epoch time: 185.24 s\n",
            "2024-03-05 00:38:45.275049: \n",
            "2024-03-05 00:38:45.275305: Epoch 75\n",
            "2024-03-05 00:38:45.275543: Current learning rate: 0.00287\n",
            "2024-03-05 00:41:57.324907: train_loss -0.8803\n",
            "2024-03-05 00:41:57.325294: val_loss -0.7265\n",
            "2024-03-05 00:41:57.325446: Pseudo dice [0.9231, 0.7057]\n",
            "2024-03-05 00:41:57.325572: Epoch time: 192.05 s\n",
            "2024-03-05 00:41:59.706968: \n",
            "2024-03-05 00:41:59.707189: Epoch 76\n",
            "2024-03-05 00:41:59.707333: Current learning rate: 0.00277\n",
            "2024-03-05 00:45:06.664360: train_loss -0.8767\n",
            "2024-03-05 00:45:06.664767: val_loss -0.7502\n",
            "2024-03-05 00:45:06.664924: Pseudo dice [0.9274, 0.7498]\n",
            "2024-03-05 00:45:06.665106: Epoch time: 186.96 s\n",
            "2024-03-05 00:45:08.835536: \n",
            "2024-03-05 00:45:08.835748: Epoch 77\n",
            "2024-03-05 00:45:08.835886: Current learning rate: 0.00266\n",
            "2024-03-05 00:48:15.435240: train_loss -0.8809\n",
            "2024-03-05 00:48:15.435612: val_loss -0.7364\n",
            "2024-03-05 00:48:15.435778: Pseudo dice [0.9238, 0.7078]\n",
            "2024-03-05 00:48:15.435929: Epoch time: 186.6 s\n",
            "2024-03-05 00:48:17.054395: \n",
            "2024-03-05 00:48:17.054576: Epoch 78\n",
            "2024-03-05 00:48:17.054695: Current learning rate: 0.00256\n",
            "2024-03-05 00:51:26.336771: train_loss -0.8836\n",
            "2024-03-05 00:51:26.337171: val_loss -0.7664\n",
            "2024-03-05 00:51:26.337355: Pseudo dice [0.9222, 0.7352]\n",
            "2024-03-05 00:51:26.337514: Epoch time: 189.28 s\n",
            "2024-03-05 00:51:30.154906: \n",
            "2024-03-05 00:51:30.155213: Epoch 79\n",
            "2024-03-05 00:51:30.155406: Current learning rate: 0.00245\n",
            "2024-03-05 00:54:48.185205: train_loss -0.8822\n",
            "2024-03-05 00:54:48.185565: val_loss -0.7664\n",
            "2024-03-05 00:54:48.185722: Pseudo dice [0.9466, 0.8232]\n",
            "2024-03-05 00:54:48.185834: Epoch time: 198.03 s\n",
            "2024-03-05 00:54:48.185940: Yayy! New best EMA pseudo Dice: 0.8367\n",
            "2024-03-05 00:54:50.637751: \n",
            "2024-03-05 00:54:50.637938: Epoch 80\n",
            "2024-03-05 00:54:50.638114: Current learning rate: 0.00235\n",
            "2024-03-05 00:58:02.994817: train_loss -0.8835\n",
            "2024-03-05 00:58:02.995204: val_loss -0.7842\n",
            "2024-03-05 00:58:02.995333: Pseudo dice [0.934, 0.7806]\n",
            "2024-03-05 00:58:02.995448: Epoch time: 192.36 s\n",
            "2024-03-05 00:58:02.995541: Yayy! New best EMA pseudo Dice: 0.8388\n",
            "2024-03-05 00:58:06.649662: \n",
            "2024-03-05 00:58:06.650020: Epoch 81\n",
            "2024-03-05 00:58:06.650196: Current learning rate: 0.00224\n",
            "2024-03-05 01:01:23.504195: train_loss -0.8798\n",
            "2024-03-05 01:01:23.504551: val_loss -0.7598\n",
            "2024-03-05 01:01:23.504707: Pseudo dice [0.935, 0.7648]\n",
            "2024-03-05 01:01:23.504829: Epoch time: 196.86 s\n",
            "2024-03-05 01:01:23.504923: Yayy! New best EMA pseudo Dice: 0.8399\n",
            "2024-03-05 01:01:26.458748: \n",
            "2024-03-05 01:01:26.458928: Epoch 82\n",
            "2024-03-05 01:01:26.459067: Current learning rate: 0.00214\n",
            "2024-03-05 01:04:24.085248: train_loss -0.8916\n",
            "2024-03-05 01:04:24.085611: val_loss -0.7768\n",
            "2024-03-05 01:04:24.085738: Pseudo dice [0.9383, 0.8025]\n",
            "2024-03-05 01:04:24.085850: Epoch time: 177.63 s\n",
            "2024-03-05 01:04:24.085939: Yayy! New best EMA pseudo Dice: 0.8429\n",
            "2024-03-05 01:04:26.921033: \n",
            "2024-03-05 01:04:26.921213: Epoch 83\n",
            "2024-03-05 01:04:26.921341: Current learning rate: 0.00203\n",
            "2024-03-05 01:07:38.477312: train_loss -0.8833\n",
            "2024-03-05 01:07:38.477656: val_loss -0.7488\n",
            "2024-03-05 01:07:38.477789: Pseudo dice [0.9097, 0.6886]\n",
            "2024-03-05 01:07:38.477891: Epoch time: 191.56 s\n",
            "2024-03-05 01:07:40.528804: \n",
            "2024-03-05 01:07:40.528967: Epoch 84\n",
            "2024-03-05 01:07:40.529144: Current learning rate: 0.00192\n",
            "2024-03-05 01:10:44.701418: train_loss -0.8852\n",
            "2024-03-05 01:10:44.713023: val_loss -0.7507\n",
            "2024-03-05 01:10:44.713307: Pseudo dice [0.9305, 0.7438]\n",
            "2024-03-05 01:10:44.713460: Epoch time: 184.17 s\n",
            "2024-03-05 01:10:47.679457: \n",
            "2024-03-05 01:10:47.679647: Epoch 85\n",
            "2024-03-05 01:10:47.679815: Current learning rate: 0.00181\n",
            "2024-03-05 01:14:01.841380: train_loss -0.8843\n",
            "2024-03-05 01:14:01.841923: val_loss -0.7658\n",
            "2024-03-05 01:14:01.842144: Pseudo dice [0.9316, 0.7748]\n",
            "2024-03-05 01:14:01.842315: Epoch time: 194.16 s\n",
            "2024-03-05 01:14:03.902403: \n",
            "2024-03-05 01:14:03.902599: Epoch 86\n",
            "2024-03-05 01:14:03.902722: Current learning rate: 0.0017\n",
            "2024-03-05 01:17:07.481921: train_loss -0.8892\n",
            "2024-03-05 01:17:07.482283: val_loss -0.765\n",
            "2024-03-05 01:17:07.482421: Pseudo dice [0.9397, 0.7715]\n",
            "2024-03-05 01:17:07.482531: Epoch time: 183.58 s\n",
            "2024-03-05 01:17:09.957178: \n",
            "2024-03-05 01:17:09.957450: Epoch 87\n",
            "2024-03-05 01:17:09.957628: Current learning rate: 0.00159\n",
            "2024-03-05 01:20:28.971889: train_loss -0.889\n",
            "2024-03-05 01:20:28.972300: val_loss -0.7276\n",
            "2024-03-05 01:20:28.972423: Pseudo dice [0.9222, 0.6743]\n",
            "2024-03-05 01:20:28.972533: Epoch time: 199.02 s\n",
            "2024-03-05 01:20:31.513684: \n",
            "2024-03-05 01:20:31.513899: Epoch 88\n",
            "2024-03-05 01:20:31.514056: Current learning rate: 0.00148\n",
            "2024-03-05 01:23:34.510362: train_loss -0.8936\n",
            "2024-03-05 01:23:34.510752: val_loss -0.7351\n",
            "2024-03-05 01:23:34.510933: Pseudo dice [0.9404, 0.7238]\n",
            "2024-03-05 01:23:34.511105: Epoch time: 183.0 s\n",
            "2024-03-05 01:23:36.504902: \n",
            "2024-03-05 01:23:36.505091: Epoch 89\n",
            "2024-03-05 01:23:36.505210: Current learning rate: 0.00137\n",
            "2024-03-05 01:26:41.164662: train_loss -0.8911\n",
            "2024-03-05 01:26:41.165052: val_loss -0.7675\n",
            "2024-03-05 01:26:41.165208: Pseudo dice [0.9386, 0.7782]\n",
            "2024-03-05 01:26:41.165323: Epoch time: 184.66 s\n",
            "2024-03-05 01:26:45.137657: \n",
            "2024-03-05 01:26:45.137897: Epoch 90\n",
            "2024-03-05 01:26:45.138054: Current learning rate: 0.00126\n",
            "2024-03-05 01:29:58.422394: train_loss -0.8922\n",
            "2024-03-05 01:29:58.432552: val_loss -0.7534\n",
            "2024-03-05 01:29:58.432822: Pseudo dice [0.928, 0.7394]\n",
            "2024-03-05 01:29:58.432970: Epoch time: 193.29 s\n",
            "2024-03-05 01:30:00.873242: \n",
            "2024-03-05 01:30:00.873443: Epoch 91\n",
            "2024-03-05 01:30:00.873590: Current learning rate: 0.00115\n",
            "2024-03-05 01:33:04.580409: train_loss -0.8883\n",
            "2024-03-05 01:33:04.580823: val_loss -0.756\n",
            "2024-03-05 01:33:04.580994: Pseudo dice [0.9282, 0.7277]\n",
            "2024-03-05 01:33:04.581142: Epoch time: 183.71 s\n",
            "2024-03-05 01:33:06.795408: \n",
            "2024-03-05 01:33:06.795635: Epoch 92\n",
            "2024-03-05 01:33:06.795818: Current learning rate: 0.00103\n",
            "2024-03-05 01:36:15.395343: train_loss -0.8916\n",
            "2024-03-05 01:36:15.395727: val_loss -0.7682\n",
            "2024-03-05 01:36:15.395877: Pseudo dice [0.9321, 0.7343]\n",
            "2024-03-05 01:36:15.396020: Epoch time: 188.6 s\n",
            "2024-03-05 01:36:19.370485: \n",
            "2024-03-05 01:36:19.370735: Epoch 93\n",
            "2024-03-05 01:36:19.370893: Current learning rate: 0.00091\n",
            "2024-03-05 01:39:31.413403: train_loss -0.8904\n",
            "2024-03-05 01:39:31.413782: val_loss -0.7545\n",
            "2024-03-05 01:39:31.413933: Pseudo dice [0.9298, 0.7251]\n",
            "2024-03-05 01:39:31.414081: Epoch time: 192.05 s\n",
            "2024-03-05 01:39:34.362967: \n",
            "2024-03-05 01:39:34.363199: Epoch 94\n",
            "2024-03-05 01:39:34.363369: Current learning rate: 0.00079\n",
            "2024-03-05 01:42:53.035432: train_loss -0.8904\n",
            "2024-03-05 01:42:53.035829: val_loss -0.7615\n",
            "2024-03-05 01:42:53.035959: Pseudo dice [0.9406, 0.7643]\n",
            "2024-03-05 01:42:53.036122: Epoch time: 198.67 s\n",
            "2024-03-05 01:42:56.291126: \n",
            "2024-03-05 01:42:56.291584: Epoch 95\n",
            "2024-03-05 01:42:56.291863: Current learning rate: 0.00067\n",
            "2024-03-05 01:46:10.609255: train_loss -0.8908\n",
            "2024-03-05 01:46:10.609592: val_loss -0.7541\n",
            "2024-03-05 01:46:10.609716: Pseudo dice [0.9383, 0.768]\n",
            "2024-03-05 01:46:10.609828: Epoch time: 194.32 s\n",
            "2024-03-05 01:46:13.129000: \n",
            "2024-03-05 01:46:13.129333: Epoch 96\n",
            "2024-03-05 01:46:13.129512: Current learning rate: 0.00055\n",
            "2024-03-05 01:49:18.919335: train_loss -0.8965\n",
            "2024-03-05 01:49:18.919672: val_loss -0.7622\n",
            "2024-03-05 01:49:18.919827: Pseudo dice [0.9347, 0.7362]\n",
            "2024-03-05 01:49:18.919935: Epoch time: 185.79 s\n",
            "2024-03-05 01:49:20.706505: \n",
            "2024-03-05 01:49:20.706749: Epoch 97\n",
            "2024-03-05 01:49:20.706893: Current learning rate: 0.00043\n",
            "2024-03-05 01:52:37.852787: train_loss -0.8918\n",
            "2024-03-05 01:52:37.853198: val_loss -0.8034\n",
            "2024-03-05 01:52:37.853323: Pseudo dice [0.943, 0.8094]\n",
            "2024-03-05 01:52:37.853438: Epoch time: 197.15 s\n",
            "2024-03-05 01:52:40.258967: \n",
            "2024-03-05 01:52:40.259159: Epoch 98\n",
            "2024-03-05 01:52:40.259313: Current learning rate: 0.0003\n",
            "2024-03-05 01:55:47.201576: train_loss -0.8926\n",
            "2024-03-05 01:55:47.201910: val_loss -0.7334\n",
            "2024-03-05 01:55:47.202055: Pseudo dice [0.94, 0.7388]\n",
            "2024-03-05 01:55:47.202189: Epoch time: 186.94 s\n",
            "2024-03-05 01:55:50.562732: \n",
            "2024-03-05 01:55:50.563001: Epoch 99\n",
            "2024-03-05 01:55:50.563155: Current learning rate: 0.00016\n",
            "2024-03-05 01:58:59.693280: train_loss -0.8945\n",
            "2024-03-05 01:58:59.706121: val_loss -0.7635\n",
            "2024-03-05 01:58:59.706410: Pseudo dice [0.9267, 0.6969]\n",
            "2024-03-05 01:58:59.706533: Epoch time: 189.13 s\n",
            "2024-03-05 01:59:03.048704: Training done.\n",
            "2024-03-05 01:59:03.125015: Using splits from existing split file: /content/nnUNet_preprocessed/Dataset007_Kidney/splits_final.json\n",
            "2024-03-05 01:59:03.125364: The split file contains 5 splits.\n",
            "2024-03-05 01:59:03.125473: Desired fold for training: 2\n",
            "2024-03-05 01:59:03.125557: This split has 41 training and 10 validation cases.\n",
            "2024-03-05 01:59:03.125830: predicting case_00000\n",
            "2024-03-05 01:59:03.127126: case_00000, shape torch.Size([1, 128, 95, 146]), rank 0\n",
            "2024-03-05 01:59:06.031061: predicting case_00004\n",
            "2024-03-05 01:59:06.032640: case_00004, shape torch.Size([1, 137, 78, 155]), rank 0\n",
            "2024-03-05 01:59:07.279295: predicting case_00007\n",
            "2024-03-05 01:59:07.280875: case_00007, shape torch.Size([1, 132, 56, 149]), rank 0\n",
            "2024-03-05 01:59:08.515750: predicting case_00023\n",
            "2024-03-05 01:59:08.517199: case_00023, shape torch.Size([1, 109, 99, 124]), rank 0\n",
            "2024-03-05 01:59:08.852891: predicting case_00024\n",
            "2024-03-05 01:59:08.854502: case_00024, shape torch.Size([1, 93, 130, 105]), rank 0\n",
            "2024-03-05 01:59:09.487989: predicting case_00025\n",
            "2024-03-05 01:59:09.489654: case_00025, shape torch.Size([1, 103, 79, 117]), rank 0\n",
            "2024-03-05 01:59:09.813628: predicting case_00030\n",
            "2024-03-05 01:59:09.815286: case_00030, shape torch.Size([1, 104, 57, 116]), rank 0\n",
            "2024-03-05 01:59:10.163506: predicting case_00039\n",
            "2024-03-05 01:59:10.177268: case_00039, shape torch.Size([1, 98, 138, 111]), rank 0\n",
            "2024-03-05 01:59:10.829307: predicting case_00045\n",
            "2024-03-05 01:59:10.830828: case_00045, shape torch.Size([1, 104, 57, 117]), rank 0\n",
            "2024-03-05 01:59:11.163103: predicting case_00046\n",
            "2024-03-05 01:59:11.164430: case_00046, shape torch.Size([1, 136, 147, 155]), rank 0\n",
            "2024-03-05 01:59:23.543261: Validation complete\n",
            "2024-03-05 01:59:23.543409: Mean Validation Dice:  0.7728819759157975\n"
          ]
        }
      ],
      "source": [
        "! nnUNetv2_train 07 3d_fullres 2 -device cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
